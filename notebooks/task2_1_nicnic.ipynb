{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. check the how many times item2 is item1's next item\n",
    "2. For each item1, normalized the count to [0, 1]\n",
    "3. Add 0.01 -> since 0 will represent item2 has never been the next item of item1\n",
    "4. Next steps\n",
    "    1. [x] counts should be included \n",
    "    2. [x] train2 data should be included\n",
    "    3. [x] 0 should be the min_count for each item\n",
    "\n",
    "\n",
    "Example: [a, b, c] -> [ab, bc] -> \n",
    "\n",
    "```\n",
    "[\n",
    "--current_item, next_item, counts\n",
    "[a, b, 1],\n",
    "[b, c, 1]\n",
    "]\n",
    "\n",
    "after normalization\n",
    "\n",
    "[\n",
    "--current_item, next_item, counts\n",
    "[a, b, 1.01],\n",
    "[b, c, 1.01]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import logging\n",
    "base_dir = '../'\n",
    "sys.path.append(base_dir)\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "import polars as pl\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from tqdm.auto import tqdm\n",
    "import polars as pl\n",
    "from utils import *\n",
    "from src.eval import model_eval\n",
    "from src.config import raw_data_session_id_dir, candidate_dir, model_for_eval, candidate_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "\n",
    "task = 'task2'\n",
    "\n",
    "version = 'v2'\n",
    "\n",
    "model_version = f'nicnic_{task}_{version}' \n",
    "nic_model_version = f'nic_task2_v2'\n",
    "\n",
    "item2consider = 4\n",
    "\n",
    "\n",
    "\n",
    "# current_model_version = f'nicnic_{task}_{version}'\n",
    "\n",
    "# target locales: locales needed for task1\n",
    "\n",
    "if task == 'task1':\n",
    "    target_locals = ['DE', 'JP', 'UK']\n",
    "elif task == 'task2':\n",
    "    target_locals = ['ES', 'FR', 'IT']\n",
    "else:\n",
    "    assert 1 == 0\n",
    "\n",
    "topn = 300\n",
    "if debug:\n",
    "    n_rows = 1000\n",
    "else:\n",
    "    n_rows = None\n",
    "# debug_session_num = 100\n",
    "train_data_dir = '.'\n",
    "test_data_dir = '.'\n",
    "\n",
    "\n",
    "model_dir = f'../model_training/{nic_model_version}/'\n",
    "\n",
    "\n",
    "# if model_for_eval:\n",
    "model_file = os.path.join(model_dir, f'nic_{model_for_eval}_for_eval.parquet')\n",
    "submit_file = os.path.join('../data/sub_files/', f'submission_{task}_nic_{model_for_eval}_for_eval.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task2_v2/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task2_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/candidates/task2_train_nicnic_task2_v2_True_top300.parquet\n",
      "../data/candidates/task2_eval_nicnic_task2_v2_True_top300.parquet\n",
      "../data/candidates/task2_test_nicnic_task2_v2_True_top300.parquet\n",
      "../data/candidates/task2_test4task3_nicnic_task2_v2_True_top300.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_cg_file = os.path.join(base_dir,\n",
    "                             candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='train'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "eval_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='eval'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "test_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='test'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "\n",
    "test4task3_file_name = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "                                    candidate_file_name.format(\n",
    "    task=task\n",
    "    , data_type='test4task3'\n",
    "    , model_version=model_version\n",
    "    , model_for_eval=model_for_eval\n",
    "    , topn=topn\n",
    "))\n",
    "print(train_cg_file)\n",
    "print(eval_cg_file)\n",
    "print(test_cg_file)\n",
    "print(test4task3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task2_test_nicnic_task2_v2_True_top300.parquet'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../model_training/nic_task2_v2/’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task2_v2/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task2_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_pl = pl.scan_parquet('../data/candidates/task2_test_nic_task2_v2_True_top100.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_prediciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_unique2id.json\t\t    sessions_test_task2_phase1.parquet\n",
      "products_train.parquet\t\t    sessions_test_task3.parquet\n",
      "sessions_eval.parquet\t\t    sessions_test_task3_phase1.parquet\n",
      "sessions_test_task1.parquet\t    sessions_train.parquet\n",
      "sessions_test_task1_phase1.parquet  sessions_train1.parquet\n",
      "sessions_test_task2.parquet\t    sessions_train2.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls ../{raw_data_session_id_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_train1.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "train2_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_train2.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "eval_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_eval.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "# df_sess.head(3).collect()\n",
    "test_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, f'sessions_test_{task}.parquet'), n_rows=n_rows).with_columns(pl.col('prev_items').apply(str2list))\n",
    "test4task3_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task3.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>locale</th><th>counts</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;FR&quot;</td><td>10000</td></tr><tr><td>&quot;ES&quot;</td><td>6422</td></tr><tr><td>&quot;IT&quot;</td><td>10000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────┐\n",
       "│ locale ┆ counts │\n",
       "│ ---    ┆ ---    │\n",
       "│ str    ┆ u32    │\n",
       "╞════════╪════════╡\n",
       "│ FR     ┆ 10000  │\n",
       "│ ES     ┆ 6422   │\n",
       "│ IT     ┆ 10000  │\n",
       "└────────┴────────┘"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4task3_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl.filter(pl.col('session_id')==3272918).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.filter(pl.col('locale').is_null()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'item', 'next_item_prediction', 'next_item_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nic_rec(target_pl, nic_model, rec_num=topn, item2consider=item2consider):\n",
    "    \n",
    "    final_cols = ['session_id', 'next_item_prediction', 'rec_num']\n",
    "    target_pl = (\n",
    "        target_pl\n",
    "            # .with_columns(\n",
    "            #     pl.col('prev_items').arr.get(-1).alias('last_item')\n",
    "            # )\n",
    "            .with_columns(\n",
    "                pl.col('prev_items').arr.lengths().alias('prev_len')\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col('prev_len').apply(lambda x: list(range(x, 0, -1))).alias('reverse_index')\n",
    "            )\n",
    "            .explode(['prev_items', 'reverse_index'])\n",
    "            .filter(pl.col('reverse_index')<=item2consider)\n",
    "            .join(nic_model.select(['item', 'next_item_prediction', 'next_item_cnt']), \n",
    "                  how='left', left_on='prev_items', right_on='item')\n",
    "            .explode(['next_item_prediction', 'next_item_cnt'])\n",
    "            .with_columns(\n",
    "                    pl.col('next_item_cnt').truediv(pl.col('reverse_index')).alias('next_item_cnt')\n",
    "            )\n",
    "            .groupby(['session_id', 'locale', 'next_item_prediction'])\n",
    "            .agg(\n",
    "                pl.col('next_item_cnt').sum()\n",
    "            )\n",
    "            .sort(['session_id', 'next_item_cnt'], descending=True)\n",
    "            .groupby(['session_id', 'locale'])\n",
    "            .agg(\n",
    "                pl.col('next_item_prediction')\n",
    "                , pl.col('next_item_cnt')\n",
    "            )\n",
    "\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('next_item_prediction').is_null()).then([]).otherwise(pl.col('next_item_prediction').arr.head(rec_num)).alias('next_item_prediction')\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "            )\n",
    "            .select(\n",
    "                final_cols\n",
    "            )\n",
    "        )\n",
    "    return target_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nic_model.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_pl = test_pl\n",
    "# nic_model=next_items_pl\n",
    "# rec_num=topn\n",
    "\n",
    "# final_cols = ['session_id', 'next_item_prediction', 'rec_num']\n",
    "# target_pl = (\n",
    "#     target_pl\n",
    "#         # .with_columns(\n",
    "#         #     pl.col('prev_items').arr.get(-1).alias('last_item')\n",
    "#         # )\n",
    "#         .with_columns(\n",
    "#             pl.col('prev_items').arr.lengths().alias('prev_len')\n",
    "#         )\n",
    "#         .with_columns(\n",
    "#             pl.col('prev_len').apply(lambda x: list(range(x, 0, -1))).alias('reverse_index')\n",
    "#         )\n",
    "#         .explode(['prev_items', 'reverse_index'])\n",
    "#         .filter(pl.col('reverse_index')<=3)\n",
    "#         .join(nic_model.select(['item', 'next_item_prediction', 'next_item_cnt']), \n",
    "#               how='left', left_on='prev_items', right_on='item')\n",
    "#         .explode(['next_item_prediction', 'next_item_cnt'])\n",
    "#         .with_columns(\n",
    "#                 pl.col('next_item_cnt').truediv(pl.col('reverse_index')).alias('next_item_cnt')\n",
    "#         )\n",
    "#         .groupby(['session_id', 'locale', 'next_item_prediction'])\n",
    "#         .agg(\n",
    "#             pl.col('next_item_cnt').sum()\n",
    "#         )\n",
    "#         .sort(['session_id', 'next_item_cnt'], descending=True)\n",
    "#         .groupby(['session_id', 'locale'])\n",
    "#         .agg(\n",
    "#             pl.col('next_item_prediction')\n",
    "#             , pl.col('next_item_cnt')\n",
    "#         )\n",
    "\n",
    "#         .with_columns(\n",
    "#             pl.when(pl.col('next_item_prediction').is_null()).then([]).otherwise(pl.col('next_item_prediction').arr.head(rec_num)).alias('next_item_prediction')\n",
    "#         )\n",
    "#         .with_columns(\n",
    "#             pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "#         )\n",
    "#         .select(\n",
    "#             final_cols\n",
    "#         )\n",
    "# ).head(3).collect()\n",
    "\n",
    "# target_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task2_v2/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_items_pl = pl.scan_parquet(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = next_items_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item', 'next_item_prediction', 'next_item_weight', 'next_item_cnt'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_items_pl.head(30).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    next_items_pl.explode('next_item_prediction')\n",
    "        .filter(\n",
    "            pl.col('next_item_prediction').is_null()\n",
    "        )\n",
    ").collect().shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl = nic_rec(target_pl=eval_pl, nic_model=next_items_pl)#.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if_hit = pl.element().rank()\n",
    "target_df = eval_pl.join(eval_candidate_pl, how='left', on='session_id')\n",
    "\n",
    "\n",
    "# eval_final.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>total_sessions</th><th>mrr</th><th>recall@20</th><th>recall@100</th></tr><tr><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>33333</td><td>0.2411</td><td>0.5327</td><td>0.5836</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────────┬────────┬───────────┬────────────┐\n",
       "│ total_sessions ┆ mrr    ┆ recall@20 ┆ recall@100 │\n",
       "│ ---            ┆ ---    ┆ ---       ┆ ---        │\n",
       "│ u32            ┆ f64    ┆ f64       ┆ f64        │\n",
       "╞════════════════╪════════╪═══════════╪════════════╡\n",
       "│ 33333          ┆ 0.2411 ┆ 0.5327    ┆ 0.5836     │\n",
       "└────────────────┴────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval(target_df=target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>rec_num</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>33333.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>34.870249</td></tr><tr><td>&quot;std&quot;</td><td>35.756147</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td></tr><tr><td>&quot;max&quot;</td><td>300.0</td></tr><tr><td>&quot;median&quot;</td><td>23.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ describe   ┆ rec_num   │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ count      ┆ 33333.0   │\n",
       "│ null_count ┆ 0.0       │\n",
       "│ mean       ┆ 34.870249 │\n",
       "│ std        ┆ 35.756147 │\n",
       "│ min        ┆ 1.0       │\n",
       "│ max        ┆ 300.0     │\n",
       "│ median     ┆ 23.0      │\n",
       "└────────────┴───────────┘"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.select('rec_num').collect().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Saving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_candidate_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task2_eval_nicnic_task2_v2_True_top300.parquet'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_cg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl.filter(pl.col('rec_num')>0).collect().write_parquet(eval_cg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & eval  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_pl = nic_rec(target_pl=train2_pl, nic_model=next_items_pl)#.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_pl.filter(pl.col('rec_num')>0).collect().write_parquet(train_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate_pl = nic_rec(target_pl=test_pl, nic_model=next_items_pl)#.head().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate_pl.filter(pl.col('rec_num')>0).collect().write_parquet(test_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task2_test_nicnic_task2_v2_True_top300.parquet'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cg_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test4task3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/candidates/task2_test4task3_nicnic_task2_v2_True_top300.parquet\n"
     ]
    }
   ],
   "source": [
    "print(test4task3_file_name)\n",
    "test4task3_cg_pl = nic_rec(target_pl=test4task3_pl, nic_model=next_items_pl)#.head().collect()\n",
    "test4task3_cg_pl.filter(pl.col('rec_num')>0).collect().write_parquet(test4task3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_task2 = pl.read_csv('../data/raw_data/sessions_test_task2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls ../data/raw_data/ | grep task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_task2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_pl.join(test_candidate_pl, how='left', on='session_id').collect()[['locale', 'next_item_prediction']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_predictions(predictions,test_sessions, check_products=False, product_df=None):\n",
    "    \"\"\"\n",
    "    These tests need to pass as they will also be applied on the evaluator\n",
    "    \"\"\"\n",
    "    test_locale_names = test_sessions['locale'].unique()\n",
    "    for locale in test_locale_names:\n",
    "        sess_test = test_sessions.query(f'locale == \"{locale}\"')\n",
    "        preds_locale =  predictions[predictions['locale'] == sess_test['locale'].iloc[0]]\n",
    "        assert sorted(preds_locale.index.values) == sorted(sess_test.index.values), f\"Session ids of {locale} doesn't match\"\n",
    "\n",
    "        if check_products:\n",
    "            # This check is not done on the evaluator\n",
    "            # but you can run it to verify there is no mixing of products between locales\n",
    "            # Since the ground truth next item will always belong to the same locale\n",
    "            # Warning - This can be slow to run\n",
    "            products = product_df.query(f'locale == \"{locale}\"')\n",
    "            predicted_products = np.unique( np.array(list(preds_locale[\"next_item_prediction\"].values)) )\n",
    "            assert np.all( np.isin(predicted_products, products['id']) ), f\"Invalid products in {locale} predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_predictions(predictions, test_sessions=test_pl.collect().to_pandas(), \n",
    "                  # check_products=True, product_df=products\n",
    "                 )\n",
    "# Its important that the parquet file you submit is saved with pyarrow backend\n",
    "predictions.to_parquet(submit_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task2_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aicrowd submission create -c task-2-next-product-recommendation-for-underrepresented-languages -f {submit_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Top200 for fallback logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m popular_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf_sess\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_items\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m]], df_test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_items\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m]]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sess' is not defined"
     ]
    }
   ],
   "source": [
    "popular_df = pd.concat([df_sess[['prev_items', 'locale']], df_test[['prev_items', 'locale']]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_pl = pl.from_pandas(popular_df).lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 200\n",
    "locale_popular_pl = (\n",
    "    popular_pl\n",
    "        .select(\n",
    "            pl.col('prev_items').apply(str2list)#.explode().alias('item')\n",
    "            , pl.col('locale')\n",
    "        )\n",
    "        .explode('prev_items')#.alias('item')\n",
    "        .groupby(['locale', 'prev_items'])\n",
    "        .agg(\n",
    "            pl.count()\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('count').rank(method='ordinal', descending=True).over('locale').alias('rank')\n",
    "        )\n",
    "        .filter(pl.col('rank')<=topn)\n",
    "        .with_columns(\n",
    "            pl.col('count').max().over('locale').alias('max_count')\n",
    "            , pl.col('count').min().over('locale').alias('min_count')\n",
    "        )\n",
    "        .with_columns(\n",
    "            ((pl.col('count')-pl.col('min_count'))/(pl.col('max_count')-pl.col('min_count'))).alias('weight')\n",
    "        )\n",
    "        .sort('locale', 'rank')\n",
    "        .select(\n",
    "            'locale'\n",
    "            , 'prev_items'\n",
    "            , 'weight'\n",
    "        )\n",
    "        .groupby('locale')\n",
    "        .agg(\n",
    "            pl.col('weight').alias('locale_popular_weight')\n",
    "            , pl.col('prev_items').alias('locale_popular_rec')\n",
    "        )\n",
    "        # .count()#.head(3).collect())\n",
    "        # .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular_df.apply(lambda x: str2list(x['prev_items']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next_item_df['next_item_prediction'] = next_item_df['next_item_prediction'].astype(str)\n",
    "# # next_item_df['next_item_weights'] = next_item_df['next_item_weights'].astype(str)\n",
    "# cols = [\n",
    "#     # 'item',\n",
    "#         'next_item_prediction'\n",
    "#         , 'next_item_weights'\n",
    "#        ]\n",
    "# next_item_pl = pl.from_pandas(next_item_df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k = []\n",
    "# # v = []\n",
    "\n",
    "# # for item in next_item_dict:\n",
    "# #     k.append(item)\n",
    "# #     v.append(next_item_dict[item])\n",
    "    \n",
    "# # df_next = pd.DataFrame({'item': k, 'next_item': v})\n",
    "# df_next = next_item_df.explode('next_item_prediction').reset_index(drop=True)\n",
    "# df_next = df_next.merge(products, how='left', left_on='item', right_on='id')\n",
    "# df_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_next['next_item'].value_counts().index.tolist()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = {\n",
    "#     'top200': top200\n",
    "#     , 'next_item_map': next_item_map\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(model_file, 'wb') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get final result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with open(model_file, 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_rec(target_df, model):\n",
    "#     next_item_map = model['next_item_map']\n",
    "#     top200  = model['top200']\n",
    "#     target_df['last_item'] = target_df['prev_items'].apply(lambda x: str2list(x)[-1])\n",
    "#     target_df['next_item_prediction'] = target_df['last_item'].map(next_item_map)\n",
    "#     preds = []\n",
    "\n",
    "#     for _, row in tqdm(target_df.iterrows(), total=len(target_df)):\n",
    "#         pred_orig = row['next_item_prediction']\n",
    "#         pred = pred_orig\n",
    "#         prev_items = str2list(row['prev_items'])\n",
    "#         if type(pred) == float:\n",
    "#             pred = top200[:100]\n",
    "#         else:\n",
    "#             if len(pred_orig) < 100:\n",
    "#                 for i in top200:\n",
    "#                     if i not in pred_orig and i not in prev_items:\n",
    "#                         pred.append(i)\n",
    "#                     if len(pred) >= 100:\n",
    "#                         break\n",
    "#             else:\n",
    "#                 pred = pred[:100]\n",
    "#         preds.append(pred)\n",
    "#     target_df['next_item_prediction'] = preds\n",
    "#     print(target_df['next_item_prediction'].apply(len).describe())\n",
    "#     return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model['next_item_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate for train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl = pl.scan_csv('sessions_train.csv')\n",
    "train_pl = pl.scan_parquet('../data/eval_data/next_item_counter_train_eval_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_locals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl = (\n",
    "    train_pl\n",
    "        .filter(pl.col('locale').is_in(target_locals))\n",
    "        .with_columns(\n",
    "            pl.col('prev_items').apply(str2list).arr.get(-1).alias('last_item')\n",
    "        )\n",
    "        .join(nex_item_pl, how='left', left_on='last_item', right_on='item')\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('next_item_rec').is_null()).then([]).otherwise(pl.col('next_item_rec').arr.head(100)).alias('next_item_prediction')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'next_item'\n",
    "            , 'locale'\n",
    "            , 'next_item_prediction'\n",
    "            , 'rec_num'\n",
    "        )\n",
    ")#.head(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl.collect().write_parquet('../data/candidates/task1_train_nic_without_pupular_top100_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final resul "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_rec(target_pl, locale_popular_pl, nex_item_pl):\n",
    "    rec_num = 100\n",
    "    target_pl = (\n",
    "        target_pl\n",
    "            .with_columns(\n",
    "                pl.col('prev_items').apply(str2list).arr.get(-1).alias('last_item')\n",
    "            )\n",
    "            .join(nex_item_pl, how='left', left_on='last_item', right_on='item')\n",
    "            .join(locale_popular_pl, how='left', on='locale')\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('next_item_rec').is_null()).then([]).otherwise(pl.col('next_item_rec')).alias('next_item_rec')\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.concat_list([pl.col('next_item_rec'), pl.col('locale_popular_rec')])\n",
    "                    .alias('next_item_prediction')\n",
    "                    .arr.head(rec_num)\n",
    "\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "            )\n",
    "    )#.head(3).collect()\n",
    "    return target_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl = pl.scan_parquet(f'../data/eval_data/w2v_train_eval_result_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nex_item_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl = pl_rec(target_pl=eval_pl, locale_popular_pl=locale_popular_pl, nex_item_pl=nex_item_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.select(\n",
    "    pl.col('next_item_prediction').arr.head(20).arr.contains(pl.col('next_item')).mean().alias('recall@20')\n",
    "    , pl.col('next_item_prediction').arr.head(100).arr.contains(pl.col('next_item')).mean().alias('recall@100')\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# eval_cols = ['len', 'recall@20', 'recall@100']\n",
    "# train_eval_df[eval_cols] = train_eval_df.apply(pd_get_recall_at_k, axis=1, result_type='expand')\n",
    "# print(train_eval_df[eval_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.collect().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.collect().write_parquet(f'../data/eval_data/{model_version}_train_eval_300k.parquet', \n",
    "                      # engine='pyarrow'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl = pl.scan_csv('sessions_test_task1.csv')\n",
    "test_pl = pl_rec(target_pl=test_pl, locale_popular_pl=locale_popular_pl, nex_item_pl=nex_item_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -al | grep {submit_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.collect().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.collect().select('locale', 'next_item_prediction').write_parquet(submit_file,\n",
    "#                                                                          # engine='pyarrow'\n",
    "#                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "# !aicrowd submission create -c task-1-next-product-recommendation -f {submit_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df = pl.scan_parquet('submission_task1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w2v_df.collect().shape[0] == test_pl.collect().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pl.concat([test_pl.select('prev_items', 'locale', 'next_item_rec').collect(), w2v_df.select('next_item_prediction').collect()]\n",
    "                    , how='horizontal' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_num = 100\n",
    "target_pl = (\n",
    "    target_df\n",
    "        .lazy()\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'locale'\n",
    "            , pl.concat_list([pl.col('next_item_rec'), pl.col('next_item_prediction')])\n",
    "                .alias('next_item_prediction')\n",
    "                .arr.head(rec_num)\n",
    "\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    ")#.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.head(6).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir ../data/sub_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.collect().select('locale', 'next_item_prediction').write_parquet('../data/sub_files/rank_v1.parquet',\n",
    "                                                                         # engine='pyarrow'\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "# !aicrowd submission create -c task-1-next-product-recommendation -f '../data/sub_files/rank_v1.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_num = 100\n",
    "target_pl = (\n",
    "    target_df\n",
    "        .lazy()\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'locale'\n",
    "            , pl.concat_list([pl.col('next_item_rec').arr.head(20), pl.col('next_item_prediction')])\n",
    "                .alias('next_item_prediction')\n",
    "                .arr.head(rec_num)\n",
    "\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    ")#.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.collect().select('locale', 'next_item_prediction').write_parquet('../data/sub_files/rank_v2.parquet',\n",
    "                                                                         # engine='pyarrow'\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "!aicrowd submission create -c task-1-next-product-recommendation -f '../data/sub_files/rank_v2.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl = pl.scan_parquet(submit_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.select(\n",
    "    pl.col('next_item_prediction').arr.lengths().min()\n",
    "    , pl.col('next_item_prediction').arr.lengths().max()\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "kdd_2023",
   "name": "common-cu110.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m104"
  },
  "kernelspec": {
   "display_name": "py3.8(kdd_2023)",
   "language": "python",
   "name": "kdd_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
