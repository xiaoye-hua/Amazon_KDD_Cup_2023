{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmjiT10Qk5m8",
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7DjmcQMAgPAJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import logging\n",
    "base_dir = '../'\n",
    "sys.path.append(base_dir)\n",
    "import os\n",
    "from gensim.similarities.annoy import AnnoyIndexer\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from annoy import AnnoyIndex\n",
    "import polars as pl\n",
    "import polars as pl\n",
    "from utils import *\n",
    "from src.eval import model_eval\n",
    "from src.config import (\n",
    "    raw_data_session_id_dir, candidate_dir, model_for_eval, candidate_file_name, submit_file_name\n",
    "    # , w2v_model_file_name, w2v_index_file_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxcGbj4xAqqe"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qYPjjtQ_AqRT"
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "topn = 200\n",
    "model_version = 'w2v_v3'\n",
    "if debug:\n",
    "    n_rows = 100\n",
    "else:\n",
    "    n_rows = None\n",
    "\n",
    "    \n",
    "task = 'task1'\n",
    "# Common setting\n",
    "model_dir = f'../model_training/{model_version}/'\n",
    "# target locales: locales needed for task1\n",
    "target_locals = [\"DE\", 'JP', 'UK']\n",
    "submit_file = os.path.join('../data/sub_files/', \n",
    "                           submit_file_name.format(\n",
    "                                task=task\n",
    "                               , model_version=model_version\n",
    "                               , model_for_eval=model_for_eval\n",
    "                               , topn=topn\n",
    "                           )\n",
    "                          )\n",
    "\n",
    "train_cg_file = os.path.join(base_dir,\n",
    "                             candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='train'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "eval_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='eval'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "test_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='test'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "\n",
    "# specific setting\n",
    "num_tree = 100\n",
    "# if model_for_eval:\n",
    "w2v_model_file = os.path.join(model_dir, f\"{model_for_eval}.model\")\n",
    "annoy_index_file = os.path.join(model_dir, f\"{str(num_tree)}_{model_for_eval}.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜../model_training/w2v_v3/â€™: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6oiTtQ56gYlY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model_training/w2v_v3/True.model; \n",
      " ../model_training/w2v_v3/100_True.index; \n",
      " ../data/sub_files/submit_task1_w2v_v3_True_top100.parquet  \n",
      " ../data/candidates/task1_train_w2v_v3_True_top100.parquet \n",
      " ../data/candidates/task1_eval_w2v_v3_True_top100.parquet \n",
      " ../data/candidates/task1_test_w2v_v3_True_top100.parquet\n"
     ]
    }
   ],
   "source": [
    "print(f\"{w2v_model_file}; \\n {annoy_index_file}; \\n {submit_file}  \\n {train_cg_file} \\n {eval_cg_file} \\n {test_cg_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_rec(target_df, w2vec, annoy_index, topn=100):\n",
    "    final_cols = ['session_id', 'next_item_prediction']\n",
    "    def get_next_items(x):\n",
    "        prev_items = x['prev_items']\n",
    "        local_rec = x['next_item_prediction']\n",
    "        final = [ele for ele in local_rec if ele not in prev_items]\n",
    "        return final\n",
    "    target_df = (\n",
    "        target_df.with_columns(\n",
    "            pl.col('prev_items').apply(lambda x: \n",
    "                                       # x.to_list()\n",
    "                                       list(map(list, zip(*w2vec.wv.most_similar(positive=x.to_list(),\n",
    "                                                                     topn=topn+10,\n",
    "                                                                     indexer=annoy_index))))[0]\n",
    "                                      ).alias('next_item_prediction'))\n",
    "        .with_columns(\n",
    "                    pl.struct([\"prev_items\", \"next_item_prediction\"]).apply(\n",
    "                        lambda x: get_next_items(x)).arr.head(topn).alias('next_item_prediction'))\n",
    "        .select(\n",
    "          final_cols\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    "    )\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0T1vtOEB5v-",
    "tags": []
   },
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_train.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "eval_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_eval.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "# df_sess.head(3).collect()\n",
    "test_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task1.parquet'), n_rows=n_rows).with_columns(pl.col('prev_items').apply(str2list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model & annnoy index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_pl.with_columns(\n",
    "    pl.col('prev_items').arr.concat(pl.col('next_item')) \n",
    ")\n",
    "if not model_for_eval:\n",
    "    eval_data = eval_pl.with_columns(\n",
    "    pl.col('prev_items').arr.concat(pl.col('next_item')) \n",
    ")\n",
    "else:\n",
    "    eval_data = eval_pl\n",
    "test_data = test_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3589687"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep = ['prev_items']\n",
    "sentences = (\n",
    "    pl.concat([train_data.select(cols_to_keep), eval_data.select(cols_to_keep), test_data.select(cols_to_keep)], how='vertical')\n",
    ").collect().to_dict()['prev_items'].to_list()\n",
    "\n",
    "# sentences = map(sentences, list)\n",
    "\n",
    "\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aJe9Y_uB8nF",
    "outputId": "e177ee22-154f-4195-f06a-6a7f7afba594"
   },
   "outputs": [],
   "source": [
    "vector_size = 32\n",
    "epochs = 10\n",
    "sg = 1 # 1 for skip-gram\n",
    "pop_thresh = 0.82415\n",
    "window = 4\n",
    "\n",
    "# \n",
    "\n",
    "# len(sentences)sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "j2aLO74iLJzD"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZL3YXLg_Dzl3",
    "outputId": "558f7e2c-a427-41eb-a368-f12c08da34af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 14782675.0\n",
      "Loss after epoch 1: 5239365.0\n",
      "Loss after epoch 2: 3863152.0\n",
      "Loss after epoch 3: 3312670.0\n",
      "Loss after epoch 4: 2841758.0\n",
      "Loss after epoch 5: 2481642.0\n",
      "Loss after epoch 6: 1343122.0\n",
      "Loss after epoch 7: 544188.0\n",
      "Loss after epoch 8: 510712.0\n",
      "Loss after epoch 9: 483772.0\n"
     ]
    }
   ],
   "source": [
    "w2vec = Word2Vec(sentences=sentences, vector_size=vector_size, epochs = epochs, sg=sg,\n",
    "                 min_count=1, workers=14,\n",
    "                 window=window,\n",
    "                  compute_loss=True\n",
    "              , callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/w2v_v3/True.model'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 100 trees are being used in this example\n",
    "annoy_index = AnnoyIndexer(w2vec, num_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QKu7E6IcOHX1"
   },
   "outputs": [],
   "source": [
    "w2vec.save(w2v_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annoy_index.save(annoy_index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/w2v_v3/True.model'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/w2v_v3/100_True.index'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annoy_index_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec = Word2Vec.load(w2v_model_file)\n",
    "annoy_index = AnnoyIndexer()\n",
    "annoy_index.load(annoy_index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl = w2v_rec(target_df=eval_pl,\n",
    "                   w2vec=w2vec, annoy_index=annoy_index, topn=topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_id': Int64, 'next_item_prediction': Unknown, 'rec_num': UInt32}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_candidate_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_candidate_pl.head(1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 1s, sys: 14.4 s, total: 29min 16s\n",
      "Wall time: 29min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eval_candidate_pl = eval_candidate_pl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>rec_num</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>326443.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>199.971186</td></tr><tr><td>&quot;std&quot;</td><td>0.563307</td></tr><tr><td>&quot;min&quot;</td><td>110.0</td></tr><tr><td>&quot;max&quot;</td><td>200.0</td></tr><tr><td>&quot;median&quot;</td><td>200.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ describe   â”† rec_num    â”‚\n",
       "â”‚ ---        â”† ---        â”‚\n",
       "â”‚ str        â”† f64        â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ count      â”† 326443.0   â”‚\n",
       "â”‚ null_count â”† 0.0        â”‚\n",
       "â”‚ mean       â”† 199.971186 â”‚\n",
       "â”‚ std        â”† 0.563307   â”‚\n",
       "â”‚ min        â”† 110.0      â”‚\n",
       "â”‚ max        â”† 200.0      â”‚\n",
       "â”‚ median     â”† 200.0      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_candidate_pl.select('rec_num').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_eval(target_df=eval_pl.join(eval_candidate_pl.lazy(), how='left', on='session_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 52.5 s, total: 3min 16s\n",
      "Wall time: 21.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>total_sessions</th><th>mrr</th><th>recall@20</th><th>recall@100</th><th>recall@all</th></tr><tr><td>u32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>326443</td><td>0.085336</td><td>0.206468</td><td>0.34157</td><td>0.392635</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ total_sessions â”† mrr      â”† recall@20 â”† recall@100 â”† recall@all â”‚\n",
       "â”‚ ---            â”† ---      â”† ---       â”† ---        â”† ---        â”‚\n",
       "â”‚ u32            â”† f64      â”† f64       â”† f64        â”† f64        â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 326443         â”† 0.085336 â”† 0.206468  â”† 0.34157    â”† 0.392635   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# model_eval(target_df=target_df)\n",
    "eval_final = (\n",
    "        eval_pl.join(eval_candidate_pl.lazy(), how='left', on='session_id')\n",
    "        .lazy()\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').cast(pl.List(pl.Utf8))\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.concat_list([pl.col('next_item'), pl.col('next_item_prediction')]).alias('mrr')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('mrr').arr.eval(\n",
    "                pl.arg_where(pl.element()==pl.element().first())\n",
    "            )\n",
    "        ).with_columns(\n",
    "            pl.col('mrr').arr.eval(\n",
    "                pl.when(pl.element()==0).then(0).otherwise(1/pl.element())\n",
    "            )\n",
    "        ).with_columns(\n",
    "            pl.col('mrr').arr.sum()\n",
    "            , pl.col('next_item_prediction').arr.head(20).arr.contains(pl.col('next_item')).mean().alias('recall@20')\n",
    "            , pl.col('next_item_prediction').arr.head(100).arr.contains(pl.col('next_item')).mean().alias('recall@100')\n",
    "            , pl.col('next_item_prediction').arr.head(topn).arr.contains(pl.col('next_item')).mean().alias('recall@all')\n",
    "\n",
    "\n",
    "        )\n",
    ")\n",
    "final_res = eval_final.select(\n",
    "        pl.count().alias('total_sessions')\n",
    "        , pl.col('mrr').mean()\n",
    "        , pl.col('recall@20').mean()\n",
    "        , pl.col('recall@100').mean()\n",
    "        , pl.col('recall@all').mean()\n",
    "\n",
    "    ).collect()\n",
    "final_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Candidate Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate_pl  = w2v_rec(target_df=test_pl,\n",
    "                   w2vec=w2vec, annoy_index=annoy_index, topn=100)\n",
    "train_candidate_pl  = w2v_rec(target_df=train_pl,\n",
    "                   w2vec=w2vec, annoy_index=annoy_index, topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 59min 55s, sys: 53.8 s, total: 2h 49s\n",
      "Wall time: 2h 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_candidate_pl = train_candidate_pl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 37s, sys: 4.15 s, total: 11min 41s\n",
      "Wall time: 11min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_candidate_pl = test_candidate_pl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_id</th><th>next_item_prediction</th></tr><tr><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>0</td><td>[&quot;B09JSPLN1M&quot;, &quot;B09W9FND7K&quot;, â€¦ &quot;B088TJJQHG&quot;]</td></tr><tr><td>1</td><td>[&quot;B08D9SVRFS&quot;, &quot;B084WZYCW3&quot;, â€¦ &quot;B06ZYCTQ3S&quot;]</td></tr><tr><td>2</td><td>[&quot;B0B1LGXWDS&quot;, &quot;B00AZYORS2&quot;, â€¦ &quot;B092JDH72P&quot;]</td></tr><tr><td>5</td><td>[&quot;B0749RNHRY&quot;, &quot;B0749V8TC7&quot;, â€¦ &quot;B07T22XJG2&quot;]</td></tr><tr><td>6</td><td>[&quot;B09SMK3R8H&quot;, &quot;B01N4ND0F9&quot;, â€¦ &quot;B07HTMYH43&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ session_id â”† next_item_prediction              â”‚\n",
       "â”‚ ---        â”† ---                               â”‚\n",
       "â”‚ i64        â”† list[str]                         â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0          â”† [\"B09JSPLN1M\", \"B09W9FND7K\", â€¦ \"â€¦ â”‚\n",
       "â”‚ 1          â”† [\"B08D9SVRFS\", \"B084WZYCW3\", â€¦ \"â€¦ â”‚\n",
       "â”‚ 2          â”† [\"B0B1LGXWDS\", \"B00AZYORS2\", â€¦ \"â€¦ â”‚\n",
       "â”‚ 5          â”† [\"B0749RNHRY\", \"B0749V8TC7\", â€¦ \"â€¦ â”‚\n",
       "â”‚ 6          â”† [\"B09SMK3R8H\", \"B01N4ND0F9\", â€¦ \"â€¦ â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_candidate_pl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl.write_parquet(eval_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_pl.write_parquet(train_cg_file)\n",
    "test_candidate_pl.write_parquet(test_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprocess_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def i2i(df):\n",
    "#     pl_df = pl.from_dataframe(df)\n",
    "#     pl_df = (\n",
    "#         pl_df\n",
    "#             .with_columns(pl.col('prev_items').apply(lambda row: get_rec(row, annoy_index=annoy_index, topn=100)).alias('next_item_prediction'))\n",
    "#     )\n",
    "#     return pl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# def pd_get_rec(df, w2vec, annoy_index, topn):\n",
    "#     next_item_prediction_lst = []\n",
    "#     for a in tqdm(df.iterrows(), total=len(df)):\n",
    "#         prev_items = a[1]['prev_items']\n",
    "#         res = [ele.replace('[', '').replace(']', '').replace('\\n', '').replace(\"'\", '').replace(' ', '') for ele in prev_items.split(' ')]\n",
    "#         # print(type(res))\n",
    "#         similarity_dic = w2vec.wv.most_similar(positive=res, topn=topn, indexer=annoy_index)\n",
    "#         res = [item for item, simi in similarity_dic]\n",
    "#         next_item_prediction_lst.append(res)\n",
    "#     df['next_item_prediction'] = next_item_prediction_lst\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNB90dXKlZkR",
    "tags": []
   },
   "source": [
    "# Validate predictions âœ… ğŸ˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_pl.join(test_candidate_pl.lazy(), how='left', on='session_id').collect()[['locale', 'next_item_prediction']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FJA368Gzguk7"
   },
   "outputs": [],
   "source": [
    "check_predictions(predictions, test_sessions=test_pl.collect().to_pandas(), \n",
    "                  # check_products=True, product_df=products\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1dTvU5VOgv0j"
   },
   "outputs": [],
   "source": [
    "# Its important that the parquet file you submit is saved with pyarrow backend\n",
    "predictions.to_parquet(submit_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submit_task1_w2v_v3_True_top100.parquet'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVrZ_TfnjL09",
    "tags": []
   },
   "source": [
    "## Submit to AIcrowd ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "rd9OYWEgixPZ"
   },
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "# !aicrowd submission create -c task-1-next-product-recommendation -f {submit_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als_model.pkl  itemid2item.json  user_item.npz\n"
     ]
    }
   ],
   "source": [
    "# ! ls {file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "kdd_2023",
   "name": "common-cu110.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m104"
  },
  "kernelspec": {
   "display_name": "py3.8(kdd_2023)",
   "language": "python",
   "name": "kdd_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
