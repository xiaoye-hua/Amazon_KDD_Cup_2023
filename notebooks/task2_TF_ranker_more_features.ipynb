{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA00wBE2Ntdm"
   },
   "source": [
    "## Packages\n",
    "\n",
    "Install and import the TF-Ranking library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6yzAaM85Z12D"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-ranking\n",
    "# !pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n3oYt3R6Nr9l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:25:30.371170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/implicit/gpu/__init__.py:13: UserWarning: CUDA extension is built, but disabling GPU support because of 'Cuda Error: no CUDA-capable device is detected (/project/./implicit/gpu/utils.h:71)'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "base_dir = '../'\n",
    "sys.path.append(base_dir)\n",
    "import os\n",
    "from utils import *\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from src.eval import model_eval\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.similarities.annoy import AnnoyIndexer\n",
    "\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "import polars as pl\n",
    "import implicit\n",
    "from src.eval import model_eval\n",
    "\n",
    "import scipy.sparse as sps\n",
    "from utils import str2list\n",
    "from src.config import raw_data_session_id_dir, candidate_file_name\n",
    "from lightgbm import LGBMRanker\n",
    "from lightgbm import early_stopping\n",
    "from utils import *\n",
    "from src.case_analysis import show_single_case\n",
    "# try github \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "task = 'task2'\n",
    "\n",
    "topn = 100\n",
    "version = 'v3'\n",
    "# # target locales: locales needed for task1\n",
    "if task == 'task1':\n",
    "    target_locals = [\"DE\", 'JP', 'UK']\n",
    "elif task == 'task2':\n",
    "    target_locals = ['ES', 'FR', 'IT']\n",
    "else:\n",
    "    assert 1 == 2\n",
    "    \n",
    "    \n",
    "eval_frac = 0.1\n",
    "\n",
    "\n",
    "ranker_train_data_dir = f'../data/rank_train_data_{task}_{version}'\n",
    "\n",
    "rank_model_version = f'{task}_rank_tf_{version}'\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "if debug:\n",
    "    epochs = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if debug:\n",
    "    SAMPLE_NUM = 3000\n",
    "else:\n",
    "    SAMPLE_NUM = -1\n",
    "\n",
    "candidate_path = '../data/candidates/'\n",
    "model_dir = '../model_training'\n",
    "\n",
    "\n",
    "w2v_model_version = f'w2v_{task}'\n",
    "nic_model_version = f'nic_{task}'\n",
    "\n",
    "rank_model_dir = os.path.join(model_dir, rank_model_version)\n",
    "model_for_eval = True\n",
    "# w2v_topn=100\n",
    "# nic_topn=100\n",
    "# PREDS_PER_SESSION = 100\n",
    "\n",
    "# num_tree = 100\n",
    "\n",
    "# submit_file = f'submission_{task}_ALS.parquet'\n",
    "num_tree = 100\n",
    "w2v_model_dir = os.path.join(model_dir, w2v_model_version)\n",
    "w2v_model_file = os.path.join(w2v_model_dir, f\"{model_for_eval}.model\")\n",
    "annoy_index_file = os.path.join(w2v_model_dir, f\"{str(num_tree)}_{model_for_eval}.index\")\n",
    "\n",
    "\n",
    "sub_file = f'../data/sub_files/{rank_model_version}.parque'\n",
    "eval_sub_file = f'../data/sub_files/eval_{rank_model_version}.parque'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_needed = ['session_id', 'next_item_prediction', 'target']\n",
    "\n",
    "\n",
    "user_col = 'session_id'\n",
    "item_col = 'next_item_prediction'\n",
    "\n",
    "# target_session_id = [3273855,\n",
    "#  3273726,\n",
    "#  3272767,\n",
    "#  3273728,\n",
    "#  3273277,\n",
    "#  3273790,\n",
    "#  3273536,\n",
    "#  3273022,\n",
    "#  3273216,\n",
    "#  3273663,\n",
    "#  3273727,\n",
    "#  3272766,\n",
    "#  3273343,\n",
    "#  3273664,\n",
    "#  3273599,\n",
    "#  3273342,\n",
    "#  3273598,\n",
    "#  3273919,\n",
    "#  3273344,\n",
    "#  3273470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if debug:\n",
    "    \n",
    "    eval_pl = (pl.scan_parquet(os.path.join(base_dir,\n",
    "                                           raw_data_session_id_dir,\n",
    "                                           'sessions_eval.parquet')).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "                  .head(SAMPLE_NUM)\n",
    "              )\n",
    "\n",
    "    test_pl = (pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, f'sessions_test_{task}.parquet'), ).with_columns(pl.col('prev_items').apply(str2list))\n",
    "               .head(SAMPLE_NUM)\n",
    "              )\n",
    "    # test4task3_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task3.parquet'), ).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list)).head(SAMPLE_NUM)\n",
    "\n",
    "    train_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'train/' '*.parquet'), ).head(SAMPLE_NUM)\n",
    "                           .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                       )\n",
    "    eval_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'eval.parquet'), ).head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    test_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test.parquet'), ).head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    # test4task3_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test4task3.parquet'), ).head(SAMPLE_NUM)\n",
    "    #                             .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "    #                         )\n",
    "else:\n",
    "    eval_pl = (pl.scan_parquet(os.path.join(base_dir,\n",
    "                                           raw_data_session_id_dir,\n",
    "                                           'sessions_eval.parquet')).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "                  # .head(SAMPLE_NUM)\n",
    "              )\n",
    "\n",
    "    test_pl = (pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, f'sessions_test_{task}.parquet'), ).with_columns(pl.col('prev_items').apply(str2list))\n",
    "               # .head(SAMPLE_NUM)\n",
    "              )\n",
    "    # test4task3_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task3.parquet'), ).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list)).head(SAMPLE_NUM)\n",
    "\n",
    "    train_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'train/' '*.parquet'), )\n",
    "                            # .head(SAMPLE_NUM)\n",
    "                           .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                       )\n",
    "    eval_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'eval.parquet'), )\n",
    "                       # .head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    test_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test.parquet'), )\n",
    "                       # .head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    # test4task3_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test4task3.parquet'), ).head(SAMPLE_NUM)\n",
    "    #                             .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "    #                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_data(target_pl,  feature_cols=[]):\n",
    "    train_df = target_pl.collect().to_pandas()\n",
    "    print(f\"train: {train_df.shape}\")\n",
    "    print(train_df['target'].value_counts())\n",
    "    cols_needed = ['user_rating', 'user_id', 'movie_title']+feature_cols\n",
    "    train_df = train_df.rename(columns={\n",
    "\n",
    "        'session_id': 'user_id'\n",
    "        , 'next_item_prediction': 'movie_title'\n",
    "        , 'target': 'user_rating'\n",
    "    })\n",
    "    ratings = tf.data.Dataset.from_tensor_slices(dict(train_df[cols_needed]))\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def get_dataset(ratings, user_ids_vocabulary):\n",
    "    key_func = lambda x: user_ids_vocabulary(x[\"user_id\"])\n",
    "    reduce_func = lambda key, dataset: dataset.batch(100)\n",
    "    ds_train = ratings.group_by_window(\n",
    "        key_func=key_func, reduce_func=reduce_func, window_size=100)\n",
    "\n",
    "    def _features_and_labels(\n",
    "        x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "      labels = x.pop(\"user_rating\")\n",
    "      return x, labels\n",
    "\n",
    "    ds_train = ds_train.map(_features_and_labels)\n",
    "\n",
    "    ds_train = ds_train.apply(\n",
    "        tf.data.experimental.dense_to_ragged_batch(batch_size=32))\n",
    "    return ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product: (137541, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:25:50.608596: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "product_df = (\n",
    "    pl.scan_parquet('../data/raw_data_session_id/products_train.parquet')\n",
    ").filter(pl.col('locale').is_in(target_locals)).collect().to_pandas()\n",
    "print(f\"product: {product_df.shape}\")\n",
    "\n",
    "product_df = product_df.rename(columns={\n",
    "    \n",
    "    'id': 'movie_title'\n",
    "\n",
    "})\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(product_df[['movie_title']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_features = pl.scan_parquet('../data/session_item_features/session_features.parquet')\n",
    "item_features = pl.scan_parquet('../data/session_item_features/item_features.parquet')\n",
    "product_pl = (pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, \n",
    "                                          'products_train.parquet'))\n",
    "                  # .with_columns(\n",
    "                  #     pl.when(pl.col('locale')=='DE').then(1).when(pl.col('locale')=='DE')\n",
    "                  #       .then(2)\n",
    "                  #       .otherwise(3).alias('locale')\n",
    "                  # )\n",
    "             )\n",
    "\n",
    "def get_additional_feature(data_pl, session_features=session_features, product_pl=product_pl, item_features=item_features):\n",
    "    session_join_keys = ['session_id']\n",
    "    session_fea_cols = ['mean_price', 'last_price', 'min_price', 'max_price']\n",
    "    data_pl = (\n",
    "        data_pl\n",
    "         .with_columns(\n",
    "            pl.col('session_id').cast(pl.Int64)\n",
    "        )\n",
    "        .join(session_features.select(session_join_keys+session_fea_cols+['locale']),\n",
    "                                    how='left', on=session_join_keys, suffix='_str')\n",
    "            .join(item_features, how='left',\n",
    "                  left_on='next_item_prediction',\n",
    "                  right_on='prev_items')\n",
    "            .join(product_pl.select(['id', 'locale', 'price']), how='left', right_on=['id', 'locale']\n",
    "                 , left_on=['next_item_prediction', 'locale_str'])\n",
    "            .with_columns(\n",
    "              pl.col('price').truediv(pl.col('mean_price')).alias('price_mean_norm')\n",
    "              , pl.col('price').truediv(pl.col('last_price')).alias('price_last_norm')\n",
    "              , pl.col('price').truediv(pl.col('min_price')).alias('price_min_norm')\n",
    "              , pl.col('price').truediv(pl.col('max_price')).alias('price_max_norm')\n",
    "              # , pl.when(pl.col('min_price')==pl.col('max_price')).then(1).otherwise((pl.col('price')-pl.col('min_price'))/(pl.col('min_price')-pl.col('max_price'))).alias('price_norm')\n",
    "            )\n",
    "            .select(\n",
    "                pl.all().exclude(session_fea_cols+['locale_str', 'price'])\n",
    "            )\n",
    "\n",
    "    )\n",
    "    return data_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_candidates = get_additional_feature(data_pl=train_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 66)\n",
      "┌──────────┬────────────┬──────────┬───────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ session_ ┆ next_item_ ┆ w2v_weig ┆ whether_w ┆ … ┆ price_mean ┆ price_last ┆ price_min_ ┆ price_max_ │\n",
      "│ id       ┆ prediction ┆ ht       ┆ 2v        ┆   ┆ _norm      ┆ _norm      ┆ norm       ┆ norm       │\n",
      "│ ---      ┆ ---        ┆ ---      ┆ ---       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│ i64      ┆ str        ┆ f64      ┆ i64       ┆   ┆ f64        ┆ f64        ┆ f64        ┆ f64        │\n",
      "╞══════════╪════════════╪══════════╪═══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ 3272766  ┆ B09C5VHGBZ ┆ 0.0      ┆ 0         ┆ … ┆ 0.633813   ┆ 0.5        ┆ 1.0        ┆ 0.5        │\n",
      "│ 3272766  ┆ B09FZ8ZZB2 ┆ 1.0      ┆ 1         ┆ … ┆ null       ┆ null       ┆ null       ┆ null       │\n",
      "│ 3272766  ┆ B09D3D8YR6 ┆ 0.21     ┆ 1         ┆ … ┆ 0.704315   ┆ 0.555617   ┆ 1.111235   ┆ 0.555617   │\n",
      "│ 3272766  ┆ B0B6W2CXN7 ┆ 0.01     ┆ 1         ┆ … ┆ null       ┆ null       ┆ null       ┆ null       │\n",
      "│ 3272766  ┆ B09G6JM5WM ┆ 0.0      ┆ 0         ┆ … ┆ 0.915821   ┆ 0.722469   ┆ 1.444939   ┆ 0.722469   │\n",
      "└──────────┴────────────┴──────────┴───────────┴───┴────────────┴────────────┴────────────┴────────────┘\n",
      "{'session_id': Int64, 'next_item_prediction': Utf8, 'w2v_weight': Float64, 'whether_w2v': Int64, 'whether_nic': Int64, 'whether_nicnic': Int64, 'whether_nfi': Int64, 'whether_covisit': Int64, 'strategy_num': Int64, 'nicnic_weight': Float64, 'next_item': Utf8, 'locale': Float64, 'prev_length': Float64, 'rec_num': Float64, 'target': Float64, 'next_item_weight': Float64, 'next_item_cnt': Float64, 'next_item_weight_nfi': Float32, 'next_item_normalized_weight': Float64, 'next_item_weight_co_visit': Float32, 'discount_weight': Float32, 'following_weight': Float32, 'following_discount_weight': Float32, 'previous_weight': Float32, 'previous_discount_weight': Float32, 'last_item_similarity': Float32, 'vec_0': Float64, 'vec_1': Float64, 'vec_2': Float64, 'vec_3': Float64, 'vec_4': Float64, 'vec_5': Float64, 'vec_6': Float64, 'vec_7': Float64, 'vec_8': Float64, 'vec_9': Float64, 'vec_10': Float64, 'vec_11': Float64, 'vec_12': Float64, 'vec_13': Float64, 'vec_14': Float64, 'vec_15': Float64, 'vec_16': Float64, 'vec_17': Float64, 'vec_18': Float64, 'vec_19': Float64, 'vec_20': Float64, 'vec_21': Float64, 'vec_22': Float64, 'vec_23': Float64, 'vec_24': Float64, 'vec_25': Float64, 'vec_26': Float64, 'vec_27': Float64, 'vec_28': Float64, 'vec_29': Float64, 'vec_30': Float64, 'vec_31': Float64, 'item_cnt': UInt32, 'pos_weighted_cnt': Float64, 'avg_pos': Float64, 'median_pos': Float64, 'price_mean_norm': Float64, 'price_last_norm': Float64, 'price_min_norm': Float64, 'price_max_norm': Float64}\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    print(target_train_candidates.head().collect())\n",
    "    print(target_train_candidates.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_train_candidates = train_candidates\n",
    "train_session_id = target_train_candidates.select(pl.col('session_id')).unique().collect()\n",
    "\n",
    "session_num = train_session_id.shape[0]\n",
    "random_pl = train_session_id.with_columns(\n",
    "        pl.Series(name='random', values=np.random.uniform(size=session_num))\n",
    ")\n",
    "train_candidates = target_train_candidates.join(random_pl.lazy(), how='left', on='session_id')\n",
    "\n",
    "sampled_train_candidates = train_candidates.filter(pl.col('random')>eval_frac).sort('session_id', descending=False).collect()\n",
    "sampled_eval_candidates = train_candidates.filter(pl.col('random')<=eval_frac).sort('session_id', descending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (3000, 59)\n",
      "target\n",
      "0.0    2979\n",
      "1.0      21\n",
      "Name: count, dtype: int64\n",
      "train: (2873, 59)\n",
      "target\n",
      "0.0    2853\n",
      "1.0      20\n",
      "Name: count, dtype: int64\n",
      "train: (127, 59)\n",
      "target\n",
      "0.0    126\n",
      "1.0      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_cols = ['next_item_normalized_weight']\n",
    "\n",
    "ratings = get_tensor_data(target_pl=train_candidates, feature_cols=feature_cols)\n",
    "sampled_train_dataset = get_tensor_data(target_pl=sampled_train_candidates.lazy(), feature_cols=feature_cols)\n",
    "sampled_eval_dataset = get_tensor_data(target_pl=sampled_eval_candidates.lazy(), feature_cols=feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_rating': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'3273343'>, 'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'B0068BBBIU'>, 'next_item_normalized_weight': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>}\n",
      "{'user_rating': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'3273343'>, 'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'B000CST6NM'>, 'next_item_normalized_weight': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>}\n",
      "{'user_rating': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'3273343'>, 'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'B09S6SXHS9'>, 'next_item_normalized_weight': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:31:13.582359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype double and shape [127]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    for row in sampled_eval_dataset.take(3):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9I1VTEjHzpfX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get user_id, item_id dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:31:22.547297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype double and shape [3000]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    }
   ],
   "source": [
    "users = ratings.map(lambda x: x[\"user_id\"])\n",
    "user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    mask_token=None)\n",
    "user_ids_vocabulary.adapt(users.batch(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:31:22.739105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [137541]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "movies = movies.map(lambda x: x[\"movie_title\"])\n",
    "movie_titles_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies.batch(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "B3wnNK1WG1lP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.string_lookup.StringLookup at 0x7fa665ed6580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMsmoqWTOTKo"
   },
   "source": [
    "Group by `user_id` to form lists for ranking models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXY7kX7nOSwH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "57r87tdQlkcT"
   },
   "outputs": [],
   "source": [
    "# for x in ds_train.take(1):\n",
    "#   for key, value in x.items():\n",
    "#     print(f\"Shape of {key}: {value.shape}\")\n",
    "#     print(f\"Example values of {key}: {value[:5].numpy()}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XV0tcpeIIdj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcZJf2qxOeWU"
   },
   "source": [
    "Generate batched features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctq2RTOqOfAo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/tmp/ipykernel_7692/2839463316.py:30: dense_to_ragged_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ragged_batch` instead.\n"
     ]
    }
   ],
   "source": [
    "ds_train = get_dataset(ratings=sampled_train_dataset, user_ids_vocabulary=user_ids_vocabulary)\n",
    "ds_eval = get_dataset(ratings=sampled_eval_dataset, user_ids_vocabulary=user_ids_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJUU3mv-_VdQ"
   },
   "source": [
    "The `user_id` and `movie_title` tensors generated in `ds_train` are of shape `[32, None]`, where the second dimension is 100 in most cases except for the batches when less than 100 items grouped in lists. A model working on ragged tensors is thus used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_eval = eval_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GTquqk1GkIfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_id: (32, None)\n",
      "Example values of user_id: [[b'3272766' b'3272766' b'3272766']\n",
      " [b'3272767' b'3272767' b'3272767']\n",
      " [b'3273022' b'3273022' b'3273022']]\n",
      "\n",
      "Shape of movie_title: (32, None)\n",
      "Example values of movie_title: [[b'B09C5VHGBZ' b'B09FZ8ZZB2' b'B09D3D8YR6']\n",
      " [b'B07WZZG98H' b'B01EA0NF8E' b'B00VYAWIRS']\n",
      " [b'B09L4BLSZR' b'B09NFHVKSG' b'B09J3LTNY7']]\n",
      "\n",
      "Shape of next_item_normalized_weight: (32, None)\n",
      "Example values of next_item_normalized_weight: [[0.42918456 0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "\n",
      "Shape of label: (32, None)\n",
      "Example values of label: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:31:28.639324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2873]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for x, label in ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_id: (2, None)\n",
      "Example values of user_id: [[b'3273343' b'3273343' b'3273343']\n",
      " [b'3273343' b'3273343' b'3273343']]\n",
      "\n",
      "Shape of movie_title: (2, None)\n",
      "Example values of movie_title: [[b'B0068BBBIU' b'B000CST6NM' b'B09S6SXHS9']\n",
      " [b'B08MZK2T5Q' b'B09QT5CBBG' b'B094YJZY98']]\n",
      "\n",
      "Shape of next_item_normalized_weight: (2, None)\n",
      "Example values of next_item_normalized_weight: [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "Shape of label: (2, None)\n",
      "Example values of label: [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:31:29.594556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [127]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for x, label in ds_eval.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrch6rVBOB9Q"
   },
   "source": [
    "## Define a model\n",
    "\n",
    "Define a ranking model by inheriting from `tf.keras.Model` and implementing the `call` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from abc import abstractmethod\n",
    "# from tensorflow.keras import Model\n",
    "# from typing import List\n",
    "\n",
    "\n",
    "\n",
    "# class DLModel(Model):\n",
    "#     def __init__(self):\n",
    "#         super(DLModel, self).__init__()\n",
    "#         self.layers_lst = []\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def call(self, inputs, training=None, mask=None):\n",
    "#         for layer in self.layers_lst:\n",
    "#             inputs = layer(inputs)\n",
    "#         return inputs\n",
    "\n",
    "# class DNN(DLModel):\n",
    "#     def __init__(self, hidden_dim: List[int], sigmoid=True) -> None:\n",
    "#         super(DNN, self).__init__()\n",
    "#         for dim in hidden_dim:\n",
    "#             self.layers_lst.append(\n",
    "#                 Dense(units=dim, use_bias=True)\n",
    "#             )\n",
    "#         self.sigmoid = sigmoid\n",
    "#         if self.sigmoid:\n",
    "#             self.layers_lst.append(\n",
    "#                 Activation(activation=\"sigmoid\")\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['next_item_normalized_weight']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "e5dNbDZwOIHR"
   },
   "outputs": [],
   "source": [
    "# class user_embedding(tf.keras.Model):\n",
    "    \n",
    "\n",
    "class MovieLensRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, user_vocab, movie_vocab):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie vocabulary and embedding.\n",
    "    self.user_vocab = user_vocab\n",
    "    self.movie_vocab = movie_vocab\n",
    "    self.user_embed = tf.keras.layers.Embedding(user_vocab.vocabulary_size(),\n",
    "                                                63)\n",
    "    self.movie_embed = tf.keras.layers.Embedding(movie_vocab.vocabulary_size(),\n",
    "                                                 64)\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    # Define how the ranking scores are computed: \n",
    "    # Take the dot-product of the user embeddings with the movie embeddings.\n",
    "    \n",
    "    new_features = features['next_item_normalized_weight']\n",
    "\n",
    "    user_embeddings = self.user_embed(self.user_vocab(features[\"user_id\"]))\n",
    "    \n",
    "    user_embeddings = tf.concat([user_embeddings, new_features], 1)\n",
    "    \n",
    "    movie_embeddings = self.movie_embed(\n",
    "        self.movie_vocab(features[\"movie_title\"]))\n",
    "\n",
    "    return tf.reduce_sum(user_embeddings * movie_embeddings, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMV0HpzmJGWk"
   },
   "source": [
    "Create the model, and then compile it with ranking `tfr.keras.losses` and `tfr.keras.metrics`, which are the core of the TF-Ranking package. \n",
    "\n",
    "This example uses a ranking-specific **softmax loss**, which is a listwise loss introduced to promote all relevant items in the ranking list with better chances on top of the irrelevant ones. In contrast to the softmax loss in the multi-class classification problem, where only one class is positive and the rest are negative, the TF-Ranking library supports multiple relevant documents in a query list and non-binary relevance labels.\n",
    "\n",
    "For ranking metrics, this example uses in specific **Normalized Discounted Cumulative Gain (NDCG)** and **Mean Reciprocal Rank (MRR)**, which calculate the user utility of a ranked query list with position discounts. For more details about ranking metrics, review evaluation measures [offline metrics](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Offline_metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_test(x, _):\n",
    "#     return x % 4 == 0\n",
    "\n",
    "\n",
    "# def is_train(x, y):\n",
    "#     return not is_test(x, y)\n",
    "\n",
    "\n",
    "# recover = lambda x, y: y\n",
    "\n",
    "# # Split the dataset for training.\n",
    "# test_dataset = ds_train.enumerate() \\\n",
    "#     .filter(is_test) \\\n",
    "#     .map(recover)\n",
    "\n",
    "# # Split the dataset for testing/validation.\n",
    "# train_dataset = ds_train.enumerate() \\\n",
    "#     .filter(is_train) \\\n",
    "#     .map(recover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "83BiHSAxL07s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/tmp/__autograph_generated_file3rltb2w3.py\", line 12, in tf__call\n        user_embeddings = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(user_embeddings), ag__.ld(new_features)], 1), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'movie_lens_ranking_model_1' (type MovieLensRankingModel).\n    \n    in user code:\n    \n        File \"/var/tmp/ipykernel_7692/1559516397.py\", line 25, in call  *\n            user_embeddings = tf.concat([user_embeddings, new_features], 1)\n    \n        ValueError: Shape (None, None) must have rank 3\n    \n    \n    Call arguments received by layer 'movie_lens_ranking_model_1' (type MovieLensRankingModel):\n      • features={'user_id': 'tf.RaggedTensor(values=Tensor(\"RaggedFromVariant_2/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant_2/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))', 'movie_title': 'tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))', 'next_item_normalized_weight': 'tf.RaggedTensor(values=Tensor(\"movie_lens_ranking_model_1/Cast:0\", shape=(None,), dtype=float32), row_splits=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39meval_metrics)\n\u001b[1;32m     12\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     14\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     18\u001b[0m ]\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train_dataset,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# validation_split=0.1\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/tmp/__autograph_generated_filetomh9ape.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/tmp/__autograph_generated_file3rltb2w3.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     10\u001b[0m new_features \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(features)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_item_normalized_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m user_embeddings \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39muser_embed, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39muser_vocab, (ag__\u001b[38;5;241m.\u001b[39mld(features)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m user_embeddings \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mld(user_embeddings), ag__\u001b[38;5;241m.\u001b[39mld(new_features)], \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m movie_embeddings \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmovie_embed, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmovie_vocab, (ag__\u001b[38;5;241m.\u001b[39mld(features)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_title\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/jupyter/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/tmp/__autograph_generated_file3rltb2w3.py\", line 12, in tf__call\n        user_embeddings = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(user_embeddings), ag__.ld(new_features)], 1), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'movie_lens_ranking_model_1' (type MovieLensRankingModel).\n    \n    in user code:\n    \n        File \"/var/tmp/ipykernel_7692/1559516397.py\", line 25, in call  *\n            user_embeddings = tf.concat([user_embeddings, new_features], 1)\n    \n        ValueError: Shape (None, None) must have rank 3\n    \n    \n    Call arguments received by layer 'movie_lens_ranking_model_1' (type MovieLensRankingModel):\n      • features={'user_id': 'tf.RaggedTensor(values=Tensor(\"RaggedFromVariant_2/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant_2/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))', 'movie_title': 'tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))', 'next_item_normalized_weight': 'tf.RaggedTensor(values=Tensor(\"movie_lens_ranking_model_1/Cast:0\", shape=(None,), dtype=float32), row_splits=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss = tfr.keras.losses.MeanSquaredLoss(ragged=True)\n",
    "\n",
    "\n",
    "model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "eval_metrics = [\n",
    "    # tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True),\n",
    "]\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    # train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=ds_eval,\n",
    "    callbacks=callbacks\n",
    "          # validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZe-WXeVMI0R"
   },
   "outputs": [],
   "source": [
    "# # Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# # ranking metrics.\n",
    "\n",
    "# loss = tfr.keras.losses.PairwiseHingeLoss(ragged=True)\n",
    "\n",
    "\n",
    "# model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "# eval_metrics = [\n",
    "#     tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "#     tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "# ]\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "# model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2tQDhqkOKf1"
   },
   "outputs": [],
   "source": [
    "# # Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# # ranking metrics.\n",
    "\n",
    "# loss = tfr.keras.losses.get(\n",
    "#     loss=tfr.keras.losses.RankingLossKey.SOFTMAX_LOSS, ragged=True)\n",
    "\n",
    "# model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "# eval_metrics = [\n",
    "#     tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "#     tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "# ]\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "# model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5uuSRXZoOKW"
   },
   "source": [
    "Generate predictions and evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model eval function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_rec(candidate_pl, model, topn=100, ground_truth_included=False):\n",
    "    candidate_pl = candidate_pl.collect().to_pandas()\n",
    "    print(f\"candidate pl shape: {candidate_pl.shape}\")\n",
    "\n",
    "    user_tensor = tf.reshape(tf.convert_to_tensor(candidate_pl[user_col]), (1, -1))\n",
    "    item_tensor = tf.reshape(tf.convert_to_tensor(candidate_pl[item_col]), (1, -1))\n",
    "    new_inputs = {\n",
    "        \"user_id\":user_tensor\n",
    "            ,\n",
    "        \"movie_title\":item_tensor\n",
    "    }\n",
    "    output = model(new_inputs)\n",
    "\n",
    "    candidate_pl['predict'] = tf.squeeze(output, axis=0).numpy()\n",
    "\n",
    "\n",
    "    test_result = (\n",
    "        pl.from_pandas(candidate_pl)\n",
    "         .lazy()\n",
    "         # .with_columns(\n",
    "         #     pl.col(item_col).alias('next_item_prediction')\n",
    "         #     , pl.col(user_col).alias('session_id').cast(pl.Int64)\n",
    "         # )\n",
    "         .with_columns(\n",
    "            pl.col('predict').rank(method='ordinal', descending=True).over('session_id').alias('rank')\n",
    "         )\n",
    "         .sort(['session_id', 'rank'])\n",
    "         .filter(pl.col('rank')<=topn)\n",
    "    )\n",
    "    if ground_truth_included:\n",
    "        test_result = (\n",
    "            test_result         \n",
    "            .groupby(['session_id'])\n",
    "             .agg(\n",
    "                 pl.col('next_item_prediction')\n",
    "                 , pl.col('next_item').unique()#.arr.get(0).cast(pl.Utf8)\n",
    "             ).with_columns(\n",
    "                 pl.col('next_item').arr.get(0).alias('next_item')\n",
    "                 , pl.col(user_col).cast(pl.Int64)\n",
    "             )\n",
    "        )\n",
    "    else:\n",
    "        test_result = (\n",
    "            test_result         \n",
    "            .groupby(['session_id'])\n",
    "             .agg(\n",
    "                 pl.col('next_item_prediction')\n",
    "             ).with_columns(\n",
    "                 pl.col(user_col).cast(pl.Int64)\n",
    "             )\n",
    "        )\n",
    "    return test_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_eval_pl = rank_rec(candidate_pl=eval_candidates\n",
    "                        , model=model\n",
    "                          , topn=topn\n",
    "                          , ground_truth_included=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_eval_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(eval_pl.join(ranker_eval_pl.lazy(), how='left', on='session_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate pl shape: (3000, 56)\n"
     ]
    }
   ],
   "source": [
    "test_result = rank_rec(candidate_pl=test_candidates\n",
    "                        , model=model\n",
    "                          , topn=topn\n",
    "                           , ground_truth_included=False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_id</th><th>next_item_prediction</th></tr><tr><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>4331307</td><td>[&quot;B0B56NWXYH&quot;, &quot;B09Z1VH85Q&quot;, … &quot;B09N7R5P99&quot;]</td></tr><tr><td>4331319</td><td>[&quot;B09Z1VH85Q&quot;, &quot;B084J38SRL&quot;, … &quot;B019GJLER8&quot;]</td></tr><tr><td>4331312</td><td>[&quot;B011EI9PKW&quot;, &quot;B09WMK1RP4&quot;, … &quot;B07Y7YLB7Z&quot;]</td></tr><tr><td>4331311</td><td>[&quot;B09XP9BXV2&quot;, &quot;B08T9RDVMT&quot;, … &quot;B09MSB4X2G&quot;]</td></tr><tr><td>4331313</td><td>[&quot;B008SO7JZ4&quot;, &quot;B09FKWS793&quot;, … &quot;B07S3BJ294&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬───────────────────────────────────┐\n",
       "│ session_id ┆ next_item_prediction              │\n",
       "│ ---        ┆ ---                               │\n",
       "│ i64        ┆ list[str]                         │\n",
       "╞════════════╪═══════════════════════════════════╡\n",
       "│ 4331307    ┆ [\"B0B56NWXYH\", \"B09Z1VH85Q\", … \"… │\n",
       "│ 4331319    ┆ [\"B09Z1VH85Q\", \"B084J38SRL\", … \"… │\n",
       "│ 4331312    ┆ [\"B011EI9PKW\", \"B09WMK1RP4\", … \"… │\n",
       "│ 4331311    ┆ [\"B09XP9BXV2\", \"B08T9RDVMT\", … \"… │\n",
       "│ 4331313    ┆ [\"B008SO7JZ4\", \"B09FKWS793\", … \"… │\n",
       "└────────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = test_pl.join(test_result, how='left', on='session_id').collect()[['locale', 'next_item_prediction']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pl = (\n",
    "    test_pl.join(test_result, how='left', on='session_id')\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('next_item_prediction').is_null())\n",
    "                .then(pl.col('prev_items'))\n",
    "                .otherwise(pl.col('next_item_prediction')).alias('next_item_prediction')\n",
    "        )\n",
    ").collect()\n",
    "\n",
    "predictions = (predictions_pl[['locale', 'next_item_prediction']].to_pandas())\n",
    "prediction_summary = (\n",
    "    predictions_pl\n",
    "        .explode('next_item_prediction')\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').is_null().alias('whether_null')\n",
    "        )\n",
    "        .groupby('session_id')\n",
    "        .agg(\n",
    "            pl.col('whether_null').sum().alias('null_num')\n",
    "            , pl.count().alias('rec_num')\n",
    "        )\n",
    ")\n",
    "assert (\n",
    "    prediction_summary.filter(pl.col('null_num')>0)\n",
    ").shape[0] == 0\n",
    "\n",
    "\n",
    "check_predictions(predictions, test_sessions=test_pl.collect().to_pandas(), \n",
    "                  # check_products=True, product_df=products\n",
    "                 )\n",
    "# Its important that the parquet file you submit is saved with pyarrow backend\n",
    "\n",
    "assert (\n",
    "    pl.from_pandas(predictions)\n",
    "        .explode('next_item_prediction')\n",
    "        .filter(\n",
    "            pl.col('next_item_prediction').is_null()\n",
    "                     )\n",
    ").shape[0] == 0\n",
    "assert predictions.shape[0] == test_pl.collect().shape[0]\n",
    "if not debug:\n",
    "    predictions.to_parquet(sub_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 28918656 Jun 11 06:31 ../data/sub_files/task2_rank_tf_v3.parque\n"
     ]
    }
   ],
   "source": [
    "! ls -al {sub_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aicrowd submission create -c task-2-next-product-recommendation-for-underrepresented-languages -f {sub_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erdwpzZlMw5i",
    "tags": []
   },
   "source": [
    "# Ranking pipeline example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to [github page](https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/tf_ranking_canned_dnn.py) for more details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copyright 2022 The TensorFlow Ranking Authors.\n",
    "# #\n",
    "# # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# # you may not use this file except in compliance with the License.\n",
    "# # You may obtain a copy of the License at\n",
    "# #\n",
    "# #     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# #\n",
    "# # Unless required by applicable law or agreed to in writing, software\n",
    "# # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# # See the License for the specific language governing permissions and\n",
    "# # limitations under the License.\n",
    "\n",
    "# r\"\"\"TF-Ranking example code for training a canned DNN estimator.\n",
    "\n",
    "# The supported proto formats are listed at ../python/data.py.\n",
    "# --------------------------------------------------------------------------------\n",
    "# Sample command lines:\n",
    "\n",
    "# MODEL_DIR=/tmp/output && \\\n",
    "# TRAIN=tensorflow_ranking/examples/data/train_numerical_elwc.tfrecord && \\\n",
    "# EVAL=tensorflow_ranking/examples/data/vali_numerical_elwc.tfrecord && \\\n",
    "# rm -rf $MODEL_DIR && \\\n",
    "# bazel build -c opt \\\n",
    "# tensorflow_ranking/examples/tf_ranking_canned_dnn_py_binary && \\\n",
    "# ./bazel-bin/tensorflow_ranking/examples/tf_ranking_canned_dnn_py_binary \\\n",
    "# --train_input_pattern=$TRAIN \\\n",
    "# --eval_input_pattern=$EVAL \\\n",
    "# --model_dir=$MODEL_DIR\n",
    "\n",
    "# You can use TensorBoard to display the training results stored in $MODEL_DIR.\n",
    "\n",
    "# Notes:\n",
    "#   * Use --alsologtostderr if the output is not printed into screen.\n",
    "# \"\"\"\n",
    "\n",
    "# from absl import flags\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_ranking as tfr\n",
    "\n",
    "# flags.DEFINE_string(\"train_input_pattern\", None,\n",
    "#                     \"Input file path used for training.\")\n",
    "# flags.DEFINE_string(\"eval_input_pattern\", None,\n",
    "#                     \"Input file path used for eval.\")\n",
    "# flags.DEFINE_string(\"model_dir\", None, \"Output directory for models.\")\n",
    "# flags.DEFINE_integer(\"batch_size\", 32, \"The batch size for train.\")\n",
    "# flags.DEFINE_integer(\"num_train_steps\", 15000, \"Number of steps for train.\")\n",
    "# flags.DEFINE_integer(\"num_eval_steps\", 10, \"Number of steps for evaluation.\")\n",
    "# flags.DEFINE_integer(\"checkpoint_secs\", 30,\n",
    "#                      \"Saves a model checkpoint every checkpoint_secs seconds.\")\n",
    "# flags.DEFINE_integer(\"num_checkpoints\", 100,\n",
    "#                      \"Saves at most num_checkpoints checkpoints in workspace.\")\n",
    "# flags.DEFINE_integer(\"num_features\", 136, \"Number of features per example.\")\n",
    "# flags.DEFINE_integer(\n",
    "#     \"list_size\", 100,\n",
    "#     \"List size used for training. Use None for dynamic list size.\")\n",
    "# flags.DEFINE_float(\"learning_rate\", 0.05, \"Learning rate for optimizer.\")\n",
    "# flags.DEFINE_float(\"dropout\", 0.8, \"The dropout rate before output layer.\")\n",
    "# flags.DEFINE_list(\"hidden_layer_dims\", [\"64\", \"32\", \"16\"],\n",
    "#                   \"Sizes for hidden layers.\")\n",
    "# flags.DEFINE_string(\"loss\", \"approx_ndcg_loss\",\n",
    "#                     \"The RankingLossKey for the loss function.\")\n",
    "# flags.DEFINE_bool(\"convert_labels_to_binary\", False,\n",
    "#                   \"If true, relevance labels are set to either 0 or 1.\")\n",
    "# flags.DEFINE_bool(\"listwise_inference\", False,\n",
    "#                   \"If true, exports accept `data_format` while serving.\")\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# _LABEL_FEATURE = \"utility\"\n",
    "\n",
    "\n",
    "# def context_feature_columns():\n",
    "#   \"\"\"Returns context feature columns.\"\"\"\n",
    "#   return {}\n",
    "\n",
    "\n",
    "# def example_feature_columns():\n",
    "#   \"\"\"Returns the example feature columns.\"\"\"\n",
    "#   feature_names = [\n",
    "#       \"custom_features_{}\".format(i + 1) for i in range(FLAGS.num_features)\n",
    "#   ]\n",
    "#   return {\n",
    "#       name:\n",
    "#       tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "#       for name in feature_names\n",
    "#   }\n",
    "\n",
    "\n",
    "# def train_and_eval():\n",
    "#   \"\"\"Train and Evaluate.\"\"\"\n",
    "#   optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "#       learning_rate=FLAGS.learning_rate)\n",
    "\n",
    "#   estimator = tfr.estimator.make_dnn_ranking_estimator(\n",
    "#       example_feature_columns(),\n",
    "#       FLAGS.hidden_layer_dims,\n",
    "#       context_feature_columns=context_feature_columns(),\n",
    "#       optimizer=optimizer,\n",
    "#       learning_rate=FLAGS.learning_rate,\n",
    "#       loss=FLAGS.loss,\n",
    "#       loss_reduction=tf.compat.v1.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "#       activation_fn=tf.nn.relu,\n",
    "#       dropout=FLAGS.dropout,\n",
    "#       use_batch_norm=True,\n",
    "#       model_dir=FLAGS.model_dir)\n",
    "\n",
    "#   hparams = {\"train_input_pattern\": FLAGS.train_input_pattern,\n",
    "#              \"eval_input_pattern\": FLAGS.eval_input_pattern,\n",
    "#              \"learning_rate\": FLAGS.learning_rate,\n",
    "#              \"train_batch_size\": FLAGS.batch_size,\n",
    "#              \"eval_batch_size\": FLAGS.batch_size,\n",
    "#              \"predict_batch_size\": FLAGS.batch_size,\n",
    "#              \"num_train_steps\": FLAGS.num_train_steps,\n",
    "#              \"num_eval_steps\": FLAGS.num_eval_steps,\n",
    "#              \"checkpoint_secs\": FLAGS.checkpoint_secs,\n",
    "#              \"num_checkpoints\": FLAGS.num_checkpoints,\n",
    "#              \"loss\": FLAGS.loss,\n",
    "#              \"list_size\": FLAGS.list_size,\n",
    "#              \"convert_labels_to_binary\": FLAGS.convert_labels_to_binary,\n",
    "#              \"listwise_inference\": FLAGS.listwise_inference,\n",
    "#              \"model_dir\": FLAGS.model_dir}\n",
    "\n",
    "#   ranking_pipeline = tfr.ext.pipeline.RankingPipeline(\n",
    "#       context_feature_columns(),\n",
    "#       example_feature_columns(),\n",
    "#       hparams,\n",
    "#       estimator=estimator,\n",
    "#       label_feature_name=_LABEL_FEATURE,\n",
    "#       label_feature_type=tf.int64)\n",
    "\n",
    "#   ranking_pipeline.train_and_eval()\n",
    "\n",
    "\n",
    "# def main(_):\n",
    "#   tf.compat.v1.set_random_seed(1234)\n",
    "#   tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "#   train_and_eval()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   flags.mark_flag_as_required(\"train_input_pattern\")\n",
    "#   flags.mark_flag_as_required(\"eval_input_pattern\")\n",
    "#   flags.mark_flag_as_required(\"model_dir\")\n",
    "\n",
    "#   tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copyright 2022 The TensorFlow Ranking Authors.\n",
    "# #\n",
    "# # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# # you may not use this file except in compliance with the License.\n",
    "# # You may obtain a copy of the License at\n",
    "# #\n",
    "# #     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# #\n",
    "# # Unless required by applicable law or agreed to in writing, software\n",
    "# # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# # See the License for the specific language governing permissions and\n",
    "# # limitations under the License.\n",
    "\n",
    "# \"\"\"Tests for tf_ranking_canned_dnn.py.\"\"\"\n",
    "\n",
    "# import os\n",
    "\n",
    "# from absl import flags\n",
    "# from absl.testing import flagsaver\n",
    "# from absl.testing import parameterized\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from google.protobuf import text_format\n",
    "# from tensorflow_ranking.examples import tf_ranking_canned_dnn\n",
    "# from tensorflow_serving.apis import input_pb2\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# ELWC = text_format.Parse(\n",
    "#     \"\"\"\n",
    "#     context {\n",
    "#     }\n",
    "#     examples {\n",
    "#       features {\n",
    "#         feature {\n",
    "#           key: \"custom_features_1\"\n",
    "#           value { float_list { value: 1.0 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"custom_features_2\"\n",
    "#           value { float_list { value: 1.5 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"utility\"\n",
    "#           value { int64_list { value: 1 } }\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "#     examples {\n",
    "#       features {\n",
    "#         feature {\n",
    "#           key: \"custom_features_1\"\n",
    "#           value { float_list { value: 1.0 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"custom_features_3\"\n",
    "#           value { float_list { value: 2.1 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"utility\"\n",
    "#           value { int64_list { value: 0 } }\n",
    "#         }\n",
    "#       }\n",
    "#     }\"\"\", input_pb2.ExampleListWithContext())\n",
    "\n",
    "\n",
    "# def _write_tfrecord_files(path):\n",
    "#   elwc_list = [ELWC.SerializeToString()] * 10\n",
    "#   if tf.io.gfile.exists(path):\n",
    "#     tf.io.gfile.remove(path)\n",
    "\n",
    "#   with tf.io.TFRecordWriter(path) as writer:\n",
    "#     for elwc in elwc_list:\n",
    "#       writer.write(elwc)\n",
    "\n",
    "\n",
    "# class TFRankingCannedDNNTest(tf.test.TestCase, parameterized.TestCase):\n",
    "\n",
    "#   def setUp(self):\n",
    "#     super(TFRankingCannedDNNTest, self).setUp()\n",
    "#     tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#     # Prepares model directory, and train and eval data.\n",
    "#     self._base_model_dir = tf.compat.v1.test.get_temp_dir() + \"/model/\"\n",
    "#     tf.io.gfile.makedirs(self._base_model_dir)\n",
    "#     self._data_file = os.path.join(self._base_model_dir, \"elwc.tfrecord\")\n",
    "#     _write_tfrecord_files(self._data_file)\n",
    "\n",
    "#   def tearDown(self):\n",
    "#     super(TFRankingCannedDNNTest, self).tearDown()\n",
    "#     if self._base_model_dir:\n",
    "#       tf.io.gfile.rmtree(self._base_model_dir)\n",
    "#     self._base_model_dir = None\n",
    "\n",
    "#   @parameterized.named_parameters((\"enable_listwise_inference\", True),\n",
    "#                                   (\"disable_listwise_inference\", False))\n",
    "#   def test_train_and_eval(self, listwise_inference):\n",
    "#     self._model_dir = self._base_model_dir + \"/\" + str(listwise_inference)\n",
    "#     with flagsaver.flagsaver(\n",
    "#         train_input_pattern=self._data_file,\n",
    "#         eval_input_pattern=self._data_file,\n",
    "#         model_dir=self._model_dir,\n",
    "#         num_features=3,\n",
    "#         num_train_steps=10,\n",
    "#         listwise_inference=listwise_inference):\n",
    "#       tf_ranking_canned_dnn.train_and_eval()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   tf.test.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "kdd_2023",
   "name": "common-cu110.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m104"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "py3.8(kdd_2023)",
   "language": "python",
   "name": "kdd_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
