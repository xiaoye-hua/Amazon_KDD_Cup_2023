{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA00wBE2Ntdm"
   },
   "source": [
    "## Packages\n",
    "\n",
    "Install and import the TF-Ranking library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6yzAaM85Z12D"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-ranking\n",
    "# !pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "n3oYt3R6Nr9l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "base_dir = '../'\n",
    "sys.path.append(base_dir)\n",
    "import os\n",
    "from utils import *\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from src.eval import model_eval\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.similarities.annoy import AnnoyIndexer\n",
    "\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "import polars as pl\n",
    "import implicit\n",
    "from src.eval import model_eval\n",
    "\n",
    "import scipy.sparse as sps\n",
    "from utils import str2list\n",
    "from src.config import raw_data_session_id_dir, candidate_file_name\n",
    "from lightgbm import LGBMRanker\n",
    "from lightgbm import early_stopping\n",
    "from utils import *\n",
    "from src.case_analysis import show_single_case\n",
    "# try github \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "task = 'task2'\n",
    "\n",
    "topn = 100\n",
    "version = 'v3'\n",
    "# # target locales: locales needed for task1\n",
    "if task == 'task1':\n",
    "    target_locals = [\"DE\", 'JP', 'UK']\n",
    "elif task == 'task2':\n",
    "    target_locals = ['ES', 'FR', 'IT']\n",
    "else:\n",
    "    assert 1 == 2\n",
    "    \n",
    "    \n",
    "eval_frac = 0.1\n",
    "\n",
    "\n",
    "ranker_train_data_dir = f'../data/rank_train_data_{task}_{version}'\n",
    "\n",
    "rank_model_version = f'{task}_rank_tf_{version}'\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "if debug:\n",
    "    epochs = 4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if debug:\n",
    "    SAMPLE_NUM = 3000\n",
    "else:\n",
    "    SAMPLE_NUM = -1\n",
    "\n",
    "candidate_path = '../data/candidates/'\n",
    "model_dir = '../model_training'\n",
    "\n",
    "\n",
    "w2v_model_version = f'w2v_{task}'\n",
    "nic_model_version = f'nic_{task}'\n",
    "\n",
    "rank_model_dir = os.path.join(model_dir, rank_model_version)\n",
    "model_for_eval = True\n",
    "# w2v_topn=100\n",
    "# nic_topn=100\n",
    "# PREDS_PER_SESSION = 100\n",
    "\n",
    "# num_tree = 100\n",
    "\n",
    "# submit_file = f'submission_{task}_ALS.parquet'\n",
    "num_tree = 100\n",
    "w2v_model_dir = os.path.join(model_dir, w2v_model_version)\n",
    "w2v_model_file = os.path.join(w2v_model_dir, f\"{model_for_eval}.model\")\n",
    "annoy_index_file = os.path.join(w2v_model_dir, f\"{str(num_tree)}_{model_for_eval}.index\")\n",
    "\n",
    "\n",
    "sub_file = f'../data/sub_files/{rank_model_version}.parque'\n",
    "eval_sub_file = f'../data/sub_files/eval_{rank_model_version}.parque'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_needed = ['session_id', 'next_item_prediction', 'target']\n",
    "\n",
    "\n",
    "user_col = 'session_id'\n",
    "item_col = 'next_item_prediction'\n",
    "\n",
    "# target_session_id = [3273855,\n",
    "#  3273726,\n",
    "#  3272767,\n",
    "#  3273728,\n",
    "#  3273277,\n",
    "#  3273790,\n",
    "#  3273536,\n",
    "#  3273022,\n",
    "#  3273216,\n",
    "#  3273663,\n",
    "#  3273727,\n",
    "#  3272766,\n",
    "#  3273343,\n",
    "#  3273664,\n",
    "#  3273599,\n",
    "#  3273342,\n",
    "#  3273598,\n",
    "#  3273919,\n",
    "#  3273344,\n",
    "#  3273470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if debug:\n",
    "    \n",
    "    eval_pl = (pl.scan_parquet(os.path.join(base_dir,\n",
    "                                           raw_data_session_id_dir,\n",
    "                                           'sessions_eval.parquet')).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "                  .head(SAMPLE_NUM)\n",
    "              )\n",
    "\n",
    "    test_pl = (pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, f'sessions_test_{task}.parquet'), ).with_columns(pl.col('prev_items').apply(str2list))\n",
    "               .head(SAMPLE_NUM)\n",
    "              )\n",
    "    # test4task3_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task3.parquet'), ).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list)).head(SAMPLE_NUM)\n",
    "\n",
    "    train_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'train/' '*.parquet'), ).head(SAMPLE_NUM)\n",
    "                           .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                       )\n",
    "    eval_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'eval.parquet'), ).head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    test_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test.parquet'), ).head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    # test4task3_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test4task3.parquet'), ).head(SAMPLE_NUM)\n",
    "    #                             .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "    #                         )\n",
    "else:\n",
    "    eval_pl = (pl.scan_parquet(os.path.join(base_dir,\n",
    "                                           raw_data_session_id_dir,\n",
    "                                           'sessions_eval.parquet')).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "                  # .head(SAMPLE_NUM)\n",
    "              )\n",
    "\n",
    "    test_pl = (pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, f'sessions_test_{task}.parquet'), ).with_columns(pl.col('prev_items').apply(str2list))\n",
    "               # .head(SAMPLE_NUM)\n",
    "              )\n",
    "    # test4task3_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task3.parquet'), ).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list)).head(SAMPLE_NUM)\n",
    "\n",
    "    train_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'train/' '*.parquet'), )\n",
    "                            # .head(SAMPLE_NUM)\n",
    "                           .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                       )\n",
    "    eval_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'eval.parquet'), )\n",
    "                       # .head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    test_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test.parquet'), )\n",
    "                       # .head(SAMPLE_NUM)\n",
    "                          .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "                      )\n",
    "    # test4task3_candidates = (pl.scan_parquet(os.path.join(ranker_train_data_dir, 'test4task3.parquet'), ).head(SAMPLE_NUM)\n",
    "    #                             .with_columns(pl.col('session_id').cast(pl.Int32).cast(pl.Utf8))\n",
    "    #                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_data(target_pl):\n",
    "    train_df = target_pl.collect().to_pandas()\n",
    "    print(f\"train: {train_df.shape}\")\n",
    "    print(train_df['target'].value_counts())\n",
    "    cols_needed = ['user_rating', 'user_id', 'movie_title']\n",
    "    train_df = train_df.rename(columns={\n",
    "\n",
    "        'session_id': 'user_id'\n",
    "        , 'next_item_prediction': 'movie_title'\n",
    "        , 'target': 'user_rating'\n",
    "    })\n",
    "    ratings = tf.data.Dataset.from_tensor_slices(dict(train_df[cols_needed]))\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def get_dataset(ratings, user_ids_vocabulary):\n",
    "    key_func = lambda x: user_ids_vocabulary(x[\"user_id\"])\n",
    "    reduce_func = lambda key, dataset: dataset.batch(100)\n",
    "    ds_train = ratings.group_by_window(\n",
    "        key_func=key_func, reduce_func=reduce_func, window_size=100)\n",
    "\n",
    "    def _features_and_labels(\n",
    "        x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "      labels = x.pop(\"user_rating\")\n",
    "      return x, labels\n",
    "\n",
    "    ds_train = ds_train.map(_features_and_labels)\n",
    "\n",
    "    ds_train = ds_train.apply(\n",
    "        tf.data.experimental.dense_to_ragged_batch(batch_size=32))\n",
    "    return ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product: (137541, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:52:45.450275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-12 05:52:45.535098: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "product_df = (\n",
    "    pl.scan_parquet('../data/raw_data_session_id/products_train.parquet')\n",
    ").filter(pl.col('locale').is_in(target_locals)).collect().to_pandas()\n",
    "print(f\"product: {product_df.shape}\")\n",
    "\n",
    "product_df = product_df.rename(columns={\n",
    "    \n",
    "    'id': 'movie_title'\n",
    "\n",
    "})\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(product_df[['movie_title']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = (pl.scan_parquet('../data/rank_train_data_task2_v3/train/part_1.parquet')\n",
    "#                .filter(pl.col('session_id').is_in(target_session_id))\n",
    "#                .with_columns(\n",
    "#                    pl.col('session_id').cast(pl.Int32).cast(pl.Utf8)\n",
    "#                )\n",
    "#            ).collect().to_pandas()\n",
    "\n",
    "# target_item_lst = train_df['next_item_prediction'].unique().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_train_candidates = train_candidates\n",
    "train_session_id = target_train_candidates.select(pl.col('session_id')).unique().collect()\n",
    "\n",
    "session_num = train_session_id.shape[0]\n",
    "random_pl = train_session_id.with_columns(\n",
    "        pl.Series(name='random', values=np.random.uniform(size=session_num))\n",
    ")\n",
    "train_candidates = target_train_candidates.join(random_pl.lazy(), how='left', on='session_id')\n",
    "\n",
    "sampled_train_candidates = train_candidates.filter(pl.col('random')>eval_frac).sort('session_id', descending=False).collect()\n",
    "sampled_eval_candidates = train_candidates.filter(pl.col('random')<=eval_frac).sort('session_id', descending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (16932988, 59)\n",
      "target\n",
      "0.0    16825338\n",
      "1.0      107650\n",
      "Name: count, dtype: int64\n",
      "train: (15227136, 59)\n",
      "target\n",
      "0.0    15130321\n",
      "1.0       96815\n",
      "Name: count, dtype: int64\n",
      "train: (1705852, 59)\n",
      "target\n",
      "0.0    1695017\n",
      "1.0      10835\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ratings = get_tensor_data(target_pl=train_candidates)\n",
    "sampled_train_dataset = get_tensor_data(target_pl=sampled_train_candidates.lazy())\n",
    "sampled_eval_dataset = get_tensor_data(target_pl=sampled_eval_candidates.lazy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec={'user_rating': TensorSpec(shape=(), dtype=tf.float64, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec={'user_rating': TensorSpec(shape=(), dtype=tf.float64, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9I1VTEjHzpfX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in users.take(3):\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get user_id, item_id dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 05:54:25.606457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [16932988]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    }
   ],
   "source": [
    "users = ratings.map(lambda x: x[\"user_id\"])\n",
    "user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    mask_token=None)\n",
    "user_ids_vocabulary.adapt(users.batch(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 06:00:41.856392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [137541]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "movies = movies.map(lambda x: x[\"movie_title\"])\n",
    "movie_titles_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies.batch(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "B3wnNK1WG1lP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.string_lookup.StringLookup at 0x7f822dce68e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMsmoqWTOTKo"
   },
   "source": [
    "Group by `user_id` to form lists for ranking models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXY7kX7nOSwH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "57r87tdQlkcT"
   },
   "outputs": [],
   "source": [
    "# for x in ds_train.take(1):\n",
    "#   for key, value in x.items():\n",
    "#     print(f\"Shape of {key}: {value.shape}\")\n",
    "#     print(f\"Example values of {key}: {value[:5].numpy()}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XV0tcpeIIdj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcZJf2qxOeWU"
   },
   "source": [
    "Generate batched features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctq2RTOqOfAo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/tmp/ipykernel_11915/1533804459.py:30: dense_to_ragged_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ragged_batch` instead.\n"
     ]
    }
   ],
   "source": [
    "ds_train = get_dataset(ratings=sampled_train_dataset, user_ids_vocabulary=user_ids_vocabulary)\n",
    "ds_eval = get_dataset(ratings=sampled_eval_dataset, user_ids_vocabulary=user_ids_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJUU3mv-_VdQ"
   },
   "source": [
    "The `user_id` and `movie_title` tensors generated in `ds_train` are of shape `[32, None]`, where the second dimension is 100 in most cases except for the batches when less than 100 items grouped in lists. A model working on ragged tensors is thus used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_eval = eval_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GTquqk1GkIfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 06:00:44.453085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [15227136]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_id: (32, None)\n",
      "Example values of user_id: [[b'3272717' b'3272717' b'3272717']\n",
      " [b'3272720' b'3272720' b'3272720']\n",
      " [b'3272725' b'3272725' b'3272725']]\n",
      "\n",
      "Shape of movie_title: (32, None)\n",
      "Example values of movie_title: [[b'9963488811' b'B01EHTBZ2G' b'B09SVCKXCZ']\n",
      " [b'B0B6PG9TPR' b'B0B9RX96SG' b'B0B8747HGD']\n",
      " [b'B0757LNVBT' b'B019RPQML4' b'B01N2L28LH']]\n",
      "\n",
      "Shape of label: (32, None)\n",
      "Example values of label: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for x, label in ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 06:00:46.342956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_id: (32, None)\n",
      "Example values of user_id: [[b'3272769' b'3272769' b'3272769']\n",
      " [b'3272792' b'3272792' b'3272792']\n",
      " [b'3272813' b'3272813' b'3272813']]\n",
      "\n",
      "Shape of movie_title: (32, None)\n",
      "Example values of movie_title: [[b'B081QN84L2' b'B01LXDSDFX' b'B07G8JT5BD']\n",
      " [b'B0B55VWXDC' b'B08YDN24LL' b'B07QS4NMW6']\n",
      " [b'B082Q25BDZ' b'B0774JS6WF' b'B0BHSYPMGN']]\n",
      "\n",
      "Shape of label: (32, None)\n",
      "Example values of label: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for x, label in ds_eval.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrch6rVBOB9Q"
   },
   "source": [
    "## Define a model\n",
    "\n",
    "Define a ranking model by inheriting from `tf.keras.Model` and implementing the `call` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "e5dNbDZwOIHR"
   },
   "outputs": [],
   "source": [
    "class MovieLensRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, user_vocab, movie_vocab):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie vocabulary and embedding.\n",
    "    self.user_vocab = user_vocab\n",
    "    self.movie_vocab = movie_vocab\n",
    "    self.user_embed = tf.keras.layers.Embedding(user_vocab.vocabulary_size(),\n",
    "                                                64)\n",
    "    self.movie_embed = tf.keras.layers.Embedding(movie_vocab.vocabulary_size(),\n",
    "                                                 64)\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    # Define how the ranking scores are computed: \n",
    "    # Take the dot-product of the user embeddings with the movie embeddings.\n",
    "\n",
    "    user_embeddings = self.user_embed(self.user_vocab(features[\"user_id\"]))\n",
    "    movie_embeddings = self.movie_embed(\n",
    "        self.movie_vocab(features[\"movie_title\"]))\n",
    "\n",
    "    return tf.reduce_sum(user_embeddings * movie_embeddings, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMV0HpzmJGWk"
   },
   "source": [
    "Create the model, and then compile it with ranking `tfr.keras.losses` and `tfr.keras.metrics`, which are the core of the TF-Ranking package. \n",
    "\n",
    "This example uses a ranking-specific **softmax loss**, which is a listwise loss introduced to promote all relevant items in the ranking list with better chances on top of the irrelevant ones. In contrast to the softmax loss in the multi-class classification problem, where only one class is positive and the rest are negative, the TF-Ranking library supports multiple relevant documents in a query list and non-binary relevance labels.\n",
    "\n",
    "For ranking metrics, this example uses in specific **Normalized Discounted Cumulative Gain (NDCG)** and **Mean Reciprocal Rank (MRR)**, which calculate the user utility of a ranked query list with position discounts. For more details about ranking metrics, review evaluation measures [offline metrics](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Offline_metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_test(x, _):\n",
    "#     return x % 4 == 0\n",
    "\n",
    "\n",
    "# def is_train(x, y):\n",
    "#     return not is_test(x, y)\n",
    "\n",
    "\n",
    "# recover = lambda x, y: y\n",
    "\n",
    "# # Split the dataset for training.\n",
    "# test_dataset = ds_train.enumerate() \\\n",
    "#     .filter(is_test) \\\n",
    "#     .map(recover)\n",
    "\n",
    "# # Split the dataset for testing/validation.\n",
    "# train_dataset = ds_train.enumerate() \\\n",
    "#     .filter(is_train) \\\n",
    "#     .map(recover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "83BiHSAxL07s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 06:00:48.167612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 06:00:49.218660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/zeros/Reshape/movie_lens_ranking_model/sub_1' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/zeros/Reshape/movie_lens_ranking_model/sub_1}}]]\n",
      "2023-06-12 06:00:49.230438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub}}]]\n",
      "2023-06-12 06:00:49.242842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub}}]]\n",
      "2023-06-12 06:00:49.247969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/cond/range_1/movie_lens_ranking_model/sub_1' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/cond/range_1/movie_lens_ranking_model/sub_1}}]]\n",
      "2023-06-12 06:00:52.804759: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/zeros/Reshape/movie_lens_ranking_model/sub_1' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/zeros/Reshape/movie_lens_ranking_model/sub_1}}]]\n",
      "2023-06-12 06:00:52.814481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub}}]]\n",
      "2023-06-12 06:00:52.825477: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/cond/range/movie_lens_ranking_model/sub}}]]\n",
      "2023-06-12 06:00:52.830081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'movie_lens_ranking_model/cond/cond/range_1/movie_lens_ranking_model/sub_1' with dtype int64\n",
      "\t [[{{node movie_lens_ranking_model/cond/cond/range_1/movie_lens_ranking_model/sub_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    408/Unknown - 187s 441ms/step - loss: 0.0061 - metric/mrr: 0.0461"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39meval_metrics)\n\u001b[1;32m     12\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     14\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     18\u001b[0m ]\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train_dataset,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# validation_split=0.1\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/kdd-2023-KklMGVX0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss = tfr.keras.losses.MeanSquaredLoss(ragged=True)\n",
    "\n",
    "\n",
    "model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "eval_metrics = [\n",
    "    # tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True),\n",
    "]\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    # train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=ds_eval,\n",
    "    callbacks=callbacks\n",
    "          # validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZe-WXeVMI0R"
   },
   "outputs": [],
   "source": [
    "# # Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# # ranking metrics.\n",
    "\n",
    "# loss = tfr.keras.losses.PairwiseHingeLoss(ragged=True)\n",
    "\n",
    "\n",
    "# model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "# eval_metrics = [\n",
    "#     tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "#     tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "# ]\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "# model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2tQDhqkOKf1"
   },
   "outputs": [],
   "source": [
    "# # Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# # ranking metrics.\n",
    "\n",
    "# loss = tfr.keras.losses.get(\n",
    "#     loss=tfr.keras.losses.RankingLossKey.SOFTMAX_LOSS, ragged=True)\n",
    "\n",
    "# model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "# eval_metrics = [\n",
    "#     tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "#     tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "# ]\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "# model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5uuSRXZoOKW"
   },
   "source": [
    "Generate predictions and evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model eval function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_rec(candidate_pl, model, topn=100, ground_truth_included=False):\n",
    "    candidate_pl = candidate_pl.collect().to_pandas()\n",
    "    print(f\"candidate pl shape: {candidate_pl.shape}\")\n",
    "\n",
    "    user_tensor = tf.reshape(tf.convert_to_tensor(candidate_pl[user_col]), (1, -1))\n",
    "    item_tensor = tf.reshape(tf.convert_to_tensor(candidate_pl[item_col]), (1, -1))\n",
    "    new_inputs = {\n",
    "        \"user_id\":user_tensor\n",
    "            ,\n",
    "        \"movie_title\":item_tensor\n",
    "    }\n",
    "    output = model(new_inputs)\n",
    "\n",
    "    candidate_pl['predict'] = tf.squeeze(output, axis=0).numpy()\n",
    "\n",
    "\n",
    "    test_result = (\n",
    "        pl.from_pandas(candidate_pl)\n",
    "         .lazy()\n",
    "         # .with_columns(\n",
    "         #     pl.col(item_col).alias('next_item_prediction')\n",
    "         #     , pl.col(user_col).alias('session_id').cast(pl.Int64)\n",
    "         # )\n",
    "         .with_columns(\n",
    "            pl.col('predict').rank(method='ordinal', descending=True).over('session_id').alias('rank')\n",
    "         )\n",
    "         .sort(['session_id', 'rank'])\n",
    "         .filter(pl.col('rank')<=topn)\n",
    "    )\n",
    "    if ground_truth_included:\n",
    "        test_result = (\n",
    "            test_result         \n",
    "            .groupby(['session_id'])\n",
    "             .agg(\n",
    "                 pl.col('next_item_prediction')\n",
    "                 , pl.col('next_item').unique()#.arr.get(0).cast(pl.Utf8)\n",
    "             ).with_columns(\n",
    "                 pl.col('next_item').arr.get(0).alias('next_item')\n",
    "                 , pl.col(user_col).cast(pl.Int64)\n",
    "             )\n",
    "        )\n",
    "    else:\n",
    "        test_result = (\n",
    "            test_result         \n",
    "            .groupby(['session_id'])\n",
    "             .agg(\n",
    "                 pl.col('next_item_prediction')\n",
    "             ).with_columns(\n",
    "                 pl.col(user_col).cast(pl.Int64)\n",
    "             )\n",
    "        )\n",
    "    return test_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_eval_pl = rank_rec(candidate_pl=eval_candidates\n",
    "                        , model=model\n",
    "                          , topn=topn\n",
    "                          , ground_truth_included=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_eval_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(eval_pl.join(ranker_eval_pl.lazy(), how='left', on='session_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate pl shape: (3000, 56)\n"
     ]
    }
   ],
   "source": [
    "test_result = rank_rec(candidate_pl=test_candidates\n",
    "                        , model=model\n",
    "                          , topn=topn\n",
    "                           , ground_truth_included=False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_id</th><th>next_item_prediction</th></tr><tr><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>4331307</td><td>[&quot;B0B56NWXYH&quot;, &quot;B09Z1VH85Q&quot;,  &quot;B09N7R5P99&quot;]</td></tr><tr><td>4331319</td><td>[&quot;B09Z1VH85Q&quot;, &quot;B084J38SRL&quot;,  &quot;B019GJLER8&quot;]</td></tr><tr><td>4331312</td><td>[&quot;B011EI9PKW&quot;, &quot;B09WMK1RP4&quot;,  &quot;B07Y7YLB7Z&quot;]</td></tr><tr><td>4331311</td><td>[&quot;B09XP9BXV2&quot;, &quot;B08T9RDVMT&quot;,  &quot;B09MSB4X2G&quot;]</td></tr><tr><td>4331313</td><td>[&quot;B008SO7JZ4&quot;, &quot;B09FKWS793&quot;,  &quot;B07S3BJ294&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "\n",
       " session_id  next_item_prediction              \n",
       " ---         ---                               \n",
       " i64         list[str]                         \n",
       "\n",
       " 4331307     [\"B0B56NWXYH\", \"B09Z1VH85Q\",  \" \n",
       " 4331319     [\"B09Z1VH85Q\", \"B084J38SRL\",  \" \n",
       " 4331312     [\"B011EI9PKW\", \"B09WMK1RP4\",  \" \n",
       " 4331311     [\"B09XP9BXV2\", \"B08T9RDVMT\",  \" \n",
       " 4331313     [\"B008SO7JZ4\", \"B09FKWS793\",  \" \n",
       ""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = test_pl.join(test_result, how='left', on='session_id').collect()[['locale', 'next_item_prediction']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pl = (\n",
    "    test_pl.join(test_result, how='left', on='session_id')\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('next_item_prediction').is_null())\n",
    "                .then(pl.col('prev_items'))\n",
    "                .otherwise(pl.col('next_item_prediction')).alias('next_item_prediction')\n",
    "        )\n",
    ").collect()\n",
    "\n",
    "predictions = (predictions_pl[['locale', 'next_item_prediction']].to_pandas())\n",
    "prediction_summary = (\n",
    "    predictions_pl\n",
    "        .explode('next_item_prediction')\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').is_null().alias('whether_null')\n",
    "        )\n",
    "        .groupby('session_id')\n",
    "        .agg(\n",
    "            pl.col('whether_null').sum().alias('null_num')\n",
    "            , pl.count().alias('rec_num')\n",
    "        )\n",
    ")\n",
    "assert (\n",
    "    prediction_summary.filter(pl.col('null_num')>0)\n",
    ").shape[0] == 0\n",
    "\n",
    "\n",
    "check_predictions(predictions, test_sessions=test_pl.collect().to_pandas(), \n",
    "                  # check_products=True, product_df=products\n",
    "                 )\n",
    "# Its important that the parquet file you submit is saved with pyarrow backend\n",
    "\n",
    "assert (\n",
    "    pl.from_pandas(predictions)\n",
    "        .explode('next_item_prediction')\n",
    "        .filter(\n",
    "            pl.col('next_item_prediction').is_null()\n",
    "                     )\n",
    ").shape[0] == 0\n",
    "assert predictions.shape[0] == test_pl.collect().shape[0]\n",
    "if not debug:\n",
    "    predictions.to_parquet(sub_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 28918656 Jun 11 06:31 ../data/sub_files/task2_rank_tf_v3.parque\n"
     ]
    }
   ],
   "source": [
    "! ls -al {sub_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aicrowd submission create -c task-2-next-product-recommendation-for-underrepresented-languages -f {sub_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erdwpzZlMw5i",
    "tags": []
   },
   "source": [
    "# Ranking pipeline example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to [github page](https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/tf_ranking_canned_dnn.py) for more details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copyright 2022 The TensorFlow Ranking Authors.\n",
    "# #\n",
    "# # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# # you may not use this file except in compliance with the License.\n",
    "# # You may obtain a copy of the License at\n",
    "# #\n",
    "# #     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# #\n",
    "# # Unless required by applicable law or agreed to in writing, software\n",
    "# # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# # See the License for the specific language governing permissions and\n",
    "# # limitations under the License.\n",
    "\n",
    "# r\"\"\"TF-Ranking example code for training a canned DNN estimator.\n",
    "\n",
    "# The supported proto formats are listed at ../python/data.py.\n",
    "# --------------------------------------------------------------------------------\n",
    "# Sample command lines:\n",
    "\n",
    "# MODEL_DIR=/tmp/output && \\\n",
    "# TRAIN=tensorflow_ranking/examples/data/train_numerical_elwc.tfrecord && \\\n",
    "# EVAL=tensorflow_ranking/examples/data/vali_numerical_elwc.tfrecord && \\\n",
    "# rm -rf $MODEL_DIR && \\\n",
    "# bazel build -c opt \\\n",
    "# tensorflow_ranking/examples/tf_ranking_canned_dnn_py_binary && \\\n",
    "# ./bazel-bin/tensorflow_ranking/examples/tf_ranking_canned_dnn_py_binary \\\n",
    "# --train_input_pattern=$TRAIN \\\n",
    "# --eval_input_pattern=$EVAL \\\n",
    "# --model_dir=$MODEL_DIR\n",
    "\n",
    "# You can use TensorBoard to display the training results stored in $MODEL_DIR.\n",
    "\n",
    "# Notes:\n",
    "#   * Use --alsologtostderr if the output is not printed into screen.\n",
    "# \"\"\"\n",
    "\n",
    "# from absl import flags\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_ranking as tfr\n",
    "\n",
    "# flags.DEFINE_string(\"train_input_pattern\", None,\n",
    "#                     \"Input file path used for training.\")\n",
    "# flags.DEFINE_string(\"eval_input_pattern\", None,\n",
    "#                     \"Input file path used for eval.\")\n",
    "# flags.DEFINE_string(\"model_dir\", None, \"Output directory for models.\")\n",
    "# flags.DEFINE_integer(\"batch_size\", 32, \"The batch size for train.\")\n",
    "# flags.DEFINE_integer(\"num_train_steps\", 15000, \"Number of steps for train.\")\n",
    "# flags.DEFINE_integer(\"num_eval_steps\", 10, \"Number of steps for evaluation.\")\n",
    "# flags.DEFINE_integer(\"checkpoint_secs\", 30,\n",
    "#                      \"Saves a model checkpoint every checkpoint_secs seconds.\")\n",
    "# flags.DEFINE_integer(\"num_checkpoints\", 100,\n",
    "#                      \"Saves at most num_checkpoints checkpoints in workspace.\")\n",
    "# flags.DEFINE_integer(\"num_features\", 136, \"Number of features per example.\")\n",
    "# flags.DEFINE_integer(\n",
    "#     \"list_size\", 100,\n",
    "#     \"List size used for training. Use None for dynamic list size.\")\n",
    "# flags.DEFINE_float(\"learning_rate\", 0.05, \"Learning rate for optimizer.\")\n",
    "# flags.DEFINE_float(\"dropout\", 0.8, \"The dropout rate before output layer.\")\n",
    "# flags.DEFINE_list(\"hidden_layer_dims\", [\"64\", \"32\", \"16\"],\n",
    "#                   \"Sizes for hidden layers.\")\n",
    "# flags.DEFINE_string(\"loss\", \"approx_ndcg_loss\",\n",
    "#                     \"The RankingLossKey for the loss function.\")\n",
    "# flags.DEFINE_bool(\"convert_labels_to_binary\", False,\n",
    "#                   \"If true, relevance labels are set to either 0 or 1.\")\n",
    "# flags.DEFINE_bool(\"listwise_inference\", False,\n",
    "#                   \"If true, exports accept `data_format` while serving.\")\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# _LABEL_FEATURE = \"utility\"\n",
    "\n",
    "\n",
    "# def context_feature_columns():\n",
    "#   \"\"\"Returns context feature columns.\"\"\"\n",
    "#   return {}\n",
    "\n",
    "\n",
    "# def example_feature_columns():\n",
    "#   \"\"\"Returns the example feature columns.\"\"\"\n",
    "#   feature_names = [\n",
    "#       \"custom_features_{}\".format(i + 1) for i in range(FLAGS.num_features)\n",
    "#   ]\n",
    "#   return {\n",
    "#       name:\n",
    "#       tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "#       for name in feature_names\n",
    "#   }\n",
    "\n",
    "\n",
    "# def train_and_eval():\n",
    "#   \"\"\"Train and Evaluate.\"\"\"\n",
    "#   optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "#       learning_rate=FLAGS.learning_rate)\n",
    "\n",
    "#   estimator = tfr.estimator.make_dnn_ranking_estimator(\n",
    "#       example_feature_columns(),\n",
    "#       FLAGS.hidden_layer_dims,\n",
    "#       context_feature_columns=context_feature_columns(),\n",
    "#       optimizer=optimizer,\n",
    "#       learning_rate=FLAGS.learning_rate,\n",
    "#       loss=FLAGS.loss,\n",
    "#       loss_reduction=tf.compat.v1.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "#       activation_fn=tf.nn.relu,\n",
    "#       dropout=FLAGS.dropout,\n",
    "#       use_batch_norm=True,\n",
    "#       model_dir=FLAGS.model_dir)\n",
    "\n",
    "#   hparams = {\"train_input_pattern\": FLAGS.train_input_pattern,\n",
    "#              \"eval_input_pattern\": FLAGS.eval_input_pattern,\n",
    "#              \"learning_rate\": FLAGS.learning_rate,\n",
    "#              \"train_batch_size\": FLAGS.batch_size,\n",
    "#              \"eval_batch_size\": FLAGS.batch_size,\n",
    "#              \"predict_batch_size\": FLAGS.batch_size,\n",
    "#              \"num_train_steps\": FLAGS.num_train_steps,\n",
    "#              \"num_eval_steps\": FLAGS.num_eval_steps,\n",
    "#              \"checkpoint_secs\": FLAGS.checkpoint_secs,\n",
    "#              \"num_checkpoints\": FLAGS.num_checkpoints,\n",
    "#              \"loss\": FLAGS.loss,\n",
    "#              \"list_size\": FLAGS.list_size,\n",
    "#              \"convert_labels_to_binary\": FLAGS.convert_labels_to_binary,\n",
    "#              \"listwise_inference\": FLAGS.listwise_inference,\n",
    "#              \"model_dir\": FLAGS.model_dir}\n",
    "\n",
    "#   ranking_pipeline = tfr.ext.pipeline.RankingPipeline(\n",
    "#       context_feature_columns(),\n",
    "#       example_feature_columns(),\n",
    "#       hparams,\n",
    "#       estimator=estimator,\n",
    "#       label_feature_name=_LABEL_FEATURE,\n",
    "#       label_feature_type=tf.int64)\n",
    "\n",
    "#   ranking_pipeline.train_and_eval()\n",
    "\n",
    "\n",
    "# def main(_):\n",
    "#   tf.compat.v1.set_random_seed(1234)\n",
    "#   tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "#   train_and_eval()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   flags.mark_flag_as_required(\"train_input_pattern\")\n",
    "#   flags.mark_flag_as_required(\"eval_input_pattern\")\n",
    "#   flags.mark_flag_as_required(\"model_dir\")\n",
    "\n",
    "#   tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copyright 2022 The TensorFlow Ranking Authors.\n",
    "# #\n",
    "# # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# # you may not use this file except in compliance with the License.\n",
    "# # You may obtain a copy of the License at\n",
    "# #\n",
    "# #     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# #\n",
    "# # Unless required by applicable law or agreed to in writing, software\n",
    "# # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# # See the License for the specific language governing permissions and\n",
    "# # limitations under the License.\n",
    "\n",
    "# \"\"\"Tests for tf_ranking_canned_dnn.py.\"\"\"\n",
    "\n",
    "# import os\n",
    "\n",
    "# from absl import flags\n",
    "# from absl.testing import flagsaver\n",
    "# from absl.testing import parameterized\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from google.protobuf import text_format\n",
    "# from tensorflow_ranking.examples import tf_ranking_canned_dnn\n",
    "# from tensorflow_serving.apis import input_pb2\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# ELWC = text_format.Parse(\n",
    "#     \"\"\"\n",
    "#     context {\n",
    "#     }\n",
    "#     examples {\n",
    "#       features {\n",
    "#         feature {\n",
    "#           key: \"custom_features_1\"\n",
    "#           value { float_list { value: 1.0 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"custom_features_2\"\n",
    "#           value { float_list { value: 1.5 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"utility\"\n",
    "#           value { int64_list { value: 1 } }\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "#     examples {\n",
    "#       features {\n",
    "#         feature {\n",
    "#           key: \"custom_features_1\"\n",
    "#           value { float_list { value: 1.0 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"custom_features_3\"\n",
    "#           value { float_list { value: 2.1 } }\n",
    "#         }\n",
    "#         feature {\n",
    "#           key: \"utility\"\n",
    "#           value { int64_list { value: 0 } }\n",
    "#         }\n",
    "#       }\n",
    "#     }\"\"\", input_pb2.ExampleListWithContext())\n",
    "\n",
    "\n",
    "# def _write_tfrecord_files(path):\n",
    "#   elwc_list = [ELWC.SerializeToString()] * 10\n",
    "#   if tf.io.gfile.exists(path):\n",
    "#     tf.io.gfile.remove(path)\n",
    "\n",
    "#   with tf.io.TFRecordWriter(path) as writer:\n",
    "#     for elwc in elwc_list:\n",
    "#       writer.write(elwc)\n",
    "\n",
    "\n",
    "# class TFRankingCannedDNNTest(tf.test.TestCase, parameterized.TestCase):\n",
    "\n",
    "#   def setUp(self):\n",
    "#     super(TFRankingCannedDNNTest, self).setUp()\n",
    "#     tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#     # Prepares model directory, and train and eval data.\n",
    "#     self._base_model_dir = tf.compat.v1.test.get_temp_dir() + \"/model/\"\n",
    "#     tf.io.gfile.makedirs(self._base_model_dir)\n",
    "#     self._data_file = os.path.join(self._base_model_dir, \"elwc.tfrecord\")\n",
    "#     _write_tfrecord_files(self._data_file)\n",
    "\n",
    "#   def tearDown(self):\n",
    "#     super(TFRankingCannedDNNTest, self).tearDown()\n",
    "#     if self._base_model_dir:\n",
    "#       tf.io.gfile.rmtree(self._base_model_dir)\n",
    "#     self._base_model_dir = None\n",
    "\n",
    "#   @parameterized.named_parameters((\"enable_listwise_inference\", True),\n",
    "#                                   (\"disable_listwise_inference\", False))\n",
    "#   def test_train_and_eval(self, listwise_inference):\n",
    "#     self._model_dir = self._base_model_dir + \"/\" + str(listwise_inference)\n",
    "#     with flagsaver.flagsaver(\n",
    "#         train_input_pattern=self._data_file,\n",
    "#         eval_input_pattern=self._data_file,\n",
    "#         model_dir=self._model_dir,\n",
    "#         num_features=3,\n",
    "#         num_train_steps=10,\n",
    "#         listwise_inference=listwise_inference):\n",
    "#       tf_ranking_canned_dnn.train_and_eval()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   tf.test.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "kdd_2023",
   "name": "common-cu110.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m104"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "py3.8(kdd_2023)",
   "language": "python",
   "name": "kdd_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
