{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. check the how many times item2 is item1's next item\n",
    "2. For each item1, normalized the count to [0, 1]\n",
    "3. Add 0.01 -> since 0 will represent item2 has never been the next item of item1\n",
    "4. Next steps\n",
    "    1. [x] counts should be included \n",
    "    2. [x] train2 data should be included\n",
    "    3. [x] 0 should be the min_count for each item\n",
    "\n",
    "\n",
    "Example: [a, b, c] -> [ab, bc] -> \n",
    "\n",
    "```\n",
    "[\n",
    "--current_item, next_item, counts\n",
    "[a, b, 1],\n",
    "[b, c, 1]\n",
    "]\n",
    "\n",
    "after normalization\n",
    "\n",
    "[\n",
    "--current_item, next_item, counts\n",
    "[a, b, 1.01],\n",
    "[b, c, 1.01]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import logging\n",
    "base_dir = '../'\n",
    "sys.path.append(base_dir)\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "import polars as pl\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from tqdm.auto import tqdm\n",
    "import polars as pl\n",
    "from utils import *\n",
    "from src.eval import model_eval\n",
    "from src.config import raw_data_session_id_dir, candidate_dir, model_for_eval, candidate_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "\n",
    "task = 'task2'\n",
    "\n",
    "model_version = f'nic_{task}_v2'\n",
    "\n",
    "# target locales: locales needed for task1\n",
    "target_locals = ['ES', 'FR', 'IT']\n",
    "\n",
    "topn = 100\n",
    "if debug:\n",
    "    n_rows = 1000\n",
    "else:\n",
    "    n_rows = None\n",
    "# debug_session_num = 100\n",
    "train_data_dir = '.'\n",
    "test_data_dir = '.'\n",
    "\n",
    "\n",
    "model_dir = f'../model_training/{model_version}/'\n",
    "\n",
    "\n",
    "# if model_for_eval:\n",
    "model_file = os.path.join(model_dir, f'nic_{model_for_eval}_for_eval.parquet')\n",
    "submit_file = os.path.join('../data/sub_files/', f'submission_{task}_nic_{model_for_eval}_for_eval.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task2_v2/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task2_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/candidates/task2_train_nic_task2_v2_True_top100.parquet\n",
      "../data/candidates/task2_eval_nic_task2_v2_True_top100.parquet\n",
      "../data/candidates/task2_test_nic_task2_v2_True_top100.parquet\n",
      "../data/candidates/task2_test4task3_nic_task2_v2_True_top100.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_cg_file = os.path.join(base_dir,\n",
    "                             candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='train'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "eval_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='eval'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "test_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='test'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "\n",
    "test4task3_file_name = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "                                    candidate_file_name.format(\n",
    "    task=task\n",
    "    , data_type='test4task3'\n",
    "    , model_version=model_version\n",
    "    , model_for_eval=model_for_eval\n",
    "    , topn=topn\n",
    "))\n",
    "print(train_cg_file)\n",
    "print(eval_cg_file)\n",
    "print(test_cg_file)\n",
    "print(test4task3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task2_test_nic_task2_v2_True_top100.parquet'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../model_training/nic_task2_v2/’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task2_v2/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task2_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_unique2id.json\t\t    sessions_test_task2_phase1.parquet\n",
      "products_train.parquet\t\t    sessions_test_task3.parquet\n",
      "sessions_eval.parquet\t\t    sessions_test_task3_phase1.parquet\n",
      "sessions_test_task1.parquet\t    sessions_train.parquet\n",
      "sessions_test_task1_phase1.parquet  sessions_train1.parquet\n",
      "sessions_test_task2.parquet\t    sessions_train2.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls ../{raw_data_session_id_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_train1.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "train2_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_train2.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "eval_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_eval.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "# df_sess.head(3).collect()\n",
    "test_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, f'sessions_test_{task}.parquet'), n_rows=n_rows).with_columns(pl.col('prev_items').apply(str2list))\n",
    "test4task3_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task3.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>locale</th><th>counts</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;IT&quot;</td><td>10000</td></tr><tr><td>&quot;ES&quot;</td><td>6422</td></tr><tr><td>&quot;FR&quot;</td><td>10000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────┐\n",
       "│ locale ┆ counts │\n",
       "│ ---    ┆ ---    │\n",
       "│ str    ┆ u32    │\n",
       "╞════════╪════════╡\n",
       "│ IT     ┆ 10000  │\n",
       "│ ES     ┆ 6422   │\n",
       "│ FR     ┆ 10000  │\n",
       "└────────┴────────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4task3_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.filter(pl.col('locale').is_null()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'item', 'next_item_prediction', 'next_item_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nic_rec(target_pl, nic_model, rec_num=topn):\n",
    "    # rec_num = 100\n",
    "    final_cols = ['session_id', 'next_item_prediction', 'rec_num']\n",
    "    target_pl = (\n",
    "        target_pl\n",
    "            .with_columns(\n",
    "                pl.col('prev_items').arr.get(-1).alias('last_item')\n",
    "            )\n",
    "            .join(nic_model, how='left', left_on='last_item', right_on='item')\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('next_item_prediction').is_null()).then([]).otherwise(pl.col('next_item_prediction').arr.head(rec_num)).alias('next_item_prediction')\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "            )\n",
    "            .select(\n",
    "                final_cols\n",
    "            )\n",
    "    )#.head(3).collect()\n",
    "    return target_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Item Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_pl.with_columns(\n",
    "    pl.col('prev_items').arr.concat(pl.col('next_item')) \n",
    ")\n",
    "if not model_for_eval:\n",
    "    eval_data = eval_pl.with_columns(\n",
    "    pl.col('prev_items').arr.concat(pl.col('next_item')) \n",
    ")\n",
    "else:\n",
    "    eval_data = eval_pl\n",
    "train2_data = train2_pl\n",
    "\n",
    "test_data = test_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_for_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not model_for_eval:\n",
    "\n",
    "\n",
    "cols_to_keep = ['prev_items']\n",
    "next_items_pl = (\n",
    "    pl.concat([train_data.select(cols_to_keep), \n",
    "               eval_data.select(cols_to_keep),\n",
    "               train2_data.select(cols_to_keep),\n",
    "               test_data.select(cols_to_keep)], how='vertical')\n",
    "        .with_columns(\n",
    "            pl.col('prev_items').arr.shift(-1).alias('next_item_lst')\n",
    "            , pl.col('prev_items').arr.lengths().alias('length')\n",
    "        )\n",
    "        .select(\n",
    "            pl.col('prev_items').arr.head(pl.col('length')-1).alias('prev')\n",
    "            , pl.col('next_item_lst').arr.head(pl.col('length')-1).alias('next')\n",
    "        )\n",
    "        .explode(['prev','next' ])\n",
    "        .groupby(['prev','next' ])\n",
    "        .agg(\n",
    "            pl.count().alias('cnt')\n",
    "        )\n",
    "        .sort(['prev', 'cnt'], descending=True)\n",
    "        .with_columns(\n",
    "            pl.col('cnt').max().over('prev').alias('max_count')\n",
    "            , pl.lit(0).alias('min_count')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('max_count')==pl.col('min_count')).then(1).otherwise((pl.col('cnt')-pl.col('min_count'))/(pl.col('max_count')-pl.col('min_count'))).alias('normalized_cnt')\n",
    "        )\n",
    "        .groupby('prev')\n",
    "        .agg(\n",
    "            pl.col('next').alias('next_item_prediction')\n",
    "            , pl.col('cnt').alias('next_item_cnt')\n",
    "            , (pl.col('normalized_cnt')).alias('next_item_weight')\n",
    "        )\n",
    "        .select(\n",
    "            pl.col('prev').alias('item')\n",
    "            , 'next_item_prediction'\n",
    "            , pl.col('next_item_weight')\n",
    "            , 'next_item_cnt'\n",
    "        )\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item</th><th>next_item_prediction</th><th>next_item_weight</th><th>next_item_cnt</th></tr><tr><td>str</td><td>list[str]</td><td>list[f64]</td><td>list[u32]</td></tr></thead><tbody><tr><td>&quot;B0B3HNKNHK&quot;</td><td>[&quot;B0B3H8DY1Y&quot;, &quot;B08Z6X4PX6&quot;, … &quot;B09M78232Q&quot;]</td><td>[1.0, 0.2, … 0.2]</td><td>[5, 1, … 1]</td></tr><tr><td>&quot;B08XXZ1TGL&quot;</td><td>[&quot;B0785JG1ZB&quot;, &quot;B01EZ0X55C&quot;, … &quot;B08JD5PV9F&quot;]</td><td>[1.0, 1.0, … 1.0]</td><td>[1, 1, … 1]</td></tr><tr><td>&quot;B08P8ZF7H4&quot;</td><td>[&quot;B075WVK551&quot;, &quot;B08J449X8T&quot;, … &quot;B08P8ZF7H4&quot;]</td><td>[1.0, 0.5, … 0.5]</td><td>[2, 1, … 1]</td></tr><tr><td>&quot;B0B46T2RCT&quot;</td><td>[&quot;B09DNZG3Z5&quot;, &quot;B08N5V5QL5&quot;, … &quot;B0949RD2VM&quot;]</td><td>[1.0, 1.0, … 0.5]</td><td>[2, 2, … 1]</td></tr><tr><td>&quot;B09TKRK8KM&quot;</td><td>[&quot;B09TKS3S1J&quot;, &quot;B09HTYY1CJ&quot;]</td><td>[1.0, 1.0]</td><td>[1, 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌────────────┬───────────────────────────────────┬───────────────────┬───────────────┐\n",
       "│ item       ┆ next_item_prediction              ┆ next_item_weight  ┆ next_item_cnt │\n",
       "│ ---        ┆ ---                               ┆ ---               ┆ ---           │\n",
       "│ str        ┆ list[str]                         ┆ list[f64]         ┆ list[u32]     │\n",
       "╞════════════╪═══════════════════════════════════╪═══════════════════╪═══════════════╡\n",
       "│ B0B3HNKNHK ┆ [\"B0B3H8DY1Y\", \"B08Z6X4PX6\", … \"… ┆ [1.0, 0.2, … 0.2] ┆ [5, 1, … 1]   │\n",
       "│ B08XXZ1TGL ┆ [\"B0785JG1ZB\", \"B01EZ0X55C\", … \"… ┆ [1.0, 1.0, … 1.0] ┆ [1, 1, … 1]   │\n",
       "│ B08P8ZF7H4 ┆ [\"B075WVK551\", \"B08J449X8T\", … \"… ┆ [1.0, 0.5, … 0.5] ┆ [2, 1, … 1]   │\n",
       "│ B0B46T2RCT ┆ [\"B09DNZG3Z5\", \"B08N5V5QL5\", … \"… ┆ [1.0, 1.0, … 0.5] ┆ [2, 2, … 1]   │\n",
       "│ B09TKRK8KM ┆ [\"B09TKS3S1J\", \"B09HTYY1CJ\"]      ┆ [1.0, 1.0]        ┆ [1, 1]        │\n",
       "└────────────┴───────────────────────────────────┴───────────────────┴───────────────┘"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_items_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_items_pl.collect()#.filter(pl.col('item')=='B09LXX1PQ9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_dict = defaultdict(list)\n",
    "\n",
    "# for _, row in tqdm(df_sess.iterrows(), total=len(df_sess)):\n",
    "#     prev_items = str2list(row['prev_items'])\n",
    "#     if not model_for_eval:\n",
    "#         next_item = row['next_item']\n",
    "#     prev_items_length = len(prev_items)\n",
    "#     if prev_items_length <= 1:\n",
    "#         if not model_for_eval:\n",
    "#             next_item_dict[prev_items[0]].append(next_item)\n",
    "#     else:\n",
    "#         for i, item in enumerate(prev_items[:-1]):\n",
    "#             next_item_dict[item].append(prev_items[i+1])\n",
    "#         if not model_for_eval:\n",
    "#             next_item_dict[prev_items[-1]].append(next_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "#     prev_items = str2list(row['prev_items'])\n",
    "#     prev_items_length = len(prev_items)\n",
    "#     if prev_items_length <= 1:\n",
    "#         continue\n",
    "#     else:\n",
    "#         for i, item in enumerate(prev_items[:-1]):\n",
    "#             next_item_dict[item].append(prev_items[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next_item_map = {}\n",
    "# topn = 100\n",
    "# item_lst = []\n",
    "# common_items_lst = []\n",
    "# weights_lst = []\n",
    "# for item in tqdm(next_item_dict):\n",
    "#     counter = Counter(next_item_dict[item])\n",
    "#     most_common_cnt = counter.most_common(1)[0][1]\n",
    "#     most_common_lst = list(zip(*counter.most_common(topn)))\n",
    "#     most_common_lst[1] = list(np.array(most_common_lst[1])/most_common_cnt)\n",
    "#     item_lst.append(item)\n",
    "#     common_items_lst.append(list(most_common_lst[0]))\n",
    "#     weights_lst.append(most_common_lst[1])\n",
    "#     # next_item_map[item] = most_common_lst\n",
    "#     # next_item_map[item] = [i[0] for i in counter.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df = pd.DataFrame(\n",
    "#     {'item': item_lst\n",
    "#     , 'next_item_prediction': common_items_lst\n",
    "#      , 'next_item_weight': weights_lst\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_items_pl.collect().filter(pl.col('item')=='B07QGW8LFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nex_item_pl = pl.from_pandas(next_item_df).lazy().select(\n",
    "#     'item'\n",
    "#     , pl.col('next_item_prediction').alias('next_item_rec')\n",
    "#     , 'next_item_weight'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../model_training/next_item_counter/model.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model['next_item_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nex_item_pl = pl.DataFrame(\n",
    "#     {\n",
    "#         'item': model['next_item_map'].keys()\n",
    "#         , 'next_item_rec': model['next_item_map'].values()\n",
    "#     }\n",
    "# ).lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106037, 4)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_items_pl.collect().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task2_v2/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_items_pl.collect().write_parquet(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "del next_items_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task2_v2/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_items_pl = pl.scan_parquet(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = next_items_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item', 'next_item_prediction', 'next_item_weight', 'next_item_cnt'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (30, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item</th><th>next_item_prediction</th><th>next_item_weight</th><th>next_item_cnt</th></tr><tr><td>str</td><td>list[str]</td><td>list[f64]</td><td>list[u32]</td></tr></thead><tbody><tr><td>&quot;B09XDBGD34&quot;</td><td>[&quot;B09XD5D996&quot;, &quot;B0B5TT8NMT&quot;, … &quot;B09CYWCSPV&quot;]</td><td>[1.0, 0.5, … 0.5]</td><td>[2, 1, … 1]</td></tr><tr><td>&quot;B08GLC64T5&quot;</td><td>[&quot;B08GLC64T5&quot;, &quot;B0924MT4HF&quot;, … &quot;B09JSY824R&quot;]</td><td>[1.0, 0.333333, … 0.333333]</td><td>[3, 1, … 1]</td></tr><tr><td>&quot;B09B2PX814&quot;</td><td>[&quot;B08C88HDN6&quot;, &quot;B0B461Q5T9&quot;, … &quot;B09VLCK6ZF&quot;]</td><td>[1.0, 0.464286, … 0.035714]</td><td>[28, 13, … 1]</td></tr><tr><td>&quot;B08C7KCJF5&quot;</td><td>[&quot;B07WD5B99P&quot;, &quot;B091CQH6VT&quot;, … &quot;B08Q29FLHD&quot;]</td><td>[1.0, 1.0, … 0.5]</td><td>[2, 2, … 1]</td></tr><tr><td>&quot;B010X1TATC&quot;</td><td>[&quot;B010X1TATC&quot;, &quot;B005NH4O66&quot;, … &quot;B08KJKCK6M&quot;]</td><td>[1.0, 0.333333, … 0.333333]</td><td>[3, 1, … 1]</td></tr><tr><td>&quot;B08GS323SR&quot;</td><td>[&quot;B08GR24CRP&quot;]</td><td>[1.0]</td><td>[1]</td></tr><tr><td>&quot;B075KK1848&quot;</td><td>[&quot;B09GW6S5CB&quot;, &quot;B08NQ4VJ5X&quot;, … &quot;B076ZR13BJ&quot;]</td><td>[1.0, 1.0, … 1.0]</td><td>[1, 1, … 1]</td></tr><tr><td>&quot;B09GLW17PK&quot;</td><td>[&quot;B09GLW17PK&quot;]</td><td>[1.0]</td><td>[1]</td></tr><tr><td>&quot;B00W79XF9U&quot;</td><td>[&quot;B00W79X5ZO&quot;]</td><td>[1.0]</td><td>[3]</td></tr><tr><td>&quot;B00A2O44D8&quot;</td><td>[&quot;B07N3C5WRG&quot;, &quot;B07DCVKCMX&quot;, &quot;B07MKV4B9R&quot;]</td><td>[1.0, 1.0, 1.0]</td><td>[1, 1, 1]</td></tr><tr><td>&quot;B009346RSS&quot;</td><td>[&quot;B009346RSS&quot;, &quot;B00MZQU4KI&quot;]</td><td>[1.0, 0.333333]</td><td>[3, 1]</td></tr><tr><td>&quot;B00FEJUDZO&quot;</td><td>[&quot;B09CV4Q941&quot;]</td><td>[1.0]</td><td>[4]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;B08RRSYNYN&quot;</td><td>[&quot;B08RS474GM&quot;, &quot;B00V33E824&quot;, &quot;B09M48VDSF&quot;]</td><td>[1.0, 0.2, 0.2]</td><td>[5, 1, 1]</td></tr><tr><td>&quot;B09ZQ9P3HD&quot;</td><td>[&quot;B094VB6D49&quot;, &quot;B09QFPYX34&quot;]</td><td>[1.0, 0.5]</td><td>[2, 1]</td></tr><tr><td>&quot;B0B2QC27V9&quot;</td><td>[&quot;B0BJ24PLNN&quot;, &quot;B0B97LQLNM&quot;, … &quot;B0B3RPCCTK&quot;]</td><td>[1.0, 1.0, … 1.0]</td><td>[1, 1, … 1]</td></tr><tr><td>&quot;B00OZOBUTW&quot;</td><td>[&quot;B00OZOCMZI&quot;]</td><td>[1.0]</td><td>[1]</td></tr><tr><td>&quot;B07K4QB28L&quot;</td><td>[&quot;B07K4QB28L&quot;, &quot;B08TJYX9H2&quot;, … &quot;B07H7RDNLB&quot;]</td><td>[1.0, 0.5, … 0.5]</td><td>[2, 1, … 1]</td></tr><tr><td>&quot;B09DW4B8WT&quot;</td><td>[&quot;B09DW3RV7Y&quot;, &quot;B09DW48SD3&quot;]</td><td>[1.0, 0.333333]</td><td>[3, 1]</td></tr><tr><td>&quot;B0BBLHHJZ8&quot;</td><td>[&quot;B08PGWXC1J&quot;, &quot;B00ET2LSLK&quot;, … &quot;B015OW6D9A&quot;]</td><td>[1.0, 1.0, … 0.5]</td><td>[2, 2, … 1]</td></tr><tr><td>&quot;B09K4JYL4X&quot;</td><td>[&quot;B00J5G1IKQ&quot;, &quot;B00WIBPZ68&quot;, … &quot;B09K4JYL4X&quot;]</td><td>[1.0, 1.0, … 1.0]</td><td>[1, 1, … 1]</td></tr><tr><td>&quot;B0922D44TF&quot;</td><td>[&quot;B093K3QRGP&quot;, &quot;B09G9FBD7S&quot;]</td><td>[1.0, 1.0]</td><td>[1, 1]</td></tr><tr><td>&quot;B08RS37VS4&quot;</td><td>[&quot;B06XC8ZKJ8&quot;, &quot;B01EK7LOJ4&quot;]</td><td>[1.0, 1.0]</td><td>[1, 1]</td></tr><tr><td>&quot;B08D9NK38M&quot;</td><td>[&quot;B08D9MMWKX&quot;]</td><td>[1.0]</td><td>[3]</td></tr><tr><td>&quot;B09QMNCG64&quot;</td><td>[&quot;B09QMNCG64&quot;, &quot;B0923CFM79&quot;, &quot;B08HH6KR2Y&quot;]</td><td>[1.0, 0.666667, 0.333333]</td><td>[3, 2, 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (30, 4)\n",
       "┌────────────┬───────────────────────────────────┬─────────────────────────────┬───────────────┐\n",
       "│ item       ┆ next_item_prediction              ┆ next_item_weight            ┆ next_item_cnt │\n",
       "│ ---        ┆ ---                               ┆ ---                         ┆ ---           │\n",
       "│ str        ┆ list[str]                         ┆ list[f64]                   ┆ list[u32]     │\n",
       "╞════════════╪═══════════════════════════════════╪═════════════════════════════╪═══════════════╡\n",
       "│ B09XDBGD34 ┆ [\"B09XD5D996\", \"B0B5TT8NMT\", … \"… ┆ [1.0, 0.5, … 0.5]           ┆ [2, 1, … 1]   │\n",
       "│ B08GLC64T5 ┆ [\"B08GLC64T5\", \"B0924MT4HF\", … \"… ┆ [1.0, 0.333333, … 0.333333] ┆ [3, 1, … 1]   │\n",
       "│ B09B2PX814 ┆ [\"B08C88HDN6\", \"B0B461Q5T9\", … \"… ┆ [1.0, 0.464286, … 0.035714] ┆ [28, 13, … 1] │\n",
       "│ B08C7KCJF5 ┆ [\"B07WD5B99P\", \"B091CQH6VT\", … \"… ┆ [1.0, 1.0, … 0.5]           ┆ [2, 2, … 1]   │\n",
       "│ …          ┆ …                                 ┆ …                           ┆ …             │\n",
       "│ B0922D44TF ┆ [\"B093K3QRGP\", \"B09G9FBD7S\"]      ┆ [1.0, 1.0]                  ┆ [1, 1]        │\n",
       "│ B08RS37VS4 ┆ [\"B06XC8ZKJ8\", \"B01EK7LOJ4\"]      ┆ [1.0, 1.0]                  ┆ [1, 1]        │\n",
       "│ B08D9NK38M ┆ [\"B08D9MMWKX\"]                    ┆ [1.0]                       ┆ [3]           │\n",
       "│ B09QMNCG64 ┆ [\"B09QMNCG64\", \"B0923CFM79\", \"B0… ┆ [1.0, 0.666667, 0.333333]   ┆ [3, 2, 1]     │\n",
       "└────────────┴───────────────────────────────────┴─────────────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_items_pl.head(30).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl = nic_rec(target_pl=eval_pl, nic_model=next_items_pl)#.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if_hit = pl.element().rank()\n",
    "target_df = eval_pl.join(eval_candidate_pl, how='left', on='session_id')\n",
    "\n",
    "\n",
    "# eval_final.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>total_sessions</th><th>mrr</th><th>recall@20</th><th>recall@100</th></tr><tr><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>33333</td><td>0.2605</td><td>0.4536</td><td>0.4742</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────────┬────────┬───────────┬────────────┐\n",
       "│ total_sessions ┆ mrr    ┆ recall@20 ┆ recall@100 │\n",
       "│ ---            ┆ ---    ┆ ---       ┆ ---        │\n",
       "│ u32            ┆ f64    ┆ f64       ┆ f64        │\n",
       "╞════════════════╪════════╪═══════════╪════════════╡\n",
       "│ 33333          ┆ 0.2605 ┆ 0.4536    ┆ 0.4742     │\n",
       "└────────────────┴────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval(target_df=target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_eval(target_df=target_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Saving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_id</th><th>next_item_prediction</th><th>rec_num</th></tr><tr><td>i64</td><td>list[str]</td><td>u32</td></tr></thead><tbody><tr><td>3272722</td><td>[&quot;B003A61V0O&quot;, &quot;B08LQY6Q9C&quot;, … &quot;B005L9EZWY&quot;]</td><td>7</td></tr><tr><td>3272739</td><td>[&quot;B08LR7B41X&quot;, &quot;B01HXRQ1PA&quot;, &quot;B00331LFMA&quot;]</td><td>3</td></tr><tr><td>3272763</td><td>[&quot;B07K527Y7N&quot;, &quot;B08BJNJHFG&quot;, … &quot;B00008D9RK&quot;]</td><td>27</td></tr><tr><td>3272776</td><td>[&quot;B09PNDJJZ9&quot;, &quot;B0B2K87MXS&quot;, … &quot;B08CH6VKHW&quot;]</td><td>26</td></tr><tr><td>3272785</td><td>[&quot;B00OUVGTJ6&quot;, &quot;B00V88L9LC&quot;, … &quot;B00IOEEOCE&quot;]</td><td>6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌────────────┬───────────────────────────────────┬─────────┐\n",
       "│ session_id ┆ next_item_prediction              ┆ rec_num │\n",
       "│ ---        ┆ ---                               ┆ ---     │\n",
       "│ i64        ┆ list[str]                         ┆ u32     │\n",
       "╞════════════╪═══════════════════════════════════╪═════════╡\n",
       "│ 3272722    ┆ [\"B003A61V0O\", \"B08LQY6Q9C\", … \"… ┆ 7       │\n",
       "│ 3272739    ┆ [\"B08LR7B41X\", \"B01HXRQ1PA\", \"B0… ┆ 3       │\n",
       "│ 3272763    ┆ [\"B07K527Y7N\", \"B08BJNJHFG\", … \"… ┆ 27      │\n",
       "│ 3272776    ┆ [\"B09PNDJJZ9\", \"B0B2K87MXS\", … \"… ┆ 26      │\n",
       "│ 3272785    ┆ [\"B00OUVGTJ6\", \"B00V88L9LC\", … \"… ┆ 6       │\n",
       "└────────────┴───────────────────────────────────┴─────────┘"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_candidate_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl.collect().write_parquet(eval_cg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & eval  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_pl = nic_rec(target_pl=train2_pl, nic_model=next_items_pl)#.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_candidate_pl = nic_rec(target_pl=eval_pl, nic_model=next_items_pl)#.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task2_train_nic_task2_v2_True_top100.parquet'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_pl.collect().write_parquet(train_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate_pl = nic_rec(target_pl=test_pl, nic_model=next_items_pl)#.head().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_candidate_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate_pl.collect().write_parquet(test_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task2_test_nic_task2_v2_True_top100.parquet'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls ../data/candidates/ | grep 'test_nic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test4task3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/candidates/task2_test4task3_nic_task2_v2_True_top100.parquet\n"
     ]
    }
   ],
   "source": [
    "print(test4task3_file_name)\n",
    "test4task3_cg_pl = nic_rec(target_pl=test4task3_pl, nic_model=next_items_pl)#.head().collect()\n",
    "test4task3_cg_pl.collect().write_parquet(test4task3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_task2 = pl.read_csv('../data/raw_data/sessions_test_task2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls ../data/raw_data/ | grep task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_task2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_pl.join(test_candidate_pl, how='left', on='session_id').collect()[['locale', 'next_item_prediction']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_predictions(predictions,test_sessions, check_products=False, product_df=None):\n",
    "    \"\"\"\n",
    "    These tests need to pass as they will also be applied on the evaluator\n",
    "    \"\"\"\n",
    "    test_locale_names = test_sessions['locale'].unique()\n",
    "    for locale in test_locale_names:\n",
    "        sess_test = test_sessions.query(f'locale == \"{locale}\"')\n",
    "        preds_locale =  predictions[predictions['locale'] == sess_test['locale'].iloc[0]]\n",
    "        assert sorted(preds_locale.index.values) == sorted(sess_test.index.values), f\"Session ids of {locale} doesn't match\"\n",
    "\n",
    "        if check_products:\n",
    "            # This check is not done on the evaluator\n",
    "            # but you can run it to verify there is no mixing of products between locales\n",
    "            # Since the ground truth next item will always belong to the same locale\n",
    "            # Warning - This can be slow to run\n",
    "            products = product_df.query(f'locale == \"{locale}\"')\n",
    "            predicted_products = np.unique( np.array(list(preds_locale[\"next_item_prediction\"].values)) )\n",
    "            assert np.all( np.isin(predicted_products, products['id']) ), f\"Invalid products in {locale} predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_predictions(predictions, test_sessions=test_pl.collect().to_pandas(), \n",
    "                  # check_products=True, product_df=products\n",
    "                 )\n",
    "# Its important that the parquet file you submit is saved with pyarrow backend\n",
    "predictions.to_parquet(submit_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task2_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aicrowd submission create -c task-2-next-product-recommendation-for-underrepresented-languages -f {submit_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Top200 for fallback logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m popular_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf_sess\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_items\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m]], df_test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_items\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m]]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sess' is not defined"
     ]
    }
   ],
   "source": [
    "popular_df = pd.concat([df_sess[['prev_items', 'locale']], df_test[['prev_items', 'locale']]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_pl = pl.from_pandas(popular_df).lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 200\n",
    "locale_popular_pl = (\n",
    "    popular_pl\n",
    "        .select(\n",
    "            pl.col('prev_items').apply(str2list)#.explode().alias('item')\n",
    "            , pl.col('locale')\n",
    "        )\n",
    "        .explode('prev_items')#.alias('item')\n",
    "        .groupby(['locale', 'prev_items'])\n",
    "        .agg(\n",
    "            pl.count()\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('count').rank(method='ordinal', descending=True).over('locale').alias('rank')\n",
    "        )\n",
    "        .filter(pl.col('rank')<=topn)\n",
    "        .with_columns(\n",
    "            pl.col('count').max().over('locale').alias('max_count')\n",
    "            , pl.col('count').min().over('locale').alias('min_count')\n",
    "        )\n",
    "        .with_columns(\n",
    "            ((pl.col('count')-pl.col('min_count'))/(pl.col('max_count')-pl.col('min_count'))).alias('weight')\n",
    "        )\n",
    "        .sort('locale', 'rank')\n",
    "        .select(\n",
    "            'locale'\n",
    "            , 'prev_items'\n",
    "            , 'weight'\n",
    "        )\n",
    "        .groupby('locale')\n",
    "        .agg(\n",
    "            pl.col('weight').alias('locale_popular_weight')\n",
    "            , pl.col('prev_items').alias('locale_popular_rec')\n",
    "        )\n",
    "        # .count()#.head(3).collect())\n",
    "        # .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular_df.apply(lambda x: str2list(x['prev_items']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next_item_df['next_item_prediction'] = next_item_df['next_item_prediction'].astype(str)\n",
    "# # next_item_df['next_item_weights'] = next_item_df['next_item_weights'].astype(str)\n",
    "# cols = [\n",
    "#     # 'item',\n",
    "#         'next_item_prediction'\n",
    "#         , 'next_item_weights'\n",
    "#        ]\n",
    "# next_item_pl = pl.from_pandas(next_item_df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k = []\n",
    "# # v = []\n",
    "\n",
    "# # for item in next_item_dict:\n",
    "# #     k.append(item)\n",
    "# #     v.append(next_item_dict[item])\n",
    "    \n",
    "# # df_next = pd.DataFrame({'item': k, 'next_item': v})\n",
    "# df_next = next_item_df.explode('next_item_prediction').reset_index(drop=True)\n",
    "# df_next = df_next.merge(products, how='left', left_on='item', right_on='id')\n",
    "# df_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_next['next_item'].value_counts().index.tolist()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = {\n",
    "#     'top200': top200\n",
    "#     , 'next_item_map': next_item_map\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(model_file, 'wb') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get final result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with open(model_file, 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_rec(target_df, model):\n",
    "#     next_item_map = model['next_item_map']\n",
    "#     top200  = model['top200']\n",
    "#     target_df['last_item'] = target_df['prev_items'].apply(lambda x: str2list(x)[-1])\n",
    "#     target_df['next_item_prediction'] = target_df['last_item'].map(next_item_map)\n",
    "#     preds = []\n",
    "\n",
    "#     for _, row in tqdm(target_df.iterrows(), total=len(target_df)):\n",
    "#         pred_orig = row['next_item_prediction']\n",
    "#         pred = pred_orig\n",
    "#         prev_items = str2list(row['prev_items'])\n",
    "#         if type(pred) == float:\n",
    "#             pred = top200[:100]\n",
    "#         else:\n",
    "#             if len(pred_orig) < 100:\n",
    "#                 for i in top200:\n",
    "#                     if i not in pred_orig and i not in prev_items:\n",
    "#                         pred.append(i)\n",
    "#                     if len(pred) >= 100:\n",
    "#                         break\n",
    "#             else:\n",
    "#                 pred = pred[:100]\n",
    "#         preds.append(pred)\n",
    "#     target_df['next_item_prediction'] = preds\n",
    "#     print(target_df['next_item_prediction'].apply(len).describe())\n",
    "#     return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model['next_item_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate for train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl = pl.scan_csv('sessions_train.csv')\n",
    "train_pl = pl.scan_parquet('../data/eval_data/next_item_counter_train_eval_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_locals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl = (\n",
    "    train_pl\n",
    "        .filter(pl.col('locale').is_in(target_locals))\n",
    "        .with_columns(\n",
    "            pl.col('prev_items').apply(str2list).arr.get(-1).alias('last_item')\n",
    "        )\n",
    "        .join(nex_item_pl, how='left', left_on='last_item', right_on='item')\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('next_item_rec').is_null()).then([]).otherwise(pl.col('next_item_rec').arr.head(100)).alias('next_item_prediction')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'next_item'\n",
    "            , 'locale'\n",
    "            , 'next_item_prediction'\n",
    "            , 'rec_num'\n",
    "        )\n",
    ")#.head(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl.collect().write_parquet('../data/candidates/task1_train_nic_without_pupular_top100_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final resul "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_rec(target_pl, locale_popular_pl, nex_item_pl):\n",
    "    rec_num = 100\n",
    "    target_pl = (\n",
    "        target_pl\n",
    "            .with_columns(\n",
    "                pl.col('prev_items').apply(str2list).arr.get(-1).alias('last_item')\n",
    "            )\n",
    "            .join(nex_item_pl, how='left', left_on='last_item', right_on='item')\n",
    "            .join(locale_popular_pl, how='left', on='locale')\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('next_item_rec').is_null()).then([]).otherwise(pl.col('next_item_rec')).alias('next_item_rec')\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.concat_list([pl.col('next_item_rec'), pl.col('locale_popular_rec')])\n",
    "                    .alias('next_item_prediction')\n",
    "                    .arr.head(rec_num)\n",
    "\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "            )\n",
    "    )#.head(3).collect()\n",
    "    return target_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl = pl.scan_parquet(f'../data/eval_data/w2v_train_eval_result_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nex_item_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl = pl_rec(target_pl=eval_pl, locale_popular_pl=locale_popular_pl, nex_item_pl=nex_item_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.select(\n",
    "    pl.col('next_item_prediction').arr.head(20).arr.contains(pl.col('next_item')).mean().alias('recall@20')\n",
    "    , pl.col('next_item_prediction').arr.head(100).arr.contains(pl.col('next_item')).mean().alias('recall@100')\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# eval_cols = ['len', 'recall@20', 'recall@100']\n",
    "# train_eval_df[eval_cols] = train_eval_df.apply(pd_get_recall_at_k, axis=1, result_type='expand')\n",
    "# print(train_eval_df[eval_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.collect().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.collect().write_parquet(f'../data/eval_data/{model_version}_train_eval_300k.parquet', \n",
    "                      # engine='pyarrow'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl = pl.scan_csv('sessions_test_task1.csv')\n",
    "test_pl = pl_rec(target_pl=test_pl, locale_popular_pl=locale_popular_pl, nex_item_pl=nex_item_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -al | grep {submit_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.collect().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.collect().select('locale', 'next_item_prediction').write_parquet(submit_file,\n",
    "#                                                                          # engine='pyarrow'\n",
    "#                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "# !aicrowd submission create -c task-1-next-product-recommendation -f {submit_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df = pl.scan_parquet('submission_task1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w2v_df.collect().shape[0] == test_pl.collect().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pl.concat([test_pl.select('prev_items', 'locale', 'next_item_rec').collect(), w2v_df.select('next_item_prediction').collect()]\n",
    "                    , how='horizontal' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_num = 100\n",
    "target_pl = (\n",
    "    target_df\n",
    "        .lazy()\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'locale'\n",
    "            , pl.concat_list([pl.col('next_item_rec'), pl.col('next_item_prediction')])\n",
    "                .alias('next_item_prediction')\n",
    "                .arr.head(rec_num)\n",
    "\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    ")#.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.head(6).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir ../data/sub_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.collect().select('locale', 'next_item_prediction').write_parquet('../data/sub_files/rank_v1.parquet',\n",
    "                                                                         # engine='pyarrow'\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "# !aicrowd submission create -c task-1-next-product-recommendation -f '../data/sub_files/rank_v1.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_num = 100\n",
    "target_pl = (\n",
    "    target_df\n",
    "        .lazy()\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'locale'\n",
    "            , pl.concat_list([pl.col('next_item_rec').arr.head(20), pl.col('next_item_prediction')])\n",
    "                .alias('next_item_prediction')\n",
    "                .arr.head(rec_num)\n",
    "\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    ")#.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.collect().select('locale', 'next_item_prediction').write_parquet('../data/sub_files/rank_v2.parquet',\n",
    "                                                                         # engine='pyarrow'\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "!aicrowd submission create -c task-1-next-product-recommendation -f '../data/sub_files/rank_v2.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl = pl.scan_parquet(submit_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.select(\n",
    "    pl.col('next_item_prediction').arr.lengths().min()\n",
    "    , pl.col('next_item_prediction').arr.lengths().max()\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "kdd_2023",
   "name": "common-cu110.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m104"
  },
  "kernelspec": {
   "display_name": "py3.8(kdd_2023)",
   "language": "python",
   "name": "kdd_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
