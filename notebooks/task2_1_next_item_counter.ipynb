{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. check the how many times item2 is item1's next item\n",
    "2. For each item1, normalized the count to [0, 1]\n",
    "3. Add 0.01 -> since 0 will represent item2 has never been the next item of item1\n",
    "4. Next steps\n",
    "    1. [x] counts should be included \n",
    "    2. [x] train2 data should be included\n",
    "    3. [x] 0 should be the min_count for each item\n",
    "\n",
    "\n",
    "Example: [a, b, c] -> [ab, bc] -> \n",
    "\n",
    "```\n",
    "[\n",
    "--current_item, next_item, counts\n",
    "[a, b, 1],\n",
    "[b, c, 1]\n",
    "]\n",
    "\n",
    "after normalization\n",
    "\n",
    "[\n",
    "--current_item, next_item, counts\n",
    "[a, b, 1.01],\n",
    "[b, c, 1.01]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import logging\n",
    "base_dir = '../'\n",
    "sys.path.append(base_dir)\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "import polars as pl\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from tqdm.auto import tqdm\n",
    "import polars as pl\n",
    "from utils import *\n",
    "from src.eval import model_eval\n",
    "from src.config import raw_data_session_id_dir, candidate_dir, model_for_eval, candidate_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "\n",
    "task = 'task1'\n",
    "\n",
    "version = 'v11'\n",
    "\n",
    "model_version = f'nic_{task}_{version}'\n",
    "\n",
    "# target locales: locales needed for task1\n",
    "\n",
    "if task == 'task1':\n",
    "    target_locals = ['DE', 'JP', 'UK']\n",
    "elif task == 'task2':\n",
    "    target_locals = ['ES', 'FR', 'IT']\n",
    "else:\n",
    "    assert 1 == 0\n",
    "\n",
    "topn = 100\n",
    "if debug:\n",
    "    n_rows = 1000\n",
    "else:\n",
    "    n_rows = None\n",
    "# debug_session_num = 100\n",
    "train_data_dir = '.'\n",
    "test_data_dir = '.'\n",
    "\n",
    "\n",
    "model_dir = f'../model_training/{model_version}/'\n",
    "\n",
    "\n",
    "# if model_for_eval:\n",
    "model_file = os.path.join(model_dir, f'nic_{model_for_eval}_for_eval.parquet')\n",
    "submit_file = os.path.join('../data/sub_files/', f'submission_{task}_nic_{model_for_eval}_for_eval.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task1_v11/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task1_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/candidates/task1_train_nic_task1_v11_True_top100.parquet\n",
      "../data/candidates/task1_eval_nic_task1_v11_True_top100.parquet\n",
      "../data/candidates/task1_test_nic_task1_v11_True_top100.parquet\n",
      "../data/candidates/task1_test4task3_nic_task1_v11_True_top100.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_cg_file = os.path.join(base_dir,\n",
    "                             candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='train'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "eval_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='eval'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "test_cg_file = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "            candidate_file_name.format(\n",
    "                task=task\n",
    "                , data_type='test'\n",
    "                , model_version=model_version\n",
    "                , model_for_eval=model_for_eval\n",
    "                , topn=topn\n",
    "            )\n",
    "                            )\n",
    "\n",
    "test4task3_file_name = os.path.join(base_dir,\n",
    "                            candidate_dir, \n",
    "                                    candidate_file_name.format(\n",
    "    task=task\n",
    "    , data_type='test4task3'\n",
    "    , model_version=model_version\n",
    "    , model_for_eval=model_for_eval\n",
    "    , topn=topn\n",
    "))\n",
    "print(train_cg_file)\n",
    "print(eval_cg_file)\n",
    "print(test_cg_file)\n",
    "print(test4task3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task1_test_nic_task1_v11_True_top100.parquet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task1_v11/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task1_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_pl = pl.scan_parquet('../data/candidates/task2_test_nic_task2_v2_True_top100.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_prediciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_unique2id.json\t\t    sessions_test_task2_phase1.parquet\n",
      "products_train.parquet\t\t    sessions_test_task3.parquet\n",
      "sessions_eval.parquet\t\t    sessions_test_task3_phase1.parquet\n",
      "sessions_test_task1.parquet\t    sessions_train.parquet\n",
      "sessions_test_task1_phase1.parquet  sessions_train1.parquet\n",
      "sessions_test_task2.parquet\t    sessions_train2.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls ../{raw_data_session_id_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_train1.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "train2_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_train2.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "eval_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_eval.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n",
    "# df_sess.head(3).collect()\n",
    "test_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, f'sessions_test_{task}.parquet'), n_rows=n_rows).with_columns(pl.col('prev_items').apply(str2list))\n",
    "test4task3_pl = pl.scan_parquet(os.path.join(base_dir, raw_data_session_id_dir, 'sessions_test_task3.parquet'), n_rows=n_rows).filter(pl.col('locale').is_in(target_locals)).with_columns(pl.col('prev_items').apply(str2list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>locale</th><th>counts</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;JP&quot;</td><td>10000</td></tr><tr><td>&quot;UK&quot;</td><td>10000</td></tr><tr><td>&quot;DE&quot;</td><td>10000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────┐\n",
       "│ locale ┆ counts │\n",
       "│ ---    ┆ ---    │\n",
       "│ str    ┆ u32    │\n",
       "╞════════╪════════╡\n",
       "│ JP     ┆ 10000  │\n",
       "│ UK     ┆ 10000  │\n",
       "│ DE     ┆ 10000  │\n",
       "└────────┴────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4task3_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl.filter(pl.col('session_id')==3272918).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.filter(pl.col('locale').is_null()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'item', 'next_item_prediction', 'next_item_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nic_rec(target_pl, nic_model, rec_num=topn):\n",
    "    # rec_num = 100\n",
    "    final_cols = ['session_id', 'next_item_prediction', 'rec_num']\n",
    "    target_pl = (\n",
    "        target_pl\n",
    "            .with_columns(\n",
    "                pl.col('prev_items').arr.get(-1).alias('last_item')\n",
    "            )\n",
    "            .join(nic_model, how='left', left_on='last_item', right_on='item')\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('next_item_prediction').is_null()).then([]).otherwise(pl.col('next_item_prediction').arr.head(rec_num)).alias('next_item_prediction')\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "            )\n",
    "            .select(\n",
    "                final_cols\n",
    "            )\n",
    "    )#.head(3).collect()\n",
    "    return target_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Item Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_pl.with_columns(\n",
    "    pl.col('prev_items').arr.concat(pl.col('next_item')) \n",
    ")\n",
    "if not model_for_eval:\n",
    "    eval_data = eval_pl.with_columns(\n",
    "    pl.col('prev_items').arr.concat(pl.col('next_item')) \n",
    ")\n",
    "else:\n",
    "    eval_data = eval_pl\n",
    "train2_data = train2_pl\n",
    "\n",
    "test_data = test_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_for_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not model_for_eval:\n",
    "\n",
    "\n",
    "cols_to_keep = ['prev_items']\n",
    "next_items_pl = (\n",
    "    pl.concat([train_data.select(cols_to_keep), \n",
    "               eval_data.select(cols_to_keep),\n",
    "               train2_data.select(cols_to_keep),\n",
    "               test_data.select(cols_to_keep)], how='vertical')\n",
    "        .with_columns(\n",
    "            pl.col('prev_items').arr.shift(-1).alias('next_item_lst')\n",
    "            , pl.col('prev_items').arr.lengths().alias('length')\n",
    "        )\n",
    "        .select(\n",
    "            pl.col('prev_items').arr.head(pl.col('length')-1).alias('prev')\n",
    "            , pl.col('next_item_lst').arr.head(pl.col('length')-1).alias('next')\n",
    "        )\n",
    "        .explode(['prev','next' ])\n",
    "        .groupby(['prev','next' ])\n",
    "        .agg(\n",
    "            pl.count().alias('cnt')\n",
    "        )\n",
    "        .sort(['prev', 'cnt'], descending=True)\n",
    "        .with_columns(\n",
    "            pl.col('cnt').max().over('prev').alias('max_count')\n",
    "            , pl.lit(0).alias('min_count')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('max_count')==pl.col('min_count')).then(1).otherwise((pl.col('cnt')-pl.col('min_count'))/(pl.col('max_count')-pl.col('min_count'))).alias('normalized_cnt')\n",
    "        )\n",
    "        .groupby('prev')\n",
    "        .agg(\n",
    "            pl.col('next').alias('next_item_prediction')\n",
    "            , pl.col('cnt').alias('next_item_cnt')\n",
    "            , (pl.col('normalized_cnt')).alias('next_item_weight')\n",
    "        )\n",
    "        .select(\n",
    "            pl.col('prev').alias('item')\n",
    "            , 'next_item_prediction'\n",
    "            , pl.col('next_item_weight')\n",
    "            , 'next_item_cnt'\n",
    "        )\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item</th><th>next_item_prediction</th><th>next_item_weight</th><th>next_item_cnt</th></tr><tr><td>str</td><td>list[str]</td><td>list[f64]</td><td>list[u32]</td></tr></thead><tbody><tr><td>&quot;B08939HB6V&quot;</td><td>[&quot;B0893873SX&quot;, &quot;B089SJNGNH&quot;, … &quot;B08GC1KJ3J&quot;]</td><td>[1.0, 0.875, … 0.125]</td><td>[8, 7, … 1]</td></tr><tr><td>&quot;B00J96Q4ZG&quot;</td><td>[&quot;B07PHWHG8V&quot;, &quot;B091FG85DW&quot;, … &quot;B07X82T8CN&quot;]</td><td>[1.0, 1.0, … 1.0]</td><td>[1, 1, … 1]</td></tr><tr><td>&quot;B09DG799QY&quot;</td><td>[&quot;B01IQJJM9Q&quot;, &quot;B01LX1CPIT&quot;]</td><td>[1.0, 0.5]</td><td>[2, 1]</td></tr><tr><td>&quot;B00HD108LU&quot;</td><td>[&quot;B004XON6CI&quot;]</td><td>[1.0]</td><td>[1]</td></tr><tr><td>&quot;B004OR8LBK&quot;</td><td>[&quot;B006MXXKRY&quot;, &quot;B00D8WQOB6&quot;]</td><td>[1.0, 0.5]</td><td>[2, 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌────────────┬───────────────────────────────────┬───────────────────────┬───────────────┐\n",
       "│ item       ┆ next_item_prediction              ┆ next_item_weight      ┆ next_item_cnt │\n",
       "│ ---        ┆ ---                               ┆ ---                   ┆ ---           │\n",
       "│ str        ┆ list[str]                         ┆ list[f64]             ┆ list[u32]     │\n",
       "╞════════════╪═══════════════════════════════════╪═══════════════════════╪═══════════════╡\n",
       "│ B08939HB6V ┆ [\"B0893873SX\", \"B089SJNGNH\", … \"… ┆ [1.0, 0.875, … 0.125] ┆ [8, 7, … 1]   │\n",
       "│ B00J96Q4ZG ┆ [\"B07PHWHG8V\", \"B091FG85DW\", … \"… ┆ [1.0, 1.0, … 1.0]     ┆ [1, 1, … 1]   │\n",
       "│ B09DG799QY ┆ [\"B01IQJJM9Q\", \"B01LX1CPIT\"]      ┆ [1.0, 0.5]            ┆ [2, 1]        │\n",
       "│ B00HD108LU ┆ [\"B004XON6CI\"]                    ┆ [1.0]                 ┆ [1]           │\n",
       "│ B004OR8LBK ┆ [\"B006MXXKRY\", \"B00D8WQOB6\"]      ┆ [1.0, 0.5]            ┆ [2, 1]        │\n",
       "└────────────┴───────────────────────────────────┴───────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_items_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_items_pl.collect()#.filter(pl.col('item')=='B09LXX1PQ9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_dict = defaultdict(list)\n",
    "\n",
    "# for _, row in tqdm(df_sess.iterrows(), total=len(df_sess)):\n",
    "#     prev_items = str2list(row['prev_items'])\n",
    "#     if not model_for_eval:\n",
    "#         next_item = row['next_item']\n",
    "#     prev_items_length = len(prev_items)\n",
    "#     if prev_items_length <= 1:\n",
    "#         if not model_for_eval:\n",
    "#             next_item_dict[prev_items[0]].append(next_item)\n",
    "#     else:\n",
    "#         for i, item in enumerate(prev_items[:-1]):\n",
    "#             next_item_dict[item].append(prev_items[i+1])\n",
    "#         if not model_for_eval:\n",
    "#             next_item_dict[prev_items[-1]].append(next_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "#     prev_items = str2list(row['prev_items'])\n",
    "#     prev_items_length = len(prev_items)\n",
    "#     if prev_items_length <= 1:\n",
    "#         continue\n",
    "#     else:\n",
    "#         for i, item in enumerate(prev_items[:-1]):\n",
    "#             next_item_dict[item].append(prev_items[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next_item_map = {}\n",
    "# topn = 100\n",
    "# item_lst = []\n",
    "# common_items_lst = []\n",
    "# weights_lst = []\n",
    "# for item in tqdm(next_item_dict):\n",
    "#     counter = Counter(next_item_dict[item])\n",
    "#     most_common_cnt = counter.most_common(1)[0][1]\n",
    "#     most_common_lst = list(zip(*counter.most_common(topn)))\n",
    "#     most_common_lst[1] = list(np.array(most_common_lst[1])/most_common_cnt)\n",
    "#     item_lst.append(item)\n",
    "#     common_items_lst.append(list(most_common_lst[0]))\n",
    "#     weights_lst.append(most_common_lst[1])\n",
    "#     # next_item_map[item] = most_common_lst\n",
    "#     # next_item_map[item] = [i[0] for i in counter.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df = pd.DataFrame(\n",
    "#     {'item': item_lst\n",
    "#     , 'next_item_prediction': common_items_lst\n",
    "#      , 'next_item_weight': weights_lst\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_items_pl.collect().filter(pl.col('item')=='B07QGW8LFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nex_item_pl = pl.from_pandas(next_item_df).lazy().select(\n",
    "#     'item'\n",
    "#     , pl.col('next_item_prediction').alias('next_item_rec')\n",
    "#     , 'next_item_weight'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../model_training/next_item_counter/model.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model['next_item_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nex_item_pl = pl.DataFrame(\n",
    "#     {\n",
    "#         'item': model['next_item_map'].keys()\n",
    "#         , 'next_item_rec': model['next_item_map'].values()\n",
    "#     }\n",
    "# ).lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1237681, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_items_pl.collect().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task1_v10/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_items_pl.collect().write_parquet(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del next_items_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/nic_task1_v10/nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_items_pl = pl.scan_parquet(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = next_items_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item', 'next_item_prediction', 'next_item_weight', 'next_item_cnt'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_items_pl.head(30).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    next_items_pl.explode('next_item_prediction')\n",
    "        .filter(\n",
    "            pl.col('next_item_prediction').is_null()\n",
    "        )\n",
    ").collect().shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.select('locale').collect().to_series().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl = nic_rec(target_pl=eval_pl, nic_model=next_items_pl)#.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if_hit = pl.element().rank()\n",
    "target_df = eval_pl.join(eval_candidate_pl, how='left', on='session_id')\n",
    "\n",
    "\n",
    "# eval_final.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>total_sessions</th><th>mrr</th><th>recall@20</th><th>recall@100</th></tr><tr><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>326443</td><td>0.2295</td><td>0.3858</td><td>0.4068</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────────┬────────┬───────────┬────────────┐\n",
       "│ total_sessions ┆ mrr    ┆ recall@20 ┆ recall@100 │\n",
       "│ ---            ┆ ---    ┆ ---       ┆ ---        │\n",
       "│ u32            ┆ f64    ┆ f64       ┆ f64        │\n",
       "╞════════════════╪════════╪═══════════╪════════════╡\n",
       "│ 326443         ┆ 0.2295 ┆ 0.3858    ┆ 0.4068     │\n",
       "└────────────────┴────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval(target_df=target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>rec_num</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>326443.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>20.689621</td></tr><tr><td>&quot;std&quot;</td><td>24.879117</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>100.0</td></tr><tr><td>&quot;median&quot;</td><td>11.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ describe   ┆ rec_num   │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ count      ┆ 326443.0  │\n",
       "│ null_count ┆ 0.0       │\n",
       "│ mean       ┆ 20.689621 │\n",
       "│ std        ┆ 24.879117 │\n",
       "│ min        ┆ 0.0       │\n",
       "│ max        ┆ 100.0     │\n",
       "│ median     ┆ 11.0      │\n",
       "└────────────┴───────────┘"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.select('rec_num').collect().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Saving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_candidate_pl.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task1_eval_nic_task1_v10_True_top100.parquet'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_cg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_candidate_pl.filter(pl.col('rec_num')>0).collect().write_parquet(eval_cg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & eval  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_pl = nic_rec(target_pl=train2_pl, nic_model=next_items_pl)#.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_pl.filter(pl.col('rec_num')>0).collect().write_parquet(train_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate_pl = nic_rec(target_pl=test_pl, nic_model=next_items_pl)#.head().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate_pl.filter(pl.col('rec_num')>0).collect().write_parquet(test_cg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/candidates/task1_test_nic_task1_v10_True_top100.parquet'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cg_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test4task3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/candidates/task1_test4task3_nic_task1_v10_True_top100.parquet\n"
     ]
    }
   ],
   "source": [
    "print(test4task3_file_name)\n",
    "test4task3_cg_pl = nic_rec(target_pl=test4task3_pl, nic_model=next_items_pl)#.head().collect()\n",
    "test4task3_cg_pl.filter(pl.col('rec_num')>0).collect().write_parquet(test4task3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_task2 = pl.read_csv('../data/raw_data/sessions_test_task2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls ../data/raw_data/ | grep task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_task2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_pl.join(test_candidate_pl, how='left', on='session_id').collect()[['locale', 'next_item_prediction']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_predictions(predictions,test_sessions, check_products=False, product_df=None):\n",
    "    \"\"\"\n",
    "    These tests need to pass as they will also be applied on the evaluator\n",
    "    \"\"\"\n",
    "    test_locale_names = test_sessions['locale'].unique()\n",
    "    for locale in test_locale_names:\n",
    "        sess_test = test_sessions.query(f'locale == \"{locale}\"')\n",
    "        preds_locale =  predictions[predictions['locale'] == sess_test['locale'].iloc[0]]\n",
    "        assert sorted(preds_locale.index.values) == sorted(sess_test.index.values), f\"Session ids of {locale} doesn't match\"\n",
    "\n",
    "        if check_products:\n",
    "            # This check is not done on the evaluator\n",
    "            # but you can run it to verify there is no mixing of products between locales\n",
    "            # Since the ground truth next item will always belong to the same locale\n",
    "            # Warning - This can be slow to run\n",
    "            products = product_df.query(f'locale == \"{locale}\"')\n",
    "            predicted_products = np.unique( np.array(list(preds_locale[\"next_item_prediction\"].values)) )\n",
    "            assert np.all( np.isin(predicted_products, products['id']) ), f\"Invalid products in {locale} predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_predictions(predictions, test_sessions=test_pl.collect().to_pandas(), \n",
    "                  # check_products=True, product_df=products\n",
    "                 )\n",
    "# Its important that the parquet file you submit is saved with pyarrow backend\n",
    "predictions.to_parquet(submit_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sub_files/submission_task2_nic_True_for_eval.parquet'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aicrowd submission create -c task-2-next-product-recommendation-for-underrepresented-languages -f {submit_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Top200 for fallback logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m popular_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf_sess\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_items\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m]], df_test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_items\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m]]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sess' is not defined"
     ]
    }
   ],
   "source": [
    "popular_df = pd.concat([df_sess[['prev_items', 'locale']], df_test[['prev_items', 'locale']]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_pl = pl.from_pandas(popular_df).lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 200\n",
    "locale_popular_pl = (\n",
    "    popular_pl\n",
    "        .select(\n",
    "            pl.col('prev_items').apply(str2list)#.explode().alias('item')\n",
    "            , pl.col('locale')\n",
    "        )\n",
    "        .explode('prev_items')#.alias('item')\n",
    "        .groupby(['locale', 'prev_items'])\n",
    "        .agg(\n",
    "            pl.count()\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('count').rank(method='ordinal', descending=True).over('locale').alias('rank')\n",
    "        )\n",
    "        .filter(pl.col('rank')<=topn)\n",
    "        .with_columns(\n",
    "            pl.col('count').max().over('locale').alias('max_count')\n",
    "            , pl.col('count').min().over('locale').alias('min_count')\n",
    "        )\n",
    "        .with_columns(\n",
    "            ((pl.col('count')-pl.col('min_count'))/(pl.col('max_count')-pl.col('min_count'))).alias('weight')\n",
    "        )\n",
    "        .sort('locale', 'rank')\n",
    "        .select(\n",
    "            'locale'\n",
    "            , 'prev_items'\n",
    "            , 'weight'\n",
    "        )\n",
    "        .groupby('locale')\n",
    "        .agg(\n",
    "            pl.col('weight').alias('locale_popular_weight')\n",
    "            , pl.col('prev_items').alias('locale_popular_rec')\n",
    "        )\n",
    "        # .count()#.head(3).collect())\n",
    "        # .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular_df.apply(lambda x: str2list(x['prev_items']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next_item_df['next_item_prediction'] = next_item_df['next_item_prediction'].astype(str)\n",
    "# # next_item_df['next_item_weights'] = next_item_df['next_item_weights'].astype(str)\n",
    "# cols = [\n",
    "#     # 'item',\n",
    "#         'next_item_prediction'\n",
    "#         , 'next_item_weights'\n",
    "#        ]\n",
    "# next_item_pl = pl.from_pandas(next_item_df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k = []\n",
    "# # v = []\n",
    "\n",
    "# # for item in next_item_dict:\n",
    "# #     k.append(item)\n",
    "# #     v.append(next_item_dict[item])\n",
    "    \n",
    "# # df_next = pd.DataFrame({'item': k, 'next_item': v})\n",
    "# df_next = next_item_df.explode('next_item_prediction').reset_index(drop=True)\n",
    "# df_next = df_next.merge(products, how='left', left_on='item', right_on='id')\n",
    "# df_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_next['next_item'].value_counts().index.tolist()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = {\n",
    "#     'top200': top200\n",
    "#     , 'next_item_map': next_item_map\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(model_file, 'wb') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get final result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with open(model_file, 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_rec(target_df, model):\n",
    "#     next_item_map = model['next_item_map']\n",
    "#     top200  = model['top200']\n",
    "#     target_df['last_item'] = target_df['prev_items'].apply(lambda x: str2list(x)[-1])\n",
    "#     target_df['next_item_prediction'] = target_df['last_item'].map(next_item_map)\n",
    "#     preds = []\n",
    "\n",
    "#     for _, row in tqdm(target_df.iterrows(), total=len(target_df)):\n",
    "#         pred_orig = row['next_item_prediction']\n",
    "#         pred = pred_orig\n",
    "#         prev_items = str2list(row['prev_items'])\n",
    "#         if type(pred) == float:\n",
    "#             pred = top200[:100]\n",
    "#         else:\n",
    "#             if len(pred_orig) < 100:\n",
    "#                 for i in top200:\n",
    "#                     if i not in pred_orig and i not in prev_items:\n",
    "#                         pred.append(i)\n",
    "#                     if len(pred) >= 100:\n",
    "#                         break\n",
    "#             else:\n",
    "#                 pred = pred[:100]\n",
    "#         preds.append(pred)\n",
    "#     target_df['next_item_prediction'] = preds\n",
    "#     print(target_df['next_item_prediction'].apply(len).describe())\n",
    "#     return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model['next_item_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate for train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pl = pl.scan_csv('sessions_train.csv')\n",
    "train_pl = pl.scan_parquet('../data/eval_data/next_item_counter_train_eval_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_locals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl = (\n",
    "    train_pl\n",
    "        .filter(pl.col('locale').is_in(target_locals))\n",
    "        .with_columns(\n",
    "            pl.col('prev_items').apply(str2list).arr.get(-1).alias('last_item')\n",
    "        )\n",
    "        .join(nex_item_pl, how='left', left_on='last_item', right_on='item')\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('next_item_rec').is_null()).then([]).otherwise(pl.col('next_item_rec').arr.head(100)).alias('next_item_prediction')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'next_item'\n",
    "            , 'locale'\n",
    "            , 'next_item_prediction'\n",
    "            , 'rec_num'\n",
    "        )\n",
    ")#.head(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl.collect().write_parquet('../data/candidates/task1_train_nic_without_pupular_top100_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final resul "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_rec(target_pl, locale_popular_pl, nex_item_pl):\n",
    "    rec_num = 100\n",
    "    target_pl = (\n",
    "        target_pl\n",
    "            .with_columns(\n",
    "                pl.col('prev_items').apply(str2list).arr.get(-1).alias('last_item')\n",
    "            )\n",
    "            .join(nex_item_pl, how='left', left_on='last_item', right_on='item')\n",
    "            .join(locale_popular_pl, how='left', on='locale')\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('next_item_rec').is_null()).then([]).otherwise(pl.col('next_item_rec')).alias('next_item_rec')\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.concat_list([pl.col('next_item_rec'), pl.col('locale_popular_rec')])\n",
    "                    .alias('next_item_prediction')\n",
    "                    .arr.head(rec_num)\n",
    "\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "            )\n",
    "    )#.head(3).collect()\n",
    "    return target_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl = pl.scan_parquet(f'../data/eval_data/w2v_train_eval_result_300k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nex_item_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locale_popular_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl = pl_rec(target_pl=eval_pl, locale_popular_pl=locale_popular_pl, nex_item_pl=nex_item_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.select(\n",
    "    pl.col('next_item_prediction').arr.head(20).arr.contains(pl.col('next_item')).mean().alias('recall@20')\n",
    "    , pl.col('next_item_prediction').arr.head(100).arr.contains(pl.col('next_item')).mean().alias('recall@100')\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# eval_cols = ['len', 'recall@20', 'recall@100']\n",
    "# train_eval_df[eval_cols] = train_eval_df.apply(pd_get_recall_at_k, axis=1, result_type='expand')\n",
    "# print(train_eval_df[eval_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.collect().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pl.collect().write_parquet(f'../data/eval_data/{model_version}_train_eval_300k.parquet', \n",
    "                      # engine='pyarrow'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl = pl.scan_csv('sessions_test_task1.csv')\n",
    "test_pl = pl_rec(target_pl=test_pl, locale_popular_pl=locale_popular_pl, nex_item_pl=nex_item_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -al | grep {submit_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.collect().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.collect().select('locale', 'next_item_prediction').write_parquet(submit_file,\n",
    "#                                                                          # engine='pyarrow'\n",
    "#                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "# !aicrowd submission create -c task-1-next-product-recommendation -f {submit_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df = pl.scan_parquet('submission_task1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w2v_df.collect().shape[0] == test_pl.collect().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pl.concat([test_pl.select('prev_items', 'locale', 'next_item_rec').collect(), w2v_df.select('next_item_prediction').collect()]\n",
    "                    , how='horizontal' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_num = 100\n",
    "target_pl = (\n",
    "    target_df\n",
    "        .lazy()\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'locale'\n",
    "            , pl.concat_list([pl.col('next_item_rec'), pl.col('next_item_prediction')])\n",
    "                .alias('next_item_prediction')\n",
    "                .arr.head(rec_num)\n",
    "\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    ")#.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.head(6).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir ../data/sub_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.collect().select('locale', 'next_item_prediction').write_parquet('../data/sub_files/rank_v1.parquet',\n",
    "                                                                         # engine='pyarrow'\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "# !aicrowd submission create -c task-1-next-product-recommendation -f '../data/sub_files/rank_v1.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_num = 100\n",
    "target_pl = (\n",
    "    target_df\n",
    "        .lazy()\n",
    "        .select(\n",
    "            'prev_items'\n",
    "            , 'locale'\n",
    "            , pl.concat_list([pl.col('next_item_rec').arr.head(20), pl.col('next_item_prediction')])\n",
    "                .alias('next_item_prediction')\n",
    "                .arr.head(rec_num)\n",
    "\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('next_item_prediction').arr.lengths().alias('rec_num')\n",
    "        )\n",
    ")#.head(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pl.collect().select('locale', 'next_item_prediction').write_parquet('../data/sub_files/rank_v2.parquet',\n",
    "                                                                         # engine='pyarrow'\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "!aicrowd submission create -c task-1-next-product-recommendation -f '../data/sub_files/rank_v2.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl = pl.scan_parquet(submit_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl.select(\n",
    "    pl.col('next_item_prediction').arr.lengths().min()\n",
    "    , pl.col('next_item_prediction').arr.lengths().max()\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "kdd_2023",
   "name": "common-cu110.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m104"
  },
  "kernelspec": {
   "display_name": "py3.8(kdd_2023)",
   "language": "python",
   "name": "kdd_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
