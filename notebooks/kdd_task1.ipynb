{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7POE7L5_kz07"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LbTnzGOhBrw",
    "outputId": "dba2e9df-ca4b-4ec9-8e63-aeecb016d038"
   },
   "outputs": [],
   "source": [
    "# !aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-QfVS2fthKWr",
    "outputId": "912cd23c-c2d4-45ad-88e9-72c49773d16b"
   },
   "outputs": [],
   "source": [
    "# !aicrowd dataset download --challenge task-1-next-product-recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmjiT10Qk5m8",
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7DjmcQMAgPAJ"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import logging\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxcGbj4xAqqe"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qYPjjtQ_AqRT"
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "debug_session_num = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6oiTtQ56gYlY"
   },
   "outputs": [],
   "source": [
    "train_data_dir = '.'\n",
    "test_data_dir = '.'\n",
    "task = 'task1'\n",
    "PREDS_PER_SESSION = 100\n",
    "\n",
    "model_dir = '../model_training/v2'\n",
    "\n",
    "# target locales: locales needed for task1\n",
    "\n",
    "target_locals = [\"DE\", 'JP', 'UK']\n",
    "\n",
    "w2v_model_file = os.path.join(model_dir, 'w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrMp8SO2tFtL",
    "tags": []
   },
   "source": [
    "# Data Description\n",
    "\n",
    "The Multilingual Shopping Session Dataset is a collection of **anonymized customer sessions** containing products from six different locales, namely English, German, Japanese, French, Italian, and Spanish. It consists of two main components: **user sessions** and **product attributes**. User sessions are a list of products that a user has engaged with in chronological order, while product attributes include various details like product title, price in local currency, brand, color, and description.\n",
    "\n",
    "---\n",
    "\n",
    "### Each product as its associated information:\n",
    "\n",
    "\n",
    "**locale**: the locale code of the product (e.g., DE)\n",
    "\n",
    "**id**: a unique for the product. Also known as Amazon Standard Item Number (ASIN) (e.g., B07WSY3MG8)\n",
    "\n",
    "**title**: title of the item (e.g., ‚ÄúJapanese Aesthetic Sakura Flowers Vaporwave Soft Grunge Gift T-Shirt‚Äù)\n",
    "\n",
    "**price**: price of the item in local currency (e.g., 24.99)\n",
    "\n",
    "**brand**: item brand name (e.g., ‚ÄúJapanese Aesthetic Flowers & Vaporwave Clothing‚Äù)\n",
    "\n",
    "**color**: color of the item (e.g., ‚ÄúBlack‚Äù)\n",
    "\n",
    "**size**: size of the item (e.g., ‚Äúxxl‚Äù)\n",
    "\n",
    "**model**: model of the item (e.g., ‚Äúiphone 13‚Äù)\n",
    "\n",
    "**material**: material of the item (e.g., ‚Äúcotton‚Äù)\n",
    "\n",
    "**author**: author of the item (e.g., ‚ÄúJ. K. Rowling‚Äù)\n",
    "\n",
    "**desc**: description about a item‚Äôs key features and benefits called out via bullet points (e.g., ‚ÄúSolid colors: 100% Cotton; Heather Grey: 90% Cotton, 10% Polyester; All Other Heathers ‚Ä¶‚Äù)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZEph_ZjlOj0"
   },
   "source": [
    "## EDA üíΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f2L9ImDqge3_"
   },
   "outputs": [],
   "source": [
    "def read_locale_data(locale, task):\n",
    "    products = read_product_data().query(f'locale == \"{locale}\"')\n",
    "    sess_train = read_train_data().query(f'locale == \"{locale}\"')\n",
    "    sess_test = read_test_data(task).query(f'locale == \"{locale}\"')\n",
    "    return products, sess_train, sess_test\n",
    "\n",
    "def show_locale_info(locale, task):\n",
    "    products, sess_train, sess_test = read_locale_data(locale, task)\n",
    "\n",
    "    train_l = sess_train['prev_items'].apply(lambda sess: len(sess))\n",
    "    test_l = sess_test['prev_items'].apply(lambda sess: len(sess))\n",
    "\n",
    "    print(f\"Locale: {locale} \\n\"\n",
    "          f\"Number of products: {products['id'].nunique()} \\n\"\n",
    "          f\"Number of train sessions: {len(sess_train)} \\n\"\n",
    "          f\"Train session lengths - \"\n",
    "          f\"Mean: {train_l.mean():.2f} | Median {train_l.median():.2f} | \"\n",
    "          f\"Min: {train_l.min():.2f} | Max {train_l.max():.2f} \\n\"\n",
    "          f\"Number of test sessions: {len(sess_test)}\"\n",
    "        )\n",
    "    if len(sess_test) > 0:\n",
    "        print(\n",
    "             f\"Test session lengths - \"\n",
    "            f\"Mean: {test_l.mean():.2f} | Median {test_l.median():.2f} | \"\n",
    "            f\"Min: {test_l.min():.2f} | Max {test_l.max():.2f} \\n\"\n",
    "        )\n",
    "    print(\"======================================================================== \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWCiG4Odggmo",
    "outputId": "e29c572c-b658-44e1-bbd5-c9df22dfded1"
   },
   "outputs": [],
   "source": [
    "# products = read_product_data(train_data_dir=train_data_dir)\n",
    "# locale_names = products['locale'].unique()\n",
    "# for locale in locale_names:\n",
    "#     show_locale_info(locale, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "S1S19qsFgk43",
    "outputId": "28e7f39f-a471-4f02-b763-bd89f15740dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>873599</th>\n",
       "      <td>['B00EVA1FFO' 'B00EVA1H66']</td>\n",
       "      <td>B00H3APNFC</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391555</th>\n",
       "      <td>['B087Q7BCRQ' 'B08DK1GS2W']</td>\n",
       "      <td>B09L7TSRWF</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547188</th>\n",
       "      <td>['B0713WW5XB' 'B077GS2LJ5' 'B0713WW5XB' 'B077G...</td>\n",
       "      <td>B09PBJJD9F</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194408</th>\n",
       "      <td>['B09V3JGPXG' 'B09V3KZ5J7' 'B09V3HXTB7' 'B09V3...</td>\n",
       "      <td>B09V3JT6N8</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159784</th>\n",
       "      <td>['B08V98Z8BK' 'B08V98Z8BK' 'B09QFPZ9B7' 'B018U...</td>\n",
       "      <td>B018FZNQ4I</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prev_items   next_item locale\n",
       "873599                         ['B00EVA1FFO' 'B00EVA1H66']  B00H3APNFC     DE\n",
       "2391555                        ['B087Q7BCRQ' 'B08DK1GS2W']  B09L7TSRWF     UK\n",
       "547188   ['B0713WW5XB' 'B077GS2LJ5' 'B0713WW5XB' 'B077G...  B09PBJJD9F     DE\n",
       "1194408  ['B09V3JGPXG' 'B09V3KZ5J7' 'B09V3HXTB7' 'B09V3...  B09V3JT6N8     JP\n",
       "2159784  ['B08V98Z8BK' 'B08V98Z8BK' 'B09QFPZ9B7' 'B018U...  B018FZNQ4I     UK"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions = read_train_data(train_data_dir=train_data_dir)\n",
    "train_sessions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tbllmbaEgmBg",
    "outputId": "2560f079-ff99-4583-b38d-715f5fd14167"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285769</th>\n",
       "      <td>['B07B5S36DP' 'B083NMTVS5' 'B07B5S36DP']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110917</th>\n",
       "      <td>['B07S8VWT5B' 'B06W9DXWY8' 'B06WRN4VGJ' 'B010R...</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217459</th>\n",
       "      <td>['B09BNX11LQ' 'B09BNWY6SB']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134735</th>\n",
       "      <td>['B0891LMDBD' 'B09BV9P5WM']</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289671</th>\n",
       "      <td>['B08VF94DSV' 'B07SWQTPDZ' 'B08VF94DSV' 'B0BGH...</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prev_items locale\n",
       "285769           ['B07B5S36DP' 'B083NMTVS5' 'B07B5S36DP']     UK\n",
       "110917  ['B07S8VWT5B' 'B06W9DXWY8' 'B06WRN4VGJ' 'B010R...     JP\n",
       "217459                        ['B09BNX11LQ' 'B09BNWY6SB']     UK\n",
       "134735                        ['B0891LMDBD' 'B09BV9P5WM']     JP\n",
       "289671  ['B08VF94DSV' 'B07SWQTPDZ' 'B08VF94DSV' 'B0BGH...     UK"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions = read_test_data(task, test_data_dir=test_data_dir)\n",
    "test_sessions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "75D8eRsBBGQI"
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    train_sessions = train_sessions.sample(debug_session_num)\n",
    "    test_sessions = test_sessions.sample(debug_session_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEJ7k_ufBOe7",
    "outputId": "f28aacc0-097e-4b14-d0a5-28219acfe674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3606249, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LpgqFwzADXJW"
   },
   "outputs": [],
   "source": [
    "train_sessions['prev_items'] = train_sessions.apply(lambda row: process_item_lst(row), axis=1)\n",
    "# test_sessions['prev_items'] = test_sessions.apply(lambda row: process_item_lst(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "locale\n",
       "UK    115936\n",
       "DE    104568\n",
       "JP     96467\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions['locale'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DE', 'JP', 'UK']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_locals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = train_sessions[train_sessions['locale'].isin(target_locals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3272716, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0T1vtOEB5v-",
    "tags": []
   },
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FXQ0pY06CGiC"
   },
   "outputs": [],
   "source": [
    "# train_sessions['prev_items'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aJe9Y_uB8nF",
    "outputId": "e177ee22-154f-4195-f06a-6a7f7afba594"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3589687"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_size = 32\n",
    "epochs = 10\n",
    "sg = 1 # 1 for skip-gram\n",
    "pop_thresh = 0.82415\n",
    "window = 4\n",
    "\n",
    "sentences = train_sessions['prev_items'].to_list() + test_sessions['prev_items'].to_list()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "j2aLO74iLJzD"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZL3YXLg_Dzl3",
    "outputId": "558f7e2c-a427-41eb-a368-f12c08da34af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 11067542.0\n",
      "Loss after epoch 1: 6493280.0\n",
      "Loss after epoch 2: 2888668.0\n",
      "Loss after epoch 3: 2580968.0\n",
      "Loss after epoch 4: 2329516.0\n",
      "Loss after epoch 5: 2048868.0\n",
      "Loss after epoch 6: 1821566.0\n",
      "Loss after epoch 7: 1773816.0\n",
      "Loss after epoch 8: 1667380.0\n",
      "Loss after epoch 9: 1025936.0\n"
     ]
    }
   ],
   "source": [
    "w2vec = Word2Vec(sentences=sentences, vector_size=vector_size, epochs = epochs, sg=sg,\n",
    "                 min_count=1, workers=14,\n",
    "                 window=window,\n",
    "                  compute_loss=True\n",
    "              , callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/v2/w2v.model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QKu7E6IcOHX1"
   },
   "outputs": [],
   "source": [
    "w2vec.save(w2v_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qjypjOksFIUA"
   },
   "outputs": [],
   "source": [
    "# ! ls sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9UswdYbIm6S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJoalTbYgnnp"
   },
   "source": [
    "Generate Submission üèãÔ∏è‚Äç‚ôÄÔ∏è\n",
    "\n",
    "\n",
    "\n",
    "Submission format:\n",
    "1. The submission should be a **parquet** file with the sessions from all the locales. \n",
    "2. Predicted products ids per locale should only be a valid product id of that locale. \n",
    "3. Predictions should be added in new column named **\"next_item_prediction\"**.\n",
    "4. Predictions should be a list of string id values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "B3zsYp_Jgn_J"
   },
   "outputs": [],
   "source": [
    "# def random_predicitons(locale, sess_test_locale):\n",
    "#     random_state = np.random.RandomState(42)\n",
    "#     products = read_product_data().query(f'locale == \"{locale}\"')\n",
    "#     predictions = []\n",
    "#     for _ in range(len(sess_test_locale)):\n",
    "#         predictions.append(\n",
    "#             list(products['id'].sample(PREDS_PER_SESSION, replace=True, random_state=random_state))\n",
    "#         ) \n",
    "#     sess_test_locale['next_item_prediction'] = predictions\n",
    "#     sess_test_locale.drop('prev_items', inplace=True, axis=1)\n",
    "#     return sess_test_locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cLu2KKKvF-ZA",
    "outputId": "b2d3da23-28cf-43dc-fd8f-d9e5ec16072d"
   },
   "outputs": [],
   "source": [
    "# test_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "zZj7SRjpNuu0",
    "outputId": "dd576d00-b16b-4acd-e001-e8906e97d8d5"
   },
   "outputs": [],
   "source": [
    "# test_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_training/v2/w2v.model'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec = Word2Vec.load(w2v_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TbHB_m2aGr8i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316971, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_sessions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2s5v2GF2HMvy",
    "outputId": "6221243b-73ba-4967-8144-cc4aefddbb69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B08KQBYV43' '3955350843' '3955350843' '39553...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items locale\n",
       "0  ['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...     DE\n",
       "1           ['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']     DE\n",
       "2  ['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...     DE\n",
       "3  ['B08KQBYV43' '3955350843' '3955350843' '39553...     DE\n",
       "4  ['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...     DE"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mv6TZEFqgrFu"
   },
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# test_locale_names = test_sessions['locale'].unique()\n",
    "# for locale in test_locale_names:\n",
    "#     sess_test_locale = test_sessions.query(f'locale == \"{locale}\"').copy()\n",
    "#     predictions.append(\n",
    "#         random_predicitons(locale, sess_test_locale)\n",
    "#     )\n",
    "# predictions = pd.concat(predictions).reset_index(drop=True)\n",
    "# predictions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QBU2Y6P_IR5x"
   },
   "outputs": [],
   "source": [
    "def get_predictions(row):\n",
    "    prev_items = row['prev_items']\n",
    "    # try:\n",
    "    similarity_dic = w2vec.wv.most_similar(positive=prev_items, topn=100)\n",
    "    res = [item for item, simi in similarity_dic] \n",
    "        # print(err)\n",
    "    # except Exception as e:\n",
    "        # print(e)\n",
    "    # res = prev_items\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_session_vector(df, w2vec):\n",
    "# #   aids = df.aid.unique()\n",
    "# #   for i, aid in enumerate(aids):\n",
    "# #     vec = w2vec.wv[aid] if i == 0 else vec + w2vec.wv[aid]\n",
    "# #   vec = vec / len(aids)\n",
    "# #   return vec\n",
    "\n",
    "# # def get_close_aids(df, w2vec, index, idx2aid, n=20):\n",
    "# #   session_vec = get_session_vector(df, w2vec)\n",
    "# #   close_aids = get_nearest_neighbours(session_vec, index, idx2aid, n)\n",
    "# #   return close_aids\n",
    "\n",
    "# # def get_nearest_neighbours(x, index, idx2aid, n=20):\n",
    "# #   indexes, distances = index.get_nns_by_vector(x, n, search_k=-1, include_distances=True)\n",
    "# #   aids = [idx2aid[i] for i in indexes]\n",
    "# #   df = pd.DataFrame(data={'aid' : aids, 'w2vec_dist' : distances})\n",
    "# #   return df\n",
    "\n",
    "# index = AnnoyIndex(vector_size, distance)\n",
    "# aid2idx = {}\n",
    "\n",
    "# popular_aids = test.groupby('aid', as_index=False).agg({'session' : 'count'})\n",
    "# popular_aids = popular_aids.loc[popular_aids['session'] > popular_aids['session'].quantile(pop_thresh)]\n",
    "# popular_aid_list = popular_aids.aid.unique()\n",
    "\n",
    "# for i, aid in enumerate(popular_aid_list):\n",
    "# aid = str(aid)\n",
    "# aid2idx[aid] = i\n",
    "# index.add_item(i, w2vec.wv[aid])\n",
    "# idx2aid = { v : k for k, v in aid2idx.items()}\n",
    "# index.build(40) # build 40 trees\n",
    "\n",
    "# reduced_test = test.copy()\n",
    "# reduced_test['aid'] = reduced_test['aid'].astype('str')\n",
    "# reduced_test['aid_vector'] = reduced_test['aid'].apply(lambda x: w2vec.wv[x])\n",
    "\n",
    "# reduced_test = reduced_test.groupby('session').apply(lambda x: get_close_aids(x, w2vec, index, idx2aid, n)).reset_index().drop(columns='level_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_sessions.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df['next_item_prediction'] = df.apply(lambda row: get_predictions(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec(prev_items, topn=10):\n",
    "    # print(prev_items)\n",
    "    res = [ele.replace('[', '').replace(']', '').replace('\\n', '').replace(\"'\", '').replace(' ', '') for ele in prev_items.split(' ')]\n",
    "    # print(type(res))\n",
    "    try:\n",
    "        similarity_dic = w2vec.wv.most_similar(positive=res, topn=topn)\n",
    "        res = [item for item, simi in similarity_dic] \n",
    "        # print(err)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 2min 42s, total: 5min 6s\n",
      "Wall time: 45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pl_df = pl.from_dataframe(df)\n",
    "pl_df = (\n",
    "    pl_df\n",
    "        .with_columns(pl.col('prev_items').apply(lambda row: get_rec(row)).alias('next_item_prediction'))\n",
    ")\n",
    "result_df = pl_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "x7vA4qfcJDaW"
   },
   "outputs": [],
   "source": [
    "# test_sessions['next_item_prediction'] = test_sessions.apply(lambda row: get_predictions(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UXy4O2nrG6NC"
   },
   "outputs": [],
   "source": [
    "predictions = result_df[['locale', 'next_item_prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ieI1oY58ICil"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locale</th>\n",
       "      <th>next_item_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>[B093375R52, B08CB8TM7H, B0895XDJ4M, B08Q7WG4T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>[B06VWFTT3V, B079ZV816K, B07RL66RQ9, B079ZV4V3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>[B08CSC94BT, B0BGHZJCMJ, B0992B1K3K, B09R4JKCK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JP</td>\n",
       "      <td>[B09H2PNSVG, B0BCHKRNPK, B09CYCF44J, B09MY7P1B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE</td>\n",
       "      <td>[B08GR2HD5X, B0742KVRJR, B00BYNCTOW, B08KNTFQX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  locale                               next_item_prediction\n",
       "0     UK  [B093375R52, B08CB8TM7H, B0895XDJ4M, B08Q7WG4T...\n",
       "1     DE  [B06VWFTT3V, B079ZV816K, B07RL66RQ9, B079ZV4V3...\n",
       "2     UK  [B08CSC94BT, B0BGHZJCMJ, B0992B1K3K, B09R4JKCK...\n",
       "3     JP  [B09H2PNSVG, B0BCHKRNPK, B09CYCF44J, B09MY7P1B...\n",
       "4     DE  [B08GR2HD5X, B0742KVRJR, B00BYNCTOW, B08KNTFQX..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNB90dXKlZkR"
   },
   "source": [
    "# Validate predictions ‚úÖ üòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1XKTojogtF2"
   },
   "outputs": [],
   "source": [
    "def check_predictions(predictions, check_products=False):\n",
    "    \"\"\"\n",
    "    These tests need to pass as they will also be applied on the evaluator\n",
    "    \"\"\"\n",
    "    test_locale_names = test_sessions['locale'].unique()\n",
    "    for locale in test_locale_names:\n",
    "        sess_test = test_sessions.query(f'locale == \"{locale}\"')\n",
    "        preds_locale =  predictions[predictions['locale'] == sess_test['locale'].iloc[0]]\n",
    "        assert sorted(preds_locale.index.values) == sorted(sess_test.index.values), f\"Session ids of {locale} doesn't match\"\n",
    "\n",
    "        if check_products:\n",
    "            # This check is not done on the evaluator\n",
    "            # but you can run it to verify there is no mixing of products between locales\n",
    "            # Since the ground truth next item will always belong to the same locale\n",
    "            # Warning - This can be slow to run\n",
    "            products = read_product_data().query(f'locale == \"{locale}\"')\n",
    "            predicted_products = np.unique( np.array(list(preds_locale[\"next_item_prediction\"].values)) )\n",
    "            assert np.all( np.isin(predicted_products, products['id']) ), f\"Invalid products in {locale} predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJA368Gzguk7"
   },
   "outputs": [],
   "source": [
    "check_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dTvU5VOgv0j"
   },
   "outputs": [],
   "source": [
    "# Its important that the parquet file you submit is saved with pyarrow backend\n",
    "predictions.to_parquet(f'submission_{task}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVrZ_TfnjL09"
   },
   "source": [
    "## Submit to AIcrowd üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rd9OYWEgixPZ"
   },
   "outputs": [],
   "source": [
    "# You can submit with aicrowd-cli, or upload manually on the challenge page.\n",
    "!aicrowd submission create -c task-1-next-product-recommendation -f \"submission_task1.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "kdd_2023",
   "name": "common-cu110.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m104"
  },
  "kernelspec": {
   "display_name": "py3.8(kdd_2023)",
   "language": "python",
   "name": "kdd_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
